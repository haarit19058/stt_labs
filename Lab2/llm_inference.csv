hash,filename,diff,llm_inference,rectified_msg
f719b6115b9638a8d5c6789ab29caae7e163e145,converter.py,"@@ -364,7 +364,7 @@ class TextConverter(PDFConverter[AnyIO]):
             vlen=[]
             ops=""""
             def vflag(fontname): # 匹配公式（和角标）字体
-                return re.match('.*\+(CM.*|MS.*|.*0700|.*0500)',fontname)
+                return re.match(r'.*\+(CM.*|MS.*|.*0700|.*0500)',fontname)
             for child in item:
                 if isinstance(child, LTChar):
                     if not vflag(child.fontname) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
@@ -457,7 +457,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             # print(cstk,tx,x,rt,y)
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ T* '
                         break
-                    vy_regex=re.match('\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
+                    vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
                     if vy_regex: # 加载公式
                         vid=int(vy_regex.group(1).replace(' ',''))
                         ptr+=len(vy_regex.group(0))
@@ -482,13 +482,13 @@ class TextConverter(PDFConverter[AnyIO]):
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正
-                            if re.match('.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112]: # 根式与大小求和
+                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112]: # 根式与大小求和
                                 fix=var[vid][0].size*0.85
-                            if re.match('.*\+(CMSY.*)',var[vid][0].fontname) and var[vid][0].cid in [112]: # 根式
+                            if re.match(r'.*\+(CMSY.*)',var[vid][0].fontname) and var[vid][0].cid in [112]: # 根式
                                 fix=var[vid][0].size*0.85
-                            if re.match('.*\+(MSAM.*)',var[vid][0].fontname) and var[vid][0].cid in [97]: # 特殊上标
+                            if re.match(r'.*\+(MSAM.*)',var[vid][0].fontname) and var[vid][0].cid in [97]: # 特殊上标
                                 fix=var[vid][0].size*0.85
-                            if re.match('.*\+(CMR.*)',var[vid][0].fontname) and var[vid][0].cid in [94,126]: # 特殊上标
+                            if re.match(r'.*\+(CMR.*)',var[vid][0].fontname) and var[vid][0].cid in [94,126]: # 特殊上标
                                 fix=var[vid][0].size*0.25
                         for vch in var[vid]:
                             vc=chr(vch.cid) # vch.get_text()
",add more comments to text converter,
f719b6115b9638a8d5c6789ab29caae7e163e145,setup.py,"@@ -4,7 +4,7 @@ from pathlib import Path
 from setuptools import setup
 
 setup(
-    name=""PDFMathTranslate"",
+    name=""pdf2zh"",
     description=""Latex PDF Translater"",
     license=""MIT"",
     author=""Byaidu"",
@@ -13,7 +13,7 @@ setup(
     setuptools_git_versioning={
         ""enabled"": True,
     },
-    setup_requires=[""setuptools-git-versioning<3""],
+    setup_requires=[""setuptools-git-versioning""],
     packages=[""pdf2zh""],
     install_requires=[
         ""charset-normalizer >= 2.0.0"",
",add missing setup.py,
1ef06a7fd3ab366ebe6c8b11d5008211d87e3efb,pdf2zh.py,"@@ -103,26 +103,26 @@ def create_parser() -> argparse.ArgumentParser:
         help=""One or more paths to PDF files."",
     )
 
-    parser.add_argument(
-        ""--version"",
-        ""-v"",
-        action=""version"",
-        version=f""pdf2zh.six v{pdf2zh.__version__}"",
-    )
-    parser.add_argument(
-        ""--debug"",
-        ""-d"",
-        default=False,
-        action=""store_true"",
-        help=""Use debug logging level."",
-    )
-    parser.add_argument(
-        ""--disable-caching"",
-        ""-C"",
-        default=False,
-        action=""store_true"",
-        help=""If caching or resources, such as fonts, should be disabled."",
-    )
+    # parser.add_argument(
+    #     ""--version"",
+    #     ""-v"",
+    #     action=""version"",
+    #     version=f""pdf2zh.six v{pdf2zh.__version__}"",
+    # )
+    # parser.add_argument(
+    #     ""--debug"",
+    #     ""-d"",
+    #     default=False,
+    #     action=""store_true"",
+    #     help=""Use debug logging level."",
+    # )
+    # parser.add_argument(
+    #     ""--disable-caching"",
+    #     ""-C"",
+    #     default=False,
+    #     action=""store_true"",
+    #     help=""If caching or resources, such as fonts, should be disabled."",
+    # )
 
     parse_params = parser.add_argument_group(
         ""Parser"",
@@ -135,21 +135,21 @@ def create_parser() -> argparse.ArgumentParser:
         nargs=""+"",
         help=""A space-seperated list of page numbers to parse."",
     )
-    parse_params.add_argument(
-        ""--pagenos"",
-        ""-p"",
-        type=str,
-        help=""A comma-separated list of page numbers to parse. ""
-        ""Included for legacy applications, use --page-numbers ""
-        ""for more idiomatic argument entry."",
-    )
-    parse_params.add_argument(
-        ""--maxpages"",
-        ""-m"",
-        type=int,
-        default=0,
-        help=""The maximum number of pages to parse."",
-    )
+    # parse_params.add_argument(
+    #     ""--pagenos"",
+    #     ""-p"",
+    #     type=str,
+    #     help=""A comma-separated list of page numbers to parse. ""
+    #     ""Included for legacy applications, use --page-numbers ""
+    #     ""for more idiomatic argument entry."",
+    # )
+    # parse_params.add_argument(
+    #     ""--maxpages"",
+    #     ""-m"",
+    #     type=int,
+    #     default=0,
+    #     help=""The maximum number of pages to parse."",
+    # )
     parse_params.add_argument(
         ""--password"",
         ""-P"",
@@ -157,153 +157,153 @@ def create_parser() -> argparse.ArgumentParser:
         default="""",
         help=""The password to use for decrypting PDF file."",
     )
-    parse_params.add_argument(
-        ""--rotation"",
-        ""-R"",
-        default=0,
-        type=int,
-        help=""The number of degrees to rotate the PDF ""
-        ""before other types of processing."",
-    )
-
-    la_params = LAParams()  # will be used for defaults
-    la_param_group = parser.add_argument_group(
-        ""Layout analysis"",
-        description=""Used during layout analysis."",
-    )
-    la_param_group.add_argument(
-        ""--no-laparams"",
-        ""-n"",
-        default=False,
-        action=""store_true"",
-        help=""If layout analysis parameters should be ignored."",
-    )
-    la_param_group.add_argument(
-        ""--detect-vertical"",
-        ""-V"",
-        default=la_params.detect_vertical,
-        action=""store_true"",
-        help=""If vertical text should be considered during layout analysis"",
-    )
-    la_param_group.add_argument(
-        ""--line-overlap"",
-        type=float,
-        default=la_params.line_overlap,
-        help=""If two characters have more overlap than this they ""
-        ""are considered to be on the same line. The overlap is specified ""
-        ""relative to the minimum height of both characters."",
-    )
-    la_param_group.add_argument(
-        ""--char-margin"",
-        ""-M"",
-        type=float,
-        default=la_params.char_margin,
-        help=""If two characters are closer together than this margin they ""
-        ""are considered to be part of the same line. The margin is ""
-        ""specified relative to the width of the character."",
-    )
-    la_param_group.add_argument(
-        ""--word-margin"",
-        ""-W"",
-        type=float,
-        default=la_params.word_margin,
-        help=""If two characters on the same line are further apart than this ""
-        ""margin then they are considered to be two separate words, and ""
-        ""an intermediate space will be added for readability. The margin ""
-        ""is specified relative to the width of the character."",
-    )
-    la_param_group.add_argument(
-        ""--line-margin"",
-        ""-L"",
-        type=float,
-        default=la_params.line_margin,
-        help=""If two lines are close together they are considered to ""
-        ""be part of the same paragraph. The margin is specified ""
-        ""relative to the height of a line."",
-    )
-    la_param_group.add_argument(
-        ""--boxes-flow"",
-        ""-F"",
-        type=float_or_disabled,
-        default=la_params.boxes_flow,
-        help=""Specifies how much a horizontal and vertical position of a ""
-        ""text matters when determining the order of lines. The value ""
-        ""should be within the range of -1.0 (only horizontal position ""
-        ""matters) to +1.0 (only vertical position matters). You can also ""
-        ""pass `disabled` to disable advanced layout analysis, and ""
-        ""instead return text based on the position of the bottom left ""
-        ""corner of the text box."",
-    )
-    la_param_group.add_argument(
-        ""--all-texts"",
-        ""-A"",
-        default=la_params.all_texts,
-        action=""store_true"",
-        help=""If layout analysis should be performed on text in figures."",
-    )
-
-    output_params = parser.add_argument_group(
-        ""Output"",
-        description=""Used during output generation."",
-    )
-    output_params.add_argument(
-        ""--outfile"",
-        ""-o"",
-        type=str,
-        default=""-"",
-        help=""Path to file where output is written. ""
-        'Or ""-"" (default) to write to stdout.',
-    )
-    output_params.add_argument(
-        ""--output_type"",
-        ""-t"",
-        type=str,
-        default=""text"",
-        help=""Type of output to generate {text,html,xml,tag}."",
-    )
-    output_params.add_argument(
-        ""--codec"",
-        ""-c"",
-        type=str,
-        default=""utf-8"",
-        help=""Text encoding to use in output file."",
-    )
-    output_params.add_argument(
-        ""--output-dir"",
-        ""-O"",
-        default=None,
-        help=""The output directory to put extracted images in. If not given, ""
-        ""images are not extracted."",
-    )
-    output_params.add_argument(
-        ""--layoutmode"",
-        ""-Y"",
-        default=""normal"",
-        type=str,
-        help=""Type of layout to use when generating html ""
-        ""{normal,exact,loose}. If normal,each line is""
-        "" positioned separately in the html. If exact""
-        "", each character is positioned separately in""
-        "" the html. If loose, same result as normal ""
-        ""but with an additional newline after each ""
-        ""text line. Only used when output_type is html."",
-    )
-    output_params.add_argument(
-        ""--scale"",
-        ""-s"",
-        type=float,
-        default=1.0,
-        help=""The amount of zoom to use when generating html file. ""
-        ""Only used when output_type is html."",
-    )
-    output_params.add_argument(
-        ""--strip-control"",
-        ""-S"",
-        default=False,
-        action=""store_true"",
-        help=""Remove control statement from text. ""
-        ""Only used when output_type is xml."",
-    )
+    # parse_params.add_argument(
+    #     ""--rotation"",
+    #     ""-R"",
+    #     default=0,
+    #     type=int,
+    #     help=""The number of degrees to rotate the PDF ""
+    #     ""before other types of processing."",
+    # )
+
+    # la_params = LAParams()  # will be used for defaults
+    # la_param_group = parser.add_argument_group(
+    #     ""Layout analysis"",
+    #     description=""Used during layout analysis."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--no-laparams"",
+    #     ""-n"",
+    #     default=False,
+    #     action=""store_true"",
+    #     help=""If layout analysis parameters should be ignored."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--detect-vertical"",
+    #     ""-V"",
+    #     default=la_params.detect_vertical,
+    #     action=""store_true"",
+    #     help=""If vertical text should be considered during layout analysis"",
+    # )
+    # la_param_group.add_argument(
+    #     ""--line-overlap"",
+    #     type=float,
+    #     default=la_params.line_overlap,
+    #     help=""If two characters have more overlap than this they ""
+    #     ""are considered to be on the same line. The overlap is specified ""
+    #     ""relative to the minimum height of both characters."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--char-margin"",
+    #     ""-M"",
+    #     type=float,
+    #     default=la_params.char_margin,
+    #     help=""If two characters are closer together than this margin they ""
+    #     ""are considered to be part of the same line. The margin is ""
+    #     ""specified relative to the width of the character."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--word-margin"",
+    #     ""-W"",
+    #     type=float,
+    #     default=la_params.word_margin,
+    #     help=""If two characters on the same line are further apart than this ""
+    #     ""margin then they are considered to be two separate words, and ""
+    #     ""an intermediate space will be added for readability. The margin ""
+    #     ""is specified relative to the width of the character."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--line-margin"",
+    #     ""-L"",
+    #     type=float,
+    #     default=la_params.line_margin,
+    #     help=""If two lines are close together they are considered to ""
+    #     ""be part of the same paragraph. The margin is specified ""
+    #     ""relative to the height of a line."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--boxes-flow"",
+    #     ""-F"",
+    #     type=float_or_disabled,
+    #     default=la_params.boxes_flow,
+    #     help=""Specifies how much a horizontal and vertical position of a ""
+    #     ""text matters when determining the order of lines. The value ""
+    #     ""should be within the range of -1.0 (only horizontal position ""
+    #     ""matters) to +1.0 (only vertical position matters). You can also ""
+    #     ""pass `disabled` to disable advanced layout analysis, and ""
+    #     ""instead return text based on the position of the bottom left ""
+    #     ""corner of the text box."",
+    # )
+    # la_param_group.add_argument(
+    #     ""--all-texts"",
+    #     ""-A"",
+    #     default=la_params.all_texts,
+    #     action=""store_true"",
+    #     help=""If layout analysis should be performed on text in figures."",
+    # )
+
+    # output_params = parser.add_argument_group(
+    #     ""Output"",
+    #     description=""Used during output generation."",
+    # )
+    # output_params.add_argument(
+    #     ""--outfile"",
+    #     ""-o"",
+    #     type=str,
+    #     default=""-"",
+    #     help=""Path to file where output is written. ""
+    #     'Or ""-"" (default) to write to stdout.',
+    # )
+    # output_params.add_argument(
+    #     ""--output_type"",
+    #     ""-t"",
+    #     type=str,
+    #     default=""text"",
+    #     help=""Type of output to generate {text,html,xml,tag}."",
+    # )
+    # output_params.add_argument(
+    #     ""--codec"",
+    #     ""-c"",
+    #     type=str,
+    #     default=""utf-8"",
+    #     help=""Text encoding to use in output file."",
+    # )
+    # output_params.add_argument(
+    #     ""--output-dir"",
+    #     ""-O"",
+    #     default=None,
+    #     help=""The output directory to put extracted images in. If not given, ""
+    #     ""images are not extracted."",
+    # )
+    # output_params.add_argument(
+    #     ""--layoutmode"",
+    #     ""-Y"",
+    #     default=""normal"",
+    #     type=str,
+    #     help=""Type of layout to use when generating html ""
+    #     ""{normal,exact,loose}. If normal,each line is""
+    #     "" positioned separately in the html. If exact""
+    #     "", each character is positioned separately in""
+    #     "" the html. If loose, same result as normal ""
+    #     ""but with an additional newline after each ""
+    #     ""text line. Only used when output_type is html."",
+    # )
+    # output_params.add_argument(
+    #     ""--scale"",
+    #     ""-s"",
+    #     type=float,
+    #     default=1.0,
+    #     help=""The amount of zoom to use when generating html file. ""
+    #     ""Only used when output_type is html."",
+    # )
+    # output_params.add_argument(
+    #     ""--strip-control"",
+    #     ""-S"",
+    #     default=False,
+    #     action=""store_true"",
+    #     help=""Remove control statement from text. ""
+    #     ""Only used when output_type is xml."",
+    # )
 
     return parser
 
@@ -312,29 +312,29 @@ def parse_args(args: Optional[List[str]]) -> argparse.Namespace:
     parsed_args = create_parser().parse_args(args=args)
 
     # Propagate parsed layout parameters to LAParams object
-    if parsed_args.no_laparams:
-        parsed_args.laparams = None
-    else:
-        parsed_args.laparams = LAParams(
-            line_overlap=parsed_args.line_overlap,
-            char_margin=parsed_args.char_margin,
-            line_margin=parsed_args.line_margin,
-            word_margin=parsed_args.word_margin,
-            boxes_flow=parsed_args.boxes_flow,
-            detect_vertical=parsed_args.detect_vertical,
-            all_texts=parsed_args.all_texts,
-        )
+    # if parsed_args.no_laparams:
+    #     parsed_args.laparams = None
+    # else:
+    #     parsed_args.laparams = LAParams(
+    #         line_overlap=parsed_args.line_overlap,
+    #         char_margin=parsed_args.char_margin,
+    #         line_margin=parsed_args.line_margin,
+    #         word_margin=parsed_args.word_margin,
+    #         boxes_flow=parsed_args.boxes_flow,
+    #         detect_vertical=parsed_args.detect_vertical,
+    #         all_texts=parsed_args.all_texts,
+    #     )
 
     if parsed_args.page_numbers:
         parsed_args.page_numbers = {x - 1 for x in parsed_args.page_numbers}
 
-    if parsed_args.pagenos:
-        parsed_args.page_numbers = {int(x) - 1 for x in parsed_args.pagenos.split("","")}
+    # if parsed_args.pagenos:
+    #     parsed_args.page_numbers = {int(x) - 1 for x in parsed_args.pagenos.split("","")}
 
-    if parsed_args.output_type == ""text"" and parsed_args.outfile != ""-"":
-        for override, alttype in OUTPUT_TYPES:
-            if parsed_args.outfile.endswith(override):
-                parsed_args.output_type = alttype
+    # if parsed_args.output_type == ""text"" and parsed_args.outfile != ""-"":
+    #     for override, alttype in OUTPUT_TYPES:
+    #         if parsed_args.outfile.endswith(override):
+    #             parsed_args.output_type = alttype
 
     return parsed_args
 
",add more options to the create_parser function,
1ef06a7fd3ab366ebe6c8b11d5008211d87e3efb,setup.py,"@@ -3,9 +3,15 @@ from pathlib import Path
 
 from setuptools import setup
 
+root_dir = Path(__file__).parent
+with open(root_dir / ""README.md"", encoding='utf-8') as f:
+    readme = f.read()
+
 setup(
     name=""pdf2zh"",
-    description=""Latex PDF Translater"",
+    long_description=readme,
+    long_description_content_type=""text/markdown"",
+    description=""Latex PDF Translator"",
     license=""MIT"",
     author=""Byaidu"",
     author_email=""byaidux@gmail.com"",
",add missing setup.py,
270c0e200d1fe1666e6057ec94bedb6e0bc434fb,converter.py,"@@ -359,8 +359,11 @@ class TextConverter(PDFConverter[AnyIO]):
             rt=None
             sstk=[]
             vstk=[]
+            vlstk=[]
             pstk=[]
+            lstk=[]
             var=[]
+            varl=[]
             vlen=[]
             ops=""""
             def vflag(fontname): # 匹配公式（和角标）字体
@@ -372,18 +375,20 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk[-1]+=f'$v{len(var)}$'
                             # print(f'$v{len(var)}$',end='')
                             var.append(vstk)
+                            varl.append(vlstk)
                             vstk=[]
+                            vlstk=[]
                     if not vstk: # 非公式或是公式开头
                         if xt and child.y1 >= xt.y0 - child.size*0.6:
                             if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
                                 lt,rt=child,child
                                 sstk.append("""")
-                                pstk.append([child.y0,child.x0,child.x0,child.size,child.font,False])
+                                pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                                 # print(f'\n\n[TEXT D] {(child.y0,child.x0,child.size)}')
                             elif child.x0 > xt.x1 + child.size*2: # 行内分离
                                 lt,rt=child,child
                                 sstk.append("""")
-                                pstk.append([child.y0,child.x0,child.x0,child.size,child.font,False])
+                                pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                                 # print(f'\n\n[TEXT A] {(child.y0,child.x0,child.size)}')
                             elif child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
@@ -392,41 +397,47 @@ class TextConverter(PDFConverter[AnyIO]):
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
-                                    pstk.append([child.y0,child.x0,child.x0,child.size,child.font,False])
+                                    pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                                     # print(f'\n\n[TEXT B] {(child.y0,child.x0,child.size)}')
                                 else: # 换行空格
                                     sstk[-1]+=' '
-                                    pstk[-1][5]=True # 标记原文段落存在换行
+                                    pstk[-1][6]=True # 标记原文段落存在换行
                                     # print(' ',end='')
                         else: # 基于纵向距离的行间分离
                             lt,rt=child,child
                             sstk.append("""")
-                            pstk.append([child.y0,child.x0,child.x0,child.size,child.font,False])
+                            pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                             # print(f'\n\n[TEXT C] {(child.y0,child.x0,child.size)}')
                     if not vflag(child.fontname): # 文字入栈
                         sstk[-1]+=child.get_text()
                         # print(child.get_text(),end='')
-                        if vflag(pstk[-1][4].fontname): # 公式开头，后续接文字，需要校正字体
-                            pstk[-1][4]=child.font
+                        if vflag(pstk[-1][5].fontname): # 公式开头，后续接文字，需要校正字体
+                            pstk[-1][5]=child.font
                     else: # 公式入栈
                         vstk.append(child)
                     xt=child
                     # 更新左右边界
                     if child.x0<lt.x0:
-                        pstk[-1][1]=child.x0
+                        pstk[-1][2]=child.x0
                         lt=child
                     if child.x1>rt.x1:
-                        pstk[-1][2]=child.x1
+                        pstk[-1][3]=child.x1
                         rt=child
-                elif isinstance(child, LTFigure):
+                elif isinstance(child, LTFigure): # 图表
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
+                elif isinstance(child, LTLine): # 线条
+                    if vstk: # 公式环境
+                        vlstk.append(child)
+                    else:
+                        lstk.append(child)
                 else:
-                    assert False
+                    # print(child)
+                    pass
             print('\n==========[VSTACK]==========\n')
             for id,v in enumerate(var):
                 l=v[-1].x1-v[0].x0
-                print(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname}> $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
+                print(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])}> $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
                 vlen.append(l)
             print('\n==========[SSTACK]==========\n')
             hash_key=cache.deterministic_hash(""PDFMathTranslate"")
@@ -448,14 +459,14 @@ class TextConverter(PDFConverter[AnyIO]):
             with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                 news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk)))
             for id,new in enumerate(news):
-                lt=x=pstk[id][1];y=pstk[id][0];rt=pstk[id][2];ptr=0;size=pstk[id][3];font=pstk[id][4];lb=pstk[id][5];cstk='';fcur=fcur_=None
+                x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
                 tx=x
                 while True:
                     # print(new,ptr)
                     if ptr==len(new): # 到达段落结尾
                         if cstk:
                             # print(cstk,tx,x,rt,y)
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ T* '
+                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ '
                         break
                     vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
                     if vy_regex: # 加载公式
@@ -474,7 +485,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if fcur_!=fcur or vy_regex or x+adv>rt+size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
                         if cstk:
                             # print(cstk,tx,x,rt,y)
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ T* '
+                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ '
                             cstk=''
                     if lb and x+adv>rt+size: # 到达右边界且原文段落存在换行
                         x=lt
@@ -495,8 +506,11 @@ class TextConverter(PDFConverter[AnyIO]):
                             vc=vc.replace('\\','\\0134')
                             vc=vc.replace('(','\\050')
                             vc=vc.replace(')','\\051')
-                            ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm ({vc}) Tj T* ""
+                            ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm ({vc}) Tj ""
                             # print(vc,vch,vch.x0,vch.x1,vch.y0,vch.y1)
+                        for l in varl[vid]:
+                            ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
+                            pass
                     else: # 插入文字缓冲区
                         if not cstk:
                             tx=x
@@ -508,7 +522,10 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk+=ch
                     fcur=fcur_
                     x+=adv
-                print(""<"",' '.join([f'{j:.1f}' for j in pstk[id][:4]]),pstk[id][4].fontname,pstk[id][5],"">"",new)
+                print(""<"",' '.join([f'{j:.1f}' for j in pstk[id][:5]]),pstk[id][5].fontname,pstk[id][6],"">"",new)
+            for l in lstk:
+                ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
+                pass
             ops=f'BT {ops}ET '
             return ops
 
@@ -525,15 +542,15 @@ class TextConverter(PDFConverter[AnyIO]):
         if self.imagewriter is not None:
             PDFConverter.render_image(self, name, stream)
 
-    def paint_path(
-        self,
-        gstate: PDFGraphicState,
-        stroke: bool,
-        fill: bool,
-        evenodd: bool,
-        path: Sequence[PathSegment],
-    ) -> None:
-        pass
+    # def paint_path(
+    #     self,
+    #     gstate: PDFGraphicState,
+    #     stroke: bool,
+    #     fill: bool,
+    #     evenodd: bool,
+    #     path: Sequence[PathSegment],
+    # ) -> None:
+    #     pass
 
 
 class HTMLConverter(PDFConverter[AnyIO]):
",add more examples to text converter,
270c0e200d1fe1666e6057ec94bedb6e0bc434fb,pdfinterp.py,"@@ -1026,7 +1026,7 @@ class PDFPageInterpreter:
                         log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
-                            if not name in ['TJ','Tj','Tm','Td','Tf','BT','ET']:
+                            if not name in ['TJ','Tj','Tm','Td','Tf','BT','ET','l']:
                                 p="" "".join([str(x).replace(""\'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
",add missing function signature,
291eebd8dcb1206e7e2e5187b13a96d138a6b1b5,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.1""
+__version__ = ""1.0.2""
 __author__ = ""Byaidu""
",update version,
291eebd8dcb1206e7e2e5187b13a96d138a6b1b5,converter.py,"@@ -482,12 +482,12 @@ class TextConverter(PDFConverter[AnyIO]):
                             fcur_='china-ss'
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
-                    if fcur_!=fcur or vy_regex or x+adv>rt+size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
+                    if fcur_!=fcur or vy_regex or x+adv>rt: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
                         if cstk:
                             # print(cstk,tx,x,rt,y)
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ '
                             cstk=''
-                    if lb and x+adv>rt+size: # 到达右边界且原文段落存在换行
+                    if lb and x+adv>rt: # 到达右边界且原文段落存在换行
                         x=lt
                         y-=size*1.5
                     if vy_regex: # 插入公式
",add support for 公公公公公公公公公公公公公公公公公公公公公公公公公公公公公公公叏,
ac2e14192cdfee974bf8333688270c24453a8ebe,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.4""
+__version__ = ""1.0.5""
 __author__ = ""Byaidu""
",update version,
ac2e14192cdfee974bf8333688270c24453a8ebe,cmapdb.py,"@@ -93,7 +93,7 @@ class CMap(CMapBase):
         copy(self.code2cid, cmap.code2cid)
 
     def decode(self, code: bytes) -> Iterator[int]:
-        log.debug(""decode: %r, %r"", self, code)
+        # log.debug(""decode: %r, %r"", self, code)
         d = self.code2cid
         for i in iter(code):
             if i in d:
@@ -150,7 +150,7 @@ class UnicodeMap(CMapBase):
         return ""<UnicodeMap: %s>"" % self.attrs.get(""CMapName"")
 
     def get_unichr(self, cid: int) -> str:
-        log.debug(""get_unichr: %r, %r"", self, cid)
+        # log.debug(""get_unichr: %r, %r"", self, cid)
         return self.cid2unichr[cid]
 
     def dump(self, out: TextIO = sys.stdout) -> None:
@@ -161,7 +161,7 @@ class UnicodeMap(CMapBase):
 class IdentityUnicodeMap(UnicodeMap):
     def get_unichr(self, cid: int) -> str:
         """"""Interpret character id as unicode codepoint""""""
-        log.debug(""get_unichr: %r, %r"", self, cid)
+        # log.debug(""get_unichr: %r, %r"", self, cid)
         return chr(cid)
 
 
@@ -233,7 +233,7 @@ class CMapDB:
     def _load_data(cls, name: str) -> Any:
         name = name.replace(""\0"", """")
         filename = ""%s.pickle.gz"" % name
-        log.debug(""loading: %r"", name)
+        # log.debug(""loading: %r"", name)
         cmap_paths = (
             os.environ.get(""CMAP_PATH"", ""/usr/share/pdf2zh/""),
             os.path.join(os.path.dirname(__file__), ""cmap""),
",add missing classes to cmap,
ac2e14192cdfee974bf8333688270c24453a8ebe,converter.py,"@@ -272,7 +272,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
         return item.adv
 
     def handle_undefined_char(self, font: PDFFont, cid: int) -> str:
-        log.debug(""undefined: %r, %r"", font, cid)
+        # log.debug(""undefined: %r, %r"", font, cid)
         return ""(cid:%d)"" % cid
 
     def receive_layout(self, ltpage: LTPage) -> None:
@@ -435,12 +435,12 @@ class TextConverter(PDFConverter[AnyIO]):
                 else:
                     # print(child)
                     pass
-            print('\n==========[VSTACK]==========\n')
+            log.debug('\n==========[VSTACK]==========\n')
             for id,v in enumerate(var):
                 l=v[-1].x1-v[0].x0
-                print(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
+                log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
                 vlen.append(l)
-            print('\n==========[SSTACK]==========\n')
+            log.debug('\n==========[SSTACK]==========\n')
             hash_key=cache.deterministic_hash(""PDFMathTranslate"")
             # if cache.is_cached(hash_key):
             #     print('Cache is found')
@@ -459,7 +459,8 @@ class TextConverter(PDFConverter[AnyIO]):
                 return new
             # tqdm with concurrent.futures.ThreadPoolExecutor()
             with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
-                news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk), position=1))
+                # news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk), position=1))
+                news = list(executor.map(worker, sstk))
             for id,new in enumerate(news):
                 x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
                 tx=x
@@ -524,7 +525,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk+=ch
                     fcur=fcur_
                     x+=adv
-                print(""<"",' '.join([f'{j:.1f}' for j in pstk[id][:5]]),pstk[id][5].fontname,pstk[id][6],"">"",new)
+                log.debug(f""< {' '.join([f'{j:.1f}' for j in pstk[id][:5]])} {pstk[id][5].fontname} {pstk[id][6]} > {new}"")
             for l in lstk:
                 ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                 pass
",add more info to the layout analyzer,
ac2e14192cdfee974bf8333688270c24453a8ebe,encodingdb.py,"@@ -121,6 +121,7 @@ class EncodingDB:
                     try:
                         cid2unicode[cid] = name2unicode(cast(str, x.name))
                     except (KeyError, ValueError) as e:
-                        log.debug(str(e))
+                        # log.debug(str(e))
+                        pass
                     cid += 1
         return cid2unicode
",fix error in encodingdb.py,
ac2e14192cdfee974bf8333688270c24453a8ebe,lzw.py,"@@ -90,13 +90,13 @@ class LZWDecoder:
                 break
             yield x
 
-            logger.debug(
-                ""nbits=%d, code=%d, output=%r, table=%r"",
-                self.nbits,
-                code,
-                x,
-                self.table[258:],
-            )
+            # logger.debug(
+            #     ""nbits=%d, code=%d, output=%r, table=%r"",
+            #     self.nbits,
+            #     code,
+            #     x,
+            #     self.table[258:],
+            # )
 
 
 def lzwdecode(data: bytes) -> bytes:
",add missing debug statements,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdf2zh.py,"@@ -110,13 +110,13 @@ def create_parser() -> argparse.ArgumentParser:
     #     action=""version"",
     #     version=f""pdf2zh.six v{pdf2zh.__version__}"",
     # )
-    # parser.add_argument(
-    #     ""--debug"",
-    #     ""-d"",
-    #     default=False,
-    #     action=""store_true"",
-    #     help=""Use debug logging level."",
-    # )
+    parser.add_argument(
+        ""--debug"",
+        ""-d"",
+        default=False,
+        action=""store_true"",
+        help=""Use debug logging level."",
+    )
     # parser.add_argument(
     #     ""--disable-caching"",
     #     ""-C"",
",add debug flag to the argument parser,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdfdocument.py,"@@ -171,7 +171,7 @@ class PDFXRef(PDFBaseXRef):
                 if use_b != b""n"":
                     continue
                 self.offsets[objid] = (None, int(pos_b), int(genno_b))
-        log.debug(""xref objects: %r"", self.offsets)
+        # log.debug(""xref objects: %r"", self.offsets)
         self.load_trailer(parser)
 
     def load_trailer(self, parser: PDFParser) -> None:
@@ -185,7 +185,7 @@ class PDFXRef(PDFBaseXRef):
                 raise PDFNoValidXRef(""Unexpected EOF - file corrupted"")
             (_, dic) = x[0]
         self.trailer.update(dict_value(dic))
-        log.debug(""trailer=%r"", self.trailer)
+        # log.debug(""trailer=%r"", self.trailer)
 
     def get_trailer(self) -> Dict[str, Any]:
         return self.trailer
@@ -213,7 +213,7 @@ class PDFXRefFallback(PDFXRef):
             if line_bytes.startswith(b""trailer""):
                 parser.seek(pos)
                 self.load_trailer(parser)
-                log.debug(""trailer: %r"", self.trailer)
+                # log.debug(""trailer: %r"", self.trailer)
                 break
             line = line_bytes.decode(""latin-1"")  # default pdf encoding
             m = self.PDFOBJ_CUE.match(line)
@@ -277,13 +277,13 @@ class PDFXRefStream(PDFBaseXRef):
         self.data = stream.get_data()
         self.entlen = self.fl1 + self.fl2 + self.fl3
         self.trailer = stream.attrs
-        log.debug(
-            ""xref stream: objid=%s, fields=%d,%d,%d"",
-            "", "".join(map(repr, self.ranges)),
-            self.fl1,
-            self.fl2,
-            self.fl3,
-        )
+        # log.debug(
+        #     ""xref stream: objid=%s, fields=%d,%d,%d"",
+        #     "", "".join(map(repr, self.ranges)),
+        #     self.fl1,
+        #     self.fl2,
+        #     self.fl3,
+        # )
 
     def get_trailer(self) -> Dict[str, Any]:
         return self.trailer
@@ -835,7 +835,7 @@ class PDFDocument:
         """"""
         if not self.xrefs:
             raise PDFException(""PDFDocument is not initialized"")
-        log.debug(""getobj: objid=%r"", objid)
+        # log.debug(""getobj: objid=%r"", objid)
         if objid in self._cached_objs:
             (obj, genno) = self._cached_objs[objid]
         else:
@@ -860,7 +860,7 @@ class PDFDocument:
                     continue
             else:
                 raise PDFObjectNotFound(objid)
-            log.debug(""register: objid=%r: %r"", objid, obj)
+            # log.debug(""register: objid=%r: %r"", objid, obj)
             if self.caching:
                 self._cached_objs[objid] = (obj, genno)
         return obj
@@ -953,10 +953,10 @@ class PDFDocument:
         prev = b""""
         for line in parser.revreadlines():
             line = line.strip()
-            log.debug(""find_xref: %r"", line)
+            # log.debug(""find_xref: %r"", line)
 
             if line == b""startxref"":
-                log.debug(""xref found: pos=%r"", prev)
+                # log.debug(""xref found: pos=%r"", prev)
 
                 if not prev.isdigit():
                     raise PDFNoValidXRef(f""Invalid xref position: {prev!r}"")
@@ -987,7 +987,7 @@ class PDFDocument:
             (pos, token) = parser.nexttoken()
         except PSEOF:
             raise PDFNoValidXRef(""Unexpected EOF"")
-        log.debug(""read_xref_from: start=%d, token=%r"", start, token)
+        # log.debug(""read_xref_from: start=%d, token=%r"", start, token)
         if isinstance(token, int):
             # XRefStream: PDF-1.5
             parser.seek(pos)
@@ -1001,7 +1001,7 @@ class PDFDocument:
             xref.load(parser)
         xrefs.append(xref)
         trailer = xref.get_trailer()
-        log.debug(""trailer: %r"", trailer)
+        # log.debug(""trailer: %r"", trailer)
         if ""XRefStm"" in trailer:
             pos = int_value(trailer[""XRefStm""])
             self.read_xref_from(parser, pos, xrefs)
",add more info about the xrefs,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdffont.py,"@@ -141,7 +141,8 @@ class Type1FontHeaderParser(PSStackParser[int]):
             try:
                 self._cid2unicode[cid] = name2unicode(cast(str, name))
             except KeyError as e:
-                log.debug(str(e))
+                # log.debug(str(e))
+                pass
         return self._cid2unicode
 
     def do_keyword(self, pos: int, token: PSKeyword) -> None:
",fix type1fontheaderparser,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdfinterp.py,"@@ -207,7 +207,7 @@ class PDFResourceManager:
         if objid and objid in self._cached_fonts:
             font = self._cached_fonts[objid]
         else:
-            log.debug(""get_font: create: objid=%r, spec=%r"", objid, spec)
+            # log.debug(""get_font: create: objid=%r, spec=%r"", objid, spec)
             if settings.STRICT:
                 if spec[""Type""] is not LITERAL_FONT:
                     raise PDFFontError(""Type is not /Font"")
@@ -394,7 +394,7 @@ class PDFPageInterpreter:
                 return PREDEFINED_COLORSPACE.get(name)
 
         for k, v in dict_value(resources).items():
-            log.debug(""Resource: %r: %r"", k, v)
+            # log.debug(""Resource: %r: %r"", k, v)
             if k == ""Font"":
                 for fontid, spec in dict_value(v).items():
                     objid = None
@@ -929,7 +929,7 @@ class PDFPageInterpreter:
             if settings.STRICT:
                 raise PDFInterpreterError(""Undefined xobject id: %r"" % xobjid)
             return
-        log.debug(""Processing xobj: %r"", xobj)
+        # log.debug(""Processing xobj: %r"", xobj)
         subtype = xobj.get(""Subtype"")
         if subtype is LITERAL_FORM and ""BBox"" in xobj:
             interpreter = self.dup()
@@ -959,7 +959,7 @@ class PDFPageInterpreter:
             pass
 
     def process_page(self, page: PDFPage) -> None:
-        log.debug(""Processing page: %r"", page)
+        # log.debug(""Processing page: %r"", page)
         (x0, y0, x1, y1) = page.mediabox
         if page.rotate == 90:
             ctm = (0, -1, 1, 0, -y0, x1)
@@ -990,12 +990,12 @@ class PDFPageInterpreter:
 
         This method may be called recursively.
         """"""
-        log.debug(
-            ""render_contents: resources=%r, streams=%r, ctm=%r"",
-            resources,
-            streams,
-            ctm,
-        )
+        # log.debug(
+        #     ""render_contents: resources=%r, streams=%r, ctm=%r"",
+        #     resources,
+        #     streams,
+        #     ctm,
+        # )
         self.init_resources(resources)
         self.init_state(ctm)
         return self.execute(list_value(streams))
@@ -1023,14 +1023,14 @@ class PDFPageInterpreter:
                     nargs = func.__code__.co_argcount - 1
                     if nargs:
                         args = self.pop(nargs)
-                        log.debug(""exec: %s %r"", name, args)
+                        # log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
                             if not name in ['TJ','Tj','Tm','Td','Tf','BT','ET','l']:
                                 p="" "".join([str(x).replace(""\'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
-                        log.debug(""exec: %s"", name)
+                        # log.debug(""exec: %s"", name)
                         func()
                         ops+=f'{name} '
                 elif settings.STRICT:
",add more info to the font manager,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdfpage.py,"@@ -126,12 +126,12 @@ class PDFPage:
                 object_type = object_properties.get(""type"")
 
             if object_type is LITERAL_PAGES and ""Kids"" in object_properties:
-                log.debug(""Pages: Kids=%r"", object_properties[""Kids""])
+                # log.debug(""Pages: Kids=%r"", object_properties[""Kids""])
                 for child in list_value(object_properties[""Kids""]):
                     yield from depth_first_search(child, object_properties, visited)
 
             elif object_type is LITERAL_PAGE:
-                log.debug(""Page: %r"", object_properties)
+                # log.debug(""Page: %r"", object_properties)
                 yield (object_id, object_properties)
 
         try:
",add depth first search for literal pages,
ac2e14192cdfee974bf8333688270c24453a8ebe,pdfparser.py,"@@ -113,13 +113,13 @@ class PDFParser(PSStackParser[Union[PSKeyword, PDFStream, PDFObjRef, None]]):
                     data += line
             self.seek(pos + objlen)
             # XXX limit objlen not to exceed object boundary
-            log.debug(
-                ""Stream: pos=%d, objlen=%d, dic=%r, data=%r..."",
-                pos,
-                objlen,
-                dic,
-                data[:10],
-            )
+            # log.debug(
+            #     ""Stream: pos=%d, objlen=%d, dic=%r, data=%r..."",
+            #     pos,
+            #     objlen,
+            #     dic,
+            #     data[:10],
+            # )
             assert self.doc is not None
             stream = PDFStream(dic, bytes(data), self.doc.decipher)
             self.push((pos, stream))
",add debug statements to parse stream,
ac2e14192cdfee974bf8333688270c24453a8ebe,psparser.py,"@@ -188,12 +188,12 @@ class PSBaseParser:
         if not pos:
             pos = self.bufpos + self.charpos
         self.fp.seek(pos)
-        log.debug(""poll(%d): %r"", pos, self.fp.read(n))
+        # log.debug(""poll(%d): %r"", pos, self.fp.read(n))
         self.fp.seek(pos0)
 
     def seek(self, pos: int) -> None:
         """"""Seeks the parser to the given position.""""""
-        log.debug(""seek: %r"", pos)
+        # log.debug(""seek: %r"", pos)
         self.fp.seek(pos)
         # reset the status for nextline()
         self.bufpos = pos
@@ -240,7 +240,7 @@ class PSBaseParser:
             else:
                 linebuf += self.buf[self.charpos :]
                 self.charpos = len(self.buf)
-        log.debug(""nextline: %r, %r"", linepos, linebuf)
+        # log.debug(""nextline: %r, %r"", linepos, linebuf)
 
         return (linepos, linebuf)
 
@@ -506,7 +506,7 @@ class PSBaseParser:
             self.fillbuf()
             self.charpos = self._parse1(self.buf, self.charpos)
         token = self._tokens.pop(0)
-        log.debug(""nexttoken: %r"", token)
+        # log.debug(""nexttoken: %r"", token)
         return token
 
 
@@ -550,23 +550,23 @@ class PSStackParser(PSBaseParser, Generic[ExtraT]):
         return objs
 
     def add_results(self, *objs: PSStackEntry[ExtraT]) -> None:
-        try:
-            log.debug(""add_results: %r"", objs)
-        except Exception:
-            log.debug(""add_results: (unprintable object)"")
+        # try:
+        #     log.debug(""add_results: %r"", objs)
+        # except Exception:
+        #     log.debug(""add_results: (unprintable object)"")
         self.results.extend(objs)
 
     def start_type(self, pos: int, type: str) -> None:
         self.context.append((pos, self.curtype, self.curstack))
         (self.curtype, self.curstack) = (type, [])
-        log.debug(""start_type: pos=%r, type=%r"", pos, type)
+        # log.debug(""start_type: pos=%r, type=%r"", pos, type)
 
     def end_type(self, type: str) -> Tuple[int, List[PSStackType[ExtraT]]]:
         if self.curtype != type:
             raise PSTypeError(f""Type mismatch: {self.curtype!r} != {type!r}"")
         objs = [obj for (_, obj) in self.curstack]
         (pos, self.curtype, self.curstack) = self.context.pop()
-        log.debug(""end_type: pos=%r, type=%r, objs=%r"", pos, type, objs)
+        # log.debug(""end_type: pos=%r, type=%r, objs=%r"", pos, type, objs)
         return (pos, objs)
 
     def do_keyword(self, pos: int, token: PSKeyword) -> None:
@@ -626,12 +626,12 @@ class PSStackParser(PSBaseParser, Generic[ExtraT]):
                     if settings.STRICT:
                         raise
             elif isinstance(token, PSKeyword):
-                log.debug(
-                    ""do_keyword: pos=%r, token=%r, stack=%r"",
-                    pos,
-                    token,
-                    self.curstack,
-                )
+                # log.debug(
+                #     ""do_keyword: pos=%r, token=%r, stack=%r"",
+                #     pos,
+                #     token,
+                #     self.curstack,
+                # )
                 if token.name==b'endobj':
                     end=pos+7
                 self.do_keyword(pos, token)
@@ -649,8 +649,8 @@ class PSStackParser(PSBaseParser, Generic[ExtraT]):
             else:
                 self.flush()
         obj = self.results.pop(0)
-        try:
-            log.debug(""nextobject: %r"", obj)
-        except Exception:
-            log.debug(""nextobject: (unprintable object)"")
+        # try:
+        #     log.debug(""nextobject: %r"", obj)
+        # except Exception:
+        #     log.debug(""nextobject: (unprintable object)"")
         return end,obj
",add more info to parser classes,
72320d7ae381a3ba795ab0bbdb9c0c30ef5e7807,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.5""
+__version__ = ""1.0.6""
 __author__ = ""Byaidu""
",update version,
72320d7ae381a3ba795ab0bbdb9c0c30ef5e7807,converter.py,"@@ -504,6 +504,8 @@ class TextConverter(PDFConverter[AnyIO]):
                                 fix=var[vid][0].size*0.85
                             if re.match(r'.*\+(CMR.*)',var[vid][0].fontname) and var[vid][0].cid in [94,126]: # 特殊上标
                                 fix=var[vid][0].size*0.25
+                            if re.match(r'.*\+(CM.*)7',var[vid][0].fontname): # 修正分式
+                                fix=var[vid][0].size*0.55
                         for vch in var[vid]:
                             vc=chr(vch.cid) # vch.get_text()
                             vc=vc.replace('\\','\\0134')
",add support for 修正分式,
71e207385a1ecd46c841ffb736b758f605f1e48c,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.6""
+__version__ = ""1.0.7""
 __author__ = ""Byaidu""
",update version,
71e207385a1ecd46c841ffb736b758f605f1e48c,converter.py,"@@ -369,7 +369,10 @@ class TextConverter(PDFConverter[AnyIO]):
             ops=""""
             def vflag(fontname): # 匹配公式（和角标）字体
                 return re.match(r'.*\+(CM.*|MS.*|.*0700|.*0500)',fontname)
-            for child in item:
+            ptr=0
+            item=list(item)
+            while ptr<len(item):
+                child=item[ptr]
                 if isinstance(child, LTChar):
                     if not vflag(child.fontname) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
@@ -416,6 +419,20 @@ class TextConverter(PDFConverter[AnyIO]):
                             pstk[-1][5]=child.font
                     else: # 公式入栈
                         vstk.append(child)
+                        if re.match(r'.*\+(CMEX.*)',child.fontname) and child.cid in [40]: # 大括号
+                            # ops+=f""ET q 1 0 0 1 0 {child.y0} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
+                            # ops+=f""ET q 1 0 0 1 0 {child.y0-child.size*3} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
+                            while ptr+1<len(item):
+                                child_=item[ptr+1]
+                                if isinstance(child_, LTChar):
+                                    # print(child_.y0,child.y0-child.size*3,child_.y1,child.y0)
+                                    if child_.y0>child.y0-child.size*3 and child_.y1<child.y0:
+                                        vstk.append(child_)
+                                    else:
+                                        break
+                                elif isinstance(child_, LTLine): # 线条
+                                    vlstk.append(child_)
+                                ptr+=1
                     xt=child
                     # 更新左右边界
                     if child.x0<lt.x0:
@@ -428,13 +445,14 @@ class TextConverter(PDFConverter[AnyIO]):
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
                 elif isinstance(child, LTLine): # 线条
-                    if vstk: # 公式环境
+                    if vstk and child.x1-child.x0<ltpage.width/3: # 公式环境
                         vlstk.append(child)
                     else:
                         lstk.append(child)
                 else:
                     # print(child)
                     pass
+                ptr+=1
             log.debug('\n==========[VSTACK]==========\n')
             for id,v in enumerate(var):
                 l=v[-1].x1-v[0].x0
",add vflag to text converter,
880af44a509e462af7df5927ca506e1066a020b4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.8""
+__version__ = ""1.0.9""
 __author__ = ""Byaidu""
",update version,
880af44a509e462af7df5927ca506e1066a020b4,converter.py,"@@ -368,7 +368,7 @@ class TextConverter(PDFConverter[AnyIO]):
             vlen=[]
             ops=""""
             def vflag(fontname): # 匹配公式（和角标）字体
-                return re.match(r'.*\+(CM.*|MS.*|.*0700|.*0500)',fontname)
+                return re.match(r'.*\+(CM.*|MS.*|XY.*|.*0700|.*0500)',fontname)
             ptr=0
             item=list(item)
             while ptr<len(item):
@@ -383,7 +383,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             vstk=[]
                             vlstk=[]
                     if not vstk: # 非公式或是公式开头
-                        if xt and child.y1 >= xt.y0 - child.size*0.6:
+                        if xt and child.y1 > xt.y0 - child.size*0.6 and child.y0 < xt.y1:
                             if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
                                 lt,rt=child,child
                                 sstk.append("""")
@@ -455,7 +455,7 @@ class TextConverter(PDFConverter[AnyIO]):
                 ptr+=1
             log.debug('\n==========[VSTACK]==========\n')
             for id,v in enumerate(var):
-                l=v[-1].x1-v[0].x0
+                l=max([vch.x1 for vch in v])-v[0].x0
                 log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
                 vlen.append(l)
             log.debug('\n==========[SSTACK]==========\n')
",add vstack to text converter,
7c1d1b8112b3d94bf4c99b173eb636139ba18d27,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.0.9""
+__version__ = ""1.1.0""
 __author__ = ""Byaidu""
",update version,
7c1d1b8112b3d94bf4c99b173eb636139ba18d27,converter.py,"@@ -383,7 +383,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             vstk=[]
                             vlstk=[]
                     if not vstk: # 非公式或是公式开头
-                        if xt and child.y1 > xt.y0 - child.size*0.6 and child.y0 < xt.y1:
+                        if xt and child.y1 > xt.y0 - child.size*0.6 and child.y0 < pstk[-1][0]+pstk[-1][4]:
                             if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
                                 lt,rt=child,child
                                 sstk.append("""")
",add support for text converter with vlstk,
45685b5b8c7ff96116430f43921e02492a5d1720,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.0""
+__version__ = ""1.1.1""
 __author__ = ""Byaidu""
",update version,
fee8f64736e4ba423074e717c474a91ff31323db,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.1""
+__version__ = ""1.1.2""
 __author__ = ""Byaidu""
",update version,
fee8f64736e4ba423074e717c474a91ff31323db,pdf2zh.py,"@@ -68,24 +68,23 @@ def extract_text(
         filename = os.path.splitext(os.path.basename(file))[0]
 
         doc_en = pymupdf.open(file)
+        page_count=doc_en.page_count
         for page in doc_en:
             page.insert_font('china-ss')
         doc_en.save('output-en.pdf')
-        page_count=doc_en.page_count
+        doc_en.close()
 
         # for fname in files:
         with open('output-en.pdf', ""rb"") as fp:
             pdf2zh.high_level.extract_text_to_fp(fp, **locals())
 
         doc_zh = pymupdf.open('output-zh.pdf')
-        doc_dual = pymupdf.open()
-        doc_dual.insert_file(doc_en)
+        doc_dual = pymupdf.open('output-en.pdf')
         doc_dual.insert_file(doc_zh)
         for id in range(page_count):
             doc_dual.move_page(page_count+id,id*2+1)
-        doc_zh.save(f'{filename}-zh.pdf',deflate=1,)
+        doc_zh.save(f'{filename}-zh.pdf',deflate=1)
         doc_dual.save(f'{filename}-dual.pdf',deflate=1)
-        doc_en.close()
         doc_zh.close()
         doc_dual.close()
 
",add examples for extract_text,
644fb242301c97984434c0908c22e1d281cac6b4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.2""
+__version__ = ""1.1.3""
 __author__ = ""Byaidu""
",update version,
644fb242301c97984434c0908c22e1d281cac6b4,converter.py,"@@ -49,7 +49,7 @@ from pdf2zh.layout import (
 from pdf2zh.pdfcolor import PDFColorSpace
 from pdf2zh.pdfdevice import PDFTextDevice
 from pdf2zh.pdfexceptions import PDFValueError
-from pdf2zh.pdffont import PDFFont, PDFUnicodeNotDefined
+from pdf2zh.pdffont import PDFFont, PDFUnicodeNotDefined, PDFCIDFont
 from pdf2zh.pdfinterp import PDFGraphicState, PDFResourceManager
 from pdf2zh.pdfpage import PDFPage
 from pdf2zh.pdftypes import PDFStream
@@ -341,10 +341,16 @@ class TextConverter(PDFConverter[AnyIO]):
         laparams: Optional[LAParams] = None,
         showpageno: bool = False,
         imagewriter: Optional[ImageWriter] = None,
+        vfont: str = None,
+        vchar: str = None,
+        thread: int = 0,
     ) -> None:
         super().__init__(rsrcmgr, outfp, codec=codec, pageno=pageno, laparams=laparams)
         self.showpageno = showpageno
         self.imagewriter = imagewriter
+        self.vfont = vfont
+        self.vchar = vchar
+        self.thread=thread
 
     def write_text(self, text: str) -> None:
         text = utils.compatible_encode_method(text, self.codec, ""ignore"")
@@ -367,14 +373,17 @@ class TextConverter(PDFConverter[AnyIO]):
             varl=[]
             vlen=[]
             ops=""""
-            def vflag(fontname): # 匹配公式（和角标）字体
-                return re.match(r'.*\+(CM.*|MS.*|XY.*|.*0700|.*0500)',fontname)
+            def vflag(font,char): # 匹配公式（和角标）字体
+                if self.vfont:
+                    return re.match(self.vfont,font) or (self.vchar and re.match(self.vchar,char))
+                else:
+                    return re.match(r'.*\+(CM.*|MS.*|XY.*|.*0700|.*0500)',font)
             ptr=0
             item=list(item)
             while ptr<len(item):
                 child=item[ptr]
                 if isinstance(child, LTChar):
-                    if not vflag(child.fontname) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
+                    if ptr==len(item)-1 or not vflag(child.fontname,child.get_text()) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk[-1]+=f'$v{len(var)}$'
                             # print(f'$v{len(var)}$',end='')
@@ -382,6 +391,9 @@ class TextConverter(PDFConverter[AnyIO]):
                             varl.append(vlstk)
                             vstk=[]
                             vlstk=[]
+                            if ptr==len(item)-1 and vflag(child.fontname,child.get_text()):
+                                var[-1].append(child)
+                                break
                     if not vstk: # 非公式或是公式开头
                         if xt and child.y1 > xt.y0 - child.size*0.6 and child.y0 < pstk[-1][0]+pstk[-1][4]:
                             if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
@@ -412,10 +424,10 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                             # print(f'\n\n[TEXT C] {(child.y0,child.x0,child.size)}')
-                    if not vflag(child.fontname): # 文字入栈
+                    if not vflag(child.fontname,child.get_text()): # 文字入栈
                         sstk[-1]+=child.get_text()
                         # print(child.get_text(),end='')
-                        if vflag(pstk[-1][5].fontname): # 公式开头，后续接文字，需要校正字体
+                        if vflag(pstk[-1][5].fontname,''): # 公式开头，后续接文字，需要校正字体
                             pstk[-1][5]=child.font
                     else: # 公式入栈
                         vstk.append(child)
@@ -465,20 +477,29 @@ class TextConverter(PDFConverter[AnyIO]):
             cache.create_cache(hash_key)
             @retry
             def worker(s): # 多线程翻译
-                if re.search('[A-Za-z]',s):
-                    hash_key_paragraph = cache.deterministic_hash(s)
-                    new = cache.load_paragraph(hash_key, hash_key_paragraph)
-                    if new is None:
-                        new=translator.translate(s,'zh-CN','en')
-                        new=remove_control_characters(new)
-                        cache.write_paragraph(hash_key, hash_key_paragraph, new)
-                else:
-                    new=s
-                return new
+                try:
+                    if re.search('[A-Za-z]',s):
+                        hash_key_paragraph = cache.deterministic_hash(s)
+                        new = cache.load_paragraph(hash_key, hash_key_paragraph)
+                        if new is None:
+                            new=translator.translate(s,'zh-CN','en')
+                            new=remove_control_characters(new)
+                            cache.write_paragraph(hash_key, hash_key_paragraph, new)
+                    else:
+                        new=s
+                    return new
+                except BaseException as e:
+                    log.exception(e,exc_info=False)
+                    raise e
             # tqdm with concurrent.futures.ThreadPoolExecutor()
-            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
+            with concurrent.futures.ThreadPoolExecutor(max_workers=self.thread) as executor:
                 # news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk), position=1))
                 news = list(executor.map(worker, sstk))
+            def raw_string(fcur,cstk):
+                if isinstance(self.fontmap[fcur],PDFCIDFont):
+                    return """".join([""%04x"" % ord(c) for c in cstk])
+                else:
+                    return """".join([""%02x"" % ord(c) for c in cstk])
             for id,new in enumerate(news):
                 x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
                 tx=x
@@ -487,7 +508,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if ptr==len(new): # 到达段落结尾
                         if cstk:
                             # print(cstk,tx,x,rt,y)
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ '
+                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
                     vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
                     if vy_regex: # 加载公式
@@ -506,7 +527,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if fcur_!=fcur or vy_regex or x+adv>rt: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
                         if cstk:
                             # print(cstk,tx,x,rt,y)
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{"""".join([""%04x"" % ord(c) for c in cstk])}>] TJ '
+                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                             cstk=''
                     if lb and x+adv>rt: # 到达右边界且原文段落存在换行
                         x=lt
@@ -514,7 +535,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正
-                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112]: # 根式与大小求和
+                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112,33]: # 根式、积分与大小求和
                                 fix=var[vid][0].size*0.85
                             if re.match(r'.*\+(CMSY.*)',var[vid][0].fontname) and var[vid][0].cid in [112]: # 根式
                                 fix=var[vid][0].size*0.85
@@ -525,11 +546,8 @@ class TextConverter(PDFConverter[AnyIO]):
                             if re.match(r'.*\+(CM.*)7',var[vid][0].fontname): # 修正分式
                                 fix=var[vid][0].size*0.55
                         for vch in var[vid]:
-                            vc=chr(vch.cid) # vch.get_text()
-                            vc=vc.replace('\\','\\0134')
-                            vc=vc.replace('(','\\050')
-                            vc=vc.replace(')','\\051')
-                            ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm ({vc}) Tj ""
+                            vc=chr(vch.cid)
+                            ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
                             # print(vc,vch,vch.x0,vch.x1,vch.y0,vch.y1)
                         for l in varl[vid]:
                             ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
",add docstrings for text converter,
644fb242301c97984434c0908c22e1d281cac6b4,high_level.py,"@@ -40,6 +40,9 @@ def extract_text_to_fp(
     debug: bool = False,
     disable_caching: bool = False,
     page_count: int = 0,
+    vfont: str = """",
+    vchar: str = """",
+    thread: int = 0,
     **kwargs: Any,
 ) -> None:
     """"""Parses text from inf-file and writes to outfp file-like object.
@@ -91,6 +94,9 @@ def extract_text_to_fp(
             codec=codec,
             laparams=laparams,
             imagewriter=imagewriter,
+            vfont=vfont,
+            vchar=vchar,
+            thread=thread,
         )
 
     elif output_type == ""xml"":
",add missing docstring,
644fb242301c97984434c0908c22e1d281cac6b4,pdf2zh.py,"@@ -45,6 +45,9 @@ def extract_text(
     output_dir: Optional[str] = None,
     debug: bool = False,
     disable_caching: bool = False,
+    vfont: str = """",
+    vchar: str = """",
+    thread: int = 0,
     **kwargs: Any,
 ) -> AnyIO:
     if not files:
@@ -104,12 +107,12 @@ def create_parser() -> argparse.ArgumentParser:
         help=""One or more paths to PDF files."",
     )
 
-    # parser.add_argument(
-    #     ""--version"",
-    #     ""-v"",
-    #     action=""version"",
-    #     version=f""pdf2zh.six v{pdf2zh.__version__}"",
-    # )
+    parser.add_argument(
+        ""--version"",
+        ""-v"",
+        action=""version"",
+        version=f""pdf2zh v{pdf2zh.__version__}"",
+    )
     parser.add_argument(
         ""--debug"",
         ""-d"",
@@ -131,6 +134,7 @@ def create_parser() -> argparse.ArgumentParser:
     )
     parse_params.add_argument(
         ""--page-numbers"",
+        ""-p"",
         type=int,
         default=None,
         nargs=""+"",
@@ -158,6 +162,27 @@ def create_parser() -> argparse.ArgumentParser:
         default="""",
         help=""The password to use for decrypting PDF file."",
     )
+    parse_params.add_argument(
+        ""--vfont"",
+        ""-f"",
+        type=str,
+        default="""",
+        help=""The regex to math font name of formula."",
+    )
+    parse_params.add_argument(
+        ""--vchar"",
+        ""-c"",
+        type=str,
+        default="""",
+        help=""The regex to math character of formula."",
+    )
+    parse_params.add_argument(
+        ""--thread"",
+        ""-t"",
+        type=int,
+        default=4,
+        help=""The number of threads to execute translation."",
+    )
     # parse_params.add_argument(
     #     ""--rotation"",
     #     ""-R"",
",add support for --version and --page-numbers,
644fb242301c97984434c0908c22e1d281cac6b4,pdfinterp.py,"@@ -974,7 +974,7 @@ class PDFPageInterpreter:
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
         page_objid=page.contents[0].objid
-        ops_full=f'{page_objid} 0 obj\n<<>>stream\n{ops_base}{ops_new}\nendstream\nendobj\n'
+        ops_full=f'{page_objid} 0 obj\n<<>>stream\n{ops_new}{ops_base}\nendstream\nendobj\n' # ops_base 可能有副作用，所以先输出 ops_new
         # print('OP_BASE',ops_base)
         # print('OP_NEW',ops_new)
         # print('OP_FULL',ops_full)
@@ -1026,7 +1026,7 @@ class PDFPageInterpreter:
                         # log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
-                            if not name in ['TJ','Tj','Tm','Td','Tf','BT','ET','l']:
+                            if not name in ['TJ','Tj','Tm','Tf','l']:
                                 p="" "".join([str(x).replace(""\'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
",add more info to the pageinterpreter,
0cdec984236981a43823129143baea93fe44b5e0,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.3""
+__version__ = ""1.1.4""
 __author__ = ""Byaidu""
",update version,
0cdec984236981a43823129143baea93fe44b5e0,converter.py,"@@ -501,8 +501,8 @@ class TextConverter(PDFConverter[AnyIO]):
                 else:
                     return """".join([""%02x"" % ord(c) for c in cstk])
             for id,new in enumerate(news):
-                x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
-                tx=x
+                tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
+                log.debug(f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}"")
                 while True:
                     # print(new,ptr)
                     if ptr==len(new): # 到达段落结尾
@@ -514,7 +514,10 @@ class TextConverter(PDFConverter[AnyIO]):
                     if vy_regex: # 加载公式
                         vid=int(vy_regex.group(1).replace(' ',''))
                         ptr+=len(vy_regex.group(0))
-                        adv=vlen[vid]
+                        if vid<len(vlen):
+                            adv=vlen[vid]
+                        else:
+                            continue # 翻译器可能会自动补个越界的公式标记
                     else: # 加载文字
                         ch=new[ptr]
                         # cid=self.china.decode(ch.encode())
@@ -535,7 +538,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正
-                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112,33]: # 根式、积分与大小求和
+                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112,33,82]: # 根式、积分与大小求和
                                 fix=var[vid][0].size*0.85
                             if re.match(r'.*\+(CMSY.*)',var[vid][0].fontname) and var[vid][0].cid in [112]: # 根式
                                 fix=var[vid][0].size*0.85
@@ -563,7 +566,6 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk+=ch
                     fcur=fcur_
                     x+=adv
-                log.debug(f""< {' '.join([f'{j:.1f}' for j in pstk[id][:5]])} {pstk[id][5].fontname} {pstk[id][6]} > {new}"")
             for l in lstk:
                 ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                 pass
",add support for 加载公式标记,
0cdec984236981a43823129143baea93fe44b5e0,pdfinterp.py,"@@ -265,7 +265,8 @@ class PDFContentParser(PSStackParser[Union[PSKeyword, PDFStream]]):
             else:
                 raise PSEOF(""Unexpected EOF, file truncated?"")
             self.fp = BytesIO(strm.get_data())
-            # print('STREAM DATA',strm.get_data())
+            if log.isEnabledFor(logging.DEBUG):
+                log.debug(f'STREAM DATA {strm.get_data()}')
 
     def seek(self, pos: int) -> None:
         self.fillfp()
@@ -683,7 +684,9 @@ class PDFPageInterpreter:
             if settings.STRICT:
                 raise PDFInterpreterError(""No colorspace specified!"")
             n = 1
-        self.graphicstate.scolor = cast(Color, self.pop(n))
+        args=self.pop(n)
+        self.graphicstate.scolor = cast(Color, args)
+        return args
 
     def do_scn(self) -> None:
         """"""Set color for nonstroking operations""""""
@@ -693,15 +696,17 @@ class PDFPageInterpreter:
             if settings.STRICT:
                 raise PDFInterpreterError(""No colorspace specified!"")
             n = 1
-        self.graphicstate.ncolor = cast(Color, self.pop(n))
+        args=self.pop(n)
+        self.graphicstate.ncolor = cast(Color, args)
+        return args
 
     def do_SC(self) -> None:
         """"""Set color for stroking operations""""""
-        self.do_SCN()
+        return self.do_SCN()
 
     def do_sc(self) -> None:
         """"""Set color for nonstroking operations""""""
-        self.do_scn()
+        return self.do_scn()
 
     def do_sh(self, name: object) -> None:
         """"""Paint area defined by shading pattern""""""
@@ -975,9 +980,10 @@ class PDFPageInterpreter:
         ops_new=self.device.end_page(page)
         page_objid=page.contents[0].objid
         ops_full=f'{page_objid} 0 obj\n<<>>stream\n{ops_new}{ops_base}\nendstream\nendobj\n' # ops_base 可能有副作用，所以先输出 ops_new
-        # print('OP_BASE',ops_base)
-        # print('OP_NEW',ops_new)
-        # print('OP_FULL',ops_full)
+        if log.isEnabledFor(logging.DEBUG):
+            log.debug(f'OP_BASE {ops_base}')
+            log.debug(f'OP_NEW {ops_new}')
+            log.debug(f'OP_FULL {ops_full}')
         return page_objid,ops_full
 
     def render_contents(
@@ -1031,8 +1037,11 @@ class PDFPageInterpreter:
                                 ops+=f'{p} {name} '
                     else:
                         # log.debug(""exec: %s"", name)
-                        func()
-                        ops+=f'{name} '
+                        targs=func()
+                        if targs==None:
+                            targs=[]
+                        p="" "".join([str(x).replace(""\'"","""") for x in targs])
+                        ops+=f'{p} {name} '
                 elif settings.STRICT:
                     error_msg = ""Unknown operator: %r"" % name
                     raise PDFInterpreterError(error_msg)
",add more documentation to the stream parser,
7eb54098c78579db96658688b74f1fdfb5f08e2d,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.4""
+__version__ = ""1.1.5""
 __author__ = ""Byaidu""
",update version,
7eb54098c78579db96658688b74f1fdfb5f08e2d,converter.py,"@@ -350,7 +350,7 @@ class TextConverter(PDFConverter[AnyIO]):
         self.imagewriter = imagewriter
         self.vfont = vfont
         self.vchar = vchar
-        self.thread=thread
+        self.thread = thread
 
     def write_text(self, text: str) -> None:
         text = utils.compatible_encode_method(text, self.codec, ""ignore"")
@@ -375,12 +375,17 @@ class TextConverter(PDFConverter[AnyIO]):
             ops=""""
             def vflag(font,char): # 匹配公式（和角标）字体
                 if self.vfont:
-                    return re.match(self.vfont,font) or (self.vchar and re.match(self.vchar,char))
+                    if re.match(self.vfont,font):
+                        return True
                 else:
-                    return re.match(r'.*\+(CM.*|MS.*|XY.*|.*0700|.*0500)',font)
+                    if re.match(r'.*\+(CM.*|MS.*|XY.*|.*0700|.*0500)',font):
+                        return True
+                if self.vchar and re.match(self.vchar,char):
+                    return True
+                return False
             ptr=0
             item=list(item)
-            while ptr<len(item):
+            while ptr<len(item): # 识别文字和公式
                 child=item[ptr]
                 if isinstance(child, LTChar):
                     if ptr==len(item)-1 or not vflag(child.fontname,child.get_text()) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
@@ -391,7 +396,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             varl.append(vlstk)
                             vstk=[]
                             vlstk=[]
-                            if ptr==len(item)-1 and vflag(child.fontname,child.get_text()):
+                            if ptr==len(item)-1 and vflag(child.fontname,child.get_text()): # 文档以公式结尾
                                 var[-1].append(child)
                                 break
                     if not vstk: # 非公式或是公式开头
@@ -436,13 +441,13 @@ class TextConverter(PDFConverter[AnyIO]):
                             # ops+=f""ET q 1 0 0 1 0 {child.y0-child.size*3} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
                             while ptr+1<len(item):
                                 child_=item[ptr+1]
-                                if isinstance(child_, LTChar):
+                                if isinstance(child_, LTChar): # 公式字符
                                     # print(child_.y0,child.y0-child.size*3,child_.y1,child.y0)
                                     if child_.y0>child.y0-child.size*3 and child_.y1<child.y0:
                                         vstk.append(child_)
                                     else:
                                         break
-                                elif isinstance(child_, LTLine): # 线条
+                                elif isinstance(child_, LTLine): # 公式线条
                                     vlstk.append(child_)
                                 ptr+=1
                     xt=child
@@ -457,9 +462,9 @@ class TextConverter(PDFConverter[AnyIO]):
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
                 elif isinstance(child, LTLine): # 线条
-                    if vstk and child.x1-child.x0<ltpage.width/3: # 公式环境
+                    if vstk and child.x1-child.x0<ltpage.width/3: # 公式线条
                         vlstk.append(child)
-                    else:
+                    else: # 全局线条
                         lstk.append(child)
                 else:
                     # print(child)
@@ -495,12 +500,12 @@ class TextConverter(PDFConverter[AnyIO]):
             with concurrent.futures.ThreadPoolExecutor(max_workers=self.thread) as executor:
                 # news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk), position=1))
                 news = list(executor.map(worker, sstk))
-            def raw_string(fcur,cstk):
+            def raw_string(fcur,cstk): # 编码字符串
                 if isinstance(self.fontmap[fcur],PDFCIDFont):
                     return """".join([""%04x"" % ord(c) for c in cstk])
                 else:
                     return """".join([""%02x"" % ord(c) for c in cstk])
-            for id,new in enumerate(news):
+            for id,new in enumerate(news): # 排版文字和公式
                 tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
                 log.debug(f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}"")
                 while True:
@@ -548,11 +553,11 @@ class TextConverter(PDFConverter[AnyIO]):
                                 fix=var[vid][0].size*0.25
                             if re.match(r'.*\+(CM.*)7',var[vid][0].fontname): # 修正分式
                                 fix=var[vid][0].size*0.55
-                        for vch in var[vid]:
+                        for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
                             ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
                             # print(vc,vch,vch.x0,vch.x1,vch.y0,vch.y1)
-                        for l in varl[vid]:
+                        for l in varl[vid]: # 排版公式线条
                             ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                             pass
                     else: # 插入文字缓冲区
@@ -566,7 +571,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk+=ch
                     fcur=fcur_
                     x+=adv
-            for l in lstk:
+            for l in lstk: # 排版全局线条
                 ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                 pass
             ops=f'BT {ops}ET '
",add support for vflag and vstk,
bfa0e93083c13540bc1ac90abd981e9fcc542451,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.5""
+__version__ = ""1.1.6""
 __author__ = ""Byaidu""
",update version,
bfa0e93083c13540bc1ac90abd981e9fcc542451,high_level.py,"@@ -148,8 +148,10 @@ def extract_text_to_fp(
         caching=not disable_caching,
     ), total=page_count, position=0):
         page.rotate = (page.rotate + rotation) % 360
-        page_objid,ops_full=interpreter.process_page(page)
-        obj_patch[page_objid]=ops_full
+        page_objids,ops_full=interpreter.process_page(page)
+        obj_patch[page_objids[0]]=ops_full
+        for objid in range(1,len(page_objids)):
+            obj_patch[page_objids[objid]]=f'{page_objids[objid]} 0 obj\n<<>>\nendobj\n'
 
     # 用最后一页的page来解析doc
     objs=[]
",add more comments,
bfa0e93083c13540bc1ac90abd981e9fcc542451,pdfinterp.py,"@@ -978,13 +978,13 @@ class PDFPageInterpreter:
         ops_base=self.render_contents(page.resources, page.contents, ctm=ctm)
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
-        page_objid=page.contents[0].objid
-        ops_full=f'{page_objid} 0 obj\n<<>>stream\n{ops_new}{ops_base}\nendstream\nendobj\n' # ops_base 可能有副作用，所以先输出 ops_new
+        page_objids=[i.objid for i in page.contents]
+        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\n{ops_new}{ops_base}\nendstream\nendobj\n' # ops_base 可能有副作用，所以先输出 ops_new
         if log.isEnabledFor(logging.DEBUG):
             log.debug(f'OP_BASE {ops_base}')
             log.debug(f'OP_NEW {ops_new}')
             log.debug(f'OP_FULL {ops_full}')
-        return page_objid,ops_full
+        return page_objids,ops_full
 
     def render_contents(
         self,
",add debug log,
f511dfddab973e911fcb4003ea6b242ebde84d4e,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.6""
+__version__ = ""1.1.7""
 __author__ = ""Byaidu""
",update version,
f511dfddab973e911fcb4003ea6b242ebde84d4e,converter.py,"@@ -483,7 +483,7 @@ class TextConverter(PDFConverter[AnyIO]):
             @retry
             def worker(s): # 多线程翻译
                 try:
-                    if re.search('[A-Za-z]',s):
+                    if re.search('[a-z]',s):
                         hash_key_paragraph = cache.deterministic_hash(s)
                         new = cache.load_paragraph(hash_key, hash_key_paragraph)
                         if new is None:
@@ -529,7 +529,10 @@ class TextConverter(PDFConverter[AnyIO]):
                         if font.char_width(ord(ch)):
                             fcur_=font.fontid
                         else:
-                            fcur_='china-ss'
+                            if ch==' ':
+                                fcur_='helv' # 半角空格
+                            else:
+                                fcur_='china-ss'
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
","add support for -529,7 + 529,10",
f511dfddab973e911fcb4003ea6b242ebde84d4e,pdf2zh.py,"@@ -74,6 +74,7 @@ def extract_text(
         page_count=doc_en.page_count
         for page in doc_en:
             page.insert_font('china-ss')
+            page.insert_font('helv')
         doc_en.save('output-en.pdf')
         doc_en.close()
 
",update extract_text.py,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,README.md,"@@ -37,7 +37,7 @@ pdf2zh example.pdf
 ### 翻译部分文档
 
 ```bash
-pdf2zh example.pdf -p 1 2 3
+pdf2zh example.pdf -p 1-3,5
 ```
 
 ### 使用正则表达式指定需要保留样式的公式字体和字符
",add example for 使用正则表达式指定需要保留样式指定需要保留样式指定需要保留样式�,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.7""
+__version__ = ""1.1.8""
 __author__ = ""Byaidu""
",update version,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,converter.py,"@@ -400,7 +400,7 @@ class TextConverter(PDFConverter[AnyIO]):
                                 var[-1].append(child)
                                 break
                     if not vstk: # 非公式或是公式开头
-                        if xt and child.y1 > xt.y0 - child.size*0.6 and child.y0 < pstk[-1][0]+pstk[-1][4]:
+                        if xt and child.y1 > xt.y0 - child.size*0.5 and child.y0 < xt.y1 + child.size:
                             if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
                                 lt,rt=child,child
                                 sstk.append("""")
@@ -414,7 +414,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             elif child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
                                 # print(' ',end='')
-                            elif child.x0 < xt.x0:
+                            elif child.x1 < xt.x0: # 换行，这里需要考虑一下字母修饰符的情况
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
@@ -483,7 +483,7 @@ class TextConverter(PDFConverter[AnyIO]):
             @retry
             def worker(s): # 多线程翻译
                 try:
-                    if re.search('[a-z]',s):
+                    if sum(map(str.islower,s))>1:
                         hash_key_paragraph = cache.deterministic_hash(s)
                         new = cache.load_paragraph(hash_key, hash_key_paragraph)
                         if new is None:
",add more examples to text converter,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,high_level.py,"@@ -30,7 +30,7 @@ def extract_text_to_fp(
     codec: str = ""utf-8"",
     laparams: Optional[LAParams] = None,
     maxpages: int = 0,
-    page_numbers: Optional[Container[int]] = None,
+    pages: Optional[Container[int]] = None,
     password: str = """",
     scale: float = 1.0,
     rotation: int = 0,
@@ -140,13 +140,17 @@ def extract_text_to_fp(
     assert device is not None
     interpreter = PDFPageInterpreter(rsrcmgr, device)
     obj_patch={}
+    if pages:
+        total_pages=len(pages)
+    else:
+        total_pages=page_count
     for page in tqdm.auto.tqdm(PDFPage.get_pages(
         inf,
-        page_numbers,
+        pages,
         maxpages=maxpages,
         password=password,
         caching=not disable_caching,
-    ), total=page_count, position=0):
+    ), total=total_pages, position=0):
         page.rotate = (page.rotate + rotation) % 360
         page_objids,ops_full=interpreter.process_page(page)
         obj_patch[page_objids[0]]=ops_full
",add progress bar to extract_text_to_fp,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,pdf2zh.py,"@@ -37,7 +37,7 @@ def extract_text(
     codec: str = ""utf-8"",
     strip_control: bool = False,
     maxpages: int = 0,
-    page_numbers: Optional[Container[int]] = None,
+    pages: Optional[Container[int]] = None,
     password: str = """",
     scale: float = 1.0,
     rotation: int = 0,
@@ -134,12 +134,10 @@ def create_parser() -> argparse.ArgumentParser:
         description=""Used during PDF parsing"",
     )
     parse_params.add_argument(
-        ""--page-numbers"",
+        ""--pages"",
         ""-p"",
-        type=int,
-        default=None,
-        nargs=""+"",
-        help=""A space-seperated list of page numbers to parse."",
+        type=str,
+        help=""The list of page numbers to parse."",
     )
     # parse_params.add_argument(
     #     ""--pagenos"",
@@ -352,8 +350,15 @@ def parse_args(args: Optional[List[str]]) -> argparse.Namespace:
     #         all_texts=parsed_args.all_texts,
     #     )
 
-    if parsed_args.page_numbers:
-        parsed_args.page_numbers = {x - 1 for x in parsed_args.page_numbers}
+    if parsed_args.pages:
+        pages = []
+        for p in parsed_args.pages.split("",""):
+            if ""-"" in p:
+                start, end = p.split(""-"")
+                pages.extend(range(int(start) - 1, int(end)))
+            else:
+                pages.append(int(p) - 1)
+        parsed_args.pages = pages
 
     # if parsed_args.pagenos:
     #     parsed_args.page_numbers = {int(x) - 1 for x in parsed_args.pagenos.split("","")}
",add docstrings for pdf parser,
0dbce3437765fada2d1ce89a27faeda614ed9fa5,pdfinterp.py,"@@ -979,7 +979,7 @@ class PDFPageInterpreter:
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
-        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\n{ops_new}{ops_base}\nendstream\nendobj\n' # ops_base 可能有副作用，所以先输出 ops_new
+        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\n{ops_base}{ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面
         if log.isEnabledFor(logging.DEBUG):
             log.debug(f'OP_BASE {ops_base}')
             log.debug(f'OP_NEW {ops_new}')
",fix crash in pdfpageinterpreter,
fef0d1efe2e8e2e5754b72adae4e5f37e1390031,mfd-tf_efficientdet_d0.pth.tar,"Binary files a/model/mfd-tf_efficientdet_d0.pth.tar and /dev/null differ
",binary files,
fef0d1efe2e8e2e5754b72adae4e5f37e1390031,pdf2zh.py,"@@ -10,6 +10,8 @@ import sys
 from typing import Any, Container, Iterable, List, Optional
 import pymupdf
 import layoutparser as lp
+import tempfile
+import urllib.request
 
 import pdf2zh.high_level
 from pdf2zh.layout import LAParams
@@ -66,8 +68,11 @@ def extract_text(
     # else:
     #     outfp = open(outfile, ""wb"")
     outfp: AnyIO = sys.stdout
-
-    model = lp.AutoLayoutModel(""lp://efficientdet/MFD/tf_efficientdet_d0"")
+    pth = os.path.join(tempfile.gettempdir(), 'mfd-tf_efficientdet_d0.pth.tar')
+    if not os.path.exists(pth):
+        print('Downloading...')
+        urllib.request.urlretrieve(""https://www.dropbox.com/s/dkr22iux7thlhel/mfd-tf_efficientdet_d0.pth.tar?dl=1"",pth)
+    model = lp.EfficientDetLayoutModel(""lp://efficientdet/MFD/tf_efficientdet_d0"",pth)
 
     for file in files:
 
","add examples for -66,8 +68,11",
fef0d1efe2e8e2e5754b72adae4e5f37e1390031,setup.py,"@@ -24,6 +24,8 @@ setup(
         ""pymupdf"",
         ""tqdm"",
         ""tenacity"",
+        ""layoutparser"",
+        ""numpy"",
     ],
     classifiers=[
         ""Programming Language :: Python :: 3"",
",add missing package-info,
588de9f52201b6e00830788dd095c9769cf8db16,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.8""
+__version__ = ""1.1.9""
 __author__ = ""Byaidu""
",update version,
588de9f52201b6e00830788dd095c9769cf8db16,setup.py,"@@ -18,13 +18,13 @@ setup(
     url=""https://github.com/Byaidu/PDFMathTranslate"",
     packages=[""pdf2zh""],
     install_requires=[
-        ""charset-normalizer >= 2.0.0"",
-        ""cryptography >= 36.0.0"",
+        ""charset-normalizer"",
+        ""cryptography"",
         ""mtranslate"",
         ""pymupdf"",
         ""tqdm"",
         ""tenacity"",
-        ""layoutparser"",
+        ""layoutparser[effdet]"",
         ""numpy"",
     ],
     classifiers=[
",add missing setup.py,
d6b76bf1a56528ad6902a3f97bf54030693f1ff2,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.1.9""
+__version__ = ""1.2.0""
 __author__ = ""Byaidu""
",update version,
d6b76bf1a56528ad6902a3f97bf54030693f1ff2,converter.py,"@@ -377,12 +377,12 @@ class TextConverter(PDFConverter[AnyIO]):
             ops=""""
             def vflag(font,char): # 匹配公式（和角标）字体
                 if self.vfont:
-                    if re.search(self.vfont,font):
+                    if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.search(r'(CM|MS|XY|MT|BL|0700|0500|Italic)',font):
+                    if re.match(r'.*+(CM.*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)',font):
                         return True
-                if self.vchar and re.search(self.vchar,char):
+                if self.vchar and re.match(self.vchar,char):
                     return True
                 return False
             ptr=0
@@ -400,8 +400,8 @@ class TextConverter(PDFConverter[AnyIO]):
                         if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1:
                             cur_v=True
                             ind_v=True
-                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
-                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
+                            lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
+                            lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
                     if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
",add more support for vflag and vchar,
d18abc57f7fe9004ff385f2e407ab5784b016c0d,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.0""
+__version__ = ""1.2.1""
 __author__ = ""Byaidu""
",update version,
d18abc57f7fe9004ff385f2e407ab5784b016c0d,converter.py,"@@ -400,8 +400,8 @@ class TextConverter(PDFConverter[AnyIO]):
                         if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1:
                             cur_v=True
                             ind_v=True
-                            lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
-                            lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
+                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
+                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
                     if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
",add support for text converter in vgt,
953764773ee836a8f134dd957cac444205897a02,README.md,"@@ -45,7 +45,7 @@ pdf2zh example.pdf -p 1-3,5
 注：从 `\ufb00` 开始是英文风格连字
 
 ```bash
-pdf2zh BDA3.pdf -f "".*+(CM[^RT].*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\ufaff])""
+pdf2zh BDA3.pdf -f "".*\+(CM[^RT].*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\ufaff])""
 ```
 
 ## 致谢
",add examples for 开始是英文风格连字,
953764773ee836a8f134dd957cac444205897a02,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.1""
+__version__ = ""1.2.2""
 __author__ = ""Byaidu""
",update version,
953764773ee836a8f134dd957cac444205897a02,converter.py,"@@ -380,7 +380,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'.*+(CM.*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)',font):
+                    if re.match(r'.*\+(CM.*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)',font):
                         return True
                 if self.vchar and re.match(self.vchar,char):
                     return True
@@ -393,9 +393,9 @@ class TextConverter(PDFConverter[AnyIO]):
                 if isinstance(child, LTChar):
                     cur_v=False
                     ind_v=False
-                    if vflag(child.fontname,child.get_text()):
+                    if vflag(child.fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
-                    for box in self.layout[ltpage.pageid]: # 独立公式
+                    for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
                         if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1:
                             cur_v=True
@@ -406,7 +406,6 @@ class TextConverter(PDFConverter[AnyIO]):
                     if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk[-1]+=f'$v{len(var)}$'
-                            # print(f'$v{len(var)}$',end='')
                             var.append(vstk)
                             varl.append(vlstk)
                             vstk=[]
@@ -416,55 +415,44 @@ class TextConverter(PDFConverter[AnyIO]):
                                 break
                     if not vstk: # 非公式或是公式开头
                         if not ind_v and xt and child.y1 > xt.y0 - child.size*0.5 and child.y0 < xt.y1 + child.size: # 非独立公式且位于同段落
-                            if False and (child.size>xt.size*1.2 or child.size<xt.size*0.8): # 字体分离（处理角标有误，更新pstk会导致段落断开）
+                            if child.x0 > xt.x1 + child.size*2: # 行内分离
                                 lt,rt=child,child
                                 sstk.append("""")
                                 pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                                # print(f'\n\n[TEXT D] {(child.y0,child.x0,child.size)}')
-                            elif child.x0 > xt.x1 + child.size*2: # 行内分离
-                                lt,rt=child,child
-                                sstk.append("""")
-                                pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                                # print(f'\n\n[TEXT A] {(child.y0,child.x0,child.size)}')
                             elif child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
-                                # print(' ',end='')
                             elif child.x1 < xt.x0: # 换行，这里需要考虑一下字母修饰符的情况
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
                                     pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                                    # print(f'\n\n[TEXT B] {(child.y0,child.x0,child.size)}')
                                 else: # 换行空格
                                     sstk[-1]+=' '
                                     pstk[-1][6]=True # 标记原文段落存在换行
-                                    # print(' ',end='')
                         else: # 基于纵向距离的行间分离
                             lt,rt=child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                            # print(f'\n\n[TEXT C] {(child.y0,child.x0,child.size)}')
                     if not cur_v: # 文字入栈
                         sstk[-1]+=child.get_text()
-                        # print(child.get_text(),end='')
                         if vflag(pstk[-1][5].fontname,''): # 公式开头，后续接文字，需要校正字体
                             pstk[-1][5]=child.font
                     else: # 公式入栈
                         vstk.append(child)
-                        if re.match(r'.*\+(CMEX.*)',child.fontname) and child.cid in [40]: # 大括号
-                            # ops+=f""ET q 1 0 0 1 0 {child.y0} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
-                            # ops+=f""ET q 1 0 0 1 0 {child.y0-child.size*3} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
-                            while ptr+1<len(item):
-                                child_=item[ptr+1]
-                                if isinstance(child_, LTChar): # 公式字符
-                                    # print(child_.y0,child.y0-child.size*3,child_.y1,child.y0)
-                                    if child_.y0>child.y0-child.size*3 and child_.y1<child.y0:
-                                        vstk.append(child_)
-                                    else:
-                                        break
-                                elif isinstance(child_, LTLine): # 公式线条
-                                    vlstk.append(child_)
-                                ptr+=1
+                        # if re.match(r'.*\+(CMEX.*)',child.fontname) and child.cid in [40]: # 大括号
+                        #     # ops+=f""ET q 1 0 0 1 0 {child.y0} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
+                        #     # ops+=f""ET q 1 0 0 1 0 {child.y0-child.size*3} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
+                        #     while ptr+1<len(item):
+                        #         child_=item[ptr+1]
+                        #         if isinstance(child_, LTChar): # 公式字符
+                        #             # print(child_.y0,child.y0-child.size*3,child_.y1,child.y0)
+                        #             if child_.y0>child.y0-child.size*3 and child_.y1<child.y0:
+                        #                 vstk.append(child_)
+                        #             else:
+                        #                 break
+                        #         elif isinstance(child_, LTLine): # 公式线条
+                        #             vlstk.append(child_)
+                        #         ptr+=1
                     xt=child
                     xt_ind=ind_v
                     # 更新左右边界
@@ -493,8 +481,6 @@ class TextConverter(PDFConverter[AnyIO]):
                 vlen.append(l)
             log.debug('\n==========[SSTACK]==========\n')
             hash_key=cache.deterministic_hash(""PDFMathTranslate"")
-            # if cache.is_cached(hash_key):
-            #     print('Cache is found')
             cache.create_cache(hash_key)
             @retry
             def worker(s): # 多线程翻译
@@ -512,9 +498,7 @@ class TextConverter(PDFConverter[AnyIO]):
                 except BaseException as e:
                     log.exception(e,exc_info=False)
                     raise e
-            # tqdm with concurrent.futures.ThreadPoolExecutor()
             with concurrent.futures.ThreadPoolExecutor(max_workers=self.thread) as executor:
-                # news = list(tqdm.auto.tqdm(executor.map(worker, sstk), total=len(sstk), position=1))
                 news = list(executor.map(worker, sstk))
             def raw_string(fcur,cstk): # 编码字符串
                 if isinstance(self.fontmap[fcur],PDFCIDFont):
@@ -525,10 +509,8 @@ class TextConverter(PDFConverter[AnyIO]):
                 tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
                 log.debug(f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}"")
                 while True:
-                    # print(new,ptr)
                     if ptr==len(new): # 到达段落结尾
                         if cstk:
-                            # print(cstk,tx,x,rt,y)
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
                     vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
@@ -541,7 +523,6 @@ class TextConverter(PDFConverter[AnyIO]):
                             continue # 翻译器可能会自动补个越界的公式标记
                     else: # 加载文字
                         ch=new[ptr]
-                        # cid=self.china.decode(ch.encode())
                         if font.char_width(ord(ch)):
                             fcur_=font.fontid
                         else:
@@ -553,7 +534,6 @@ class TextConverter(PDFConverter[AnyIO]):
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
                         if cstk:
-                            # print(cstk,tx,x,rt,y)
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                             cstk=''
                     if lb and x+adv>rt: # 到达右边界且原文段落存在换行
@@ -575,10 +555,9 @@ class TextConverter(PDFConverter[AnyIO]):
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
                             ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
-                            # print(vc,vch,vch.x0,vch.x1,vch.y0,vch.y1)
                         for l in varl[vid]: # 排版公式线条
-                            ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
-                            pass
+                            if l.linewidth<5: # hack
+                                ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                     else: # 插入文字缓冲区
                         if not cstk:
                             tx=x
@@ -595,11 +574,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
             ops=f'BT {ops}ET '
             return ops
-
-        # if self.showpageno:
-        #     self.write_text(""Page %s\n"" % ltpage.pageid)
         ops=render(ltpage)
-        # self.write_text(""\f"")
         return ops
 
     # Some dummy functions to save memory/CPU when all that is wanted
",add vflag to text converter,
953764773ee836a8f134dd957cac444205897a02,pdf2zh.py,"@@ -61,12 +61,6 @@ def extract_text(
             if outfile.endswith(override):
                 output_type = alttype
 
-    # if outfile == ""-"":
-    #     outfp: AnyIO = sys.stdout
-    #     if sys.stdout.encoding is not None:
-    #         codec = ""utf-8""
-    # else:
-    #     outfp = open(outfile, ""wb"")
     outfp: AnyIO = sys.stdout
     pth = os.path.join(tempfile.gettempdir(), 'mfd-tf_efficientdet_d0.pth.tar')
     if not os.path.exists(pth):
@@ -84,9 +78,7 @@ def extract_text(
             page.insert_font('china-ss')
             page.insert_font('helv')
         doc_en.save('output-en.pdf')
-        # doc_en.close()
 
-        # for fname in files:
         with open('output-en.pdf', ""rb"") as fp:
             pdf2zh.high_level.extract_text_to_fp(fp, **locals())
 
@@ -116,7 +108,6 @@ def create_parser() -> argparse.ArgumentParser:
         nargs=""+"",
         help=""One or more paths to PDF files."",
     )
-
     parser.add_argument(
         ""--version"",
         ""-v"",
@@ -130,14 +121,6 @@ def create_parser() -> argparse.ArgumentParser:
         action=""store_true"",
         help=""Use debug logging level."",
     )
-    # parser.add_argument(
-    #     ""--disable-caching"",
-    #     ""-C"",
-    #     default=False,
-    #     action=""store_true"",
-    #     help=""If caching or resources, such as fonts, should be disabled."",
-    # )
-
     parse_params = parser.add_argument_group(
         ""Parser"",
         description=""Used during PDF parsing"",
@@ -148,21 +131,6 @@ def create_parser() -> argparse.ArgumentParser:
         type=str,
         help=""The list of page numbers to parse."",
     )
-    # parse_params.add_argument(
-    #     ""--pagenos"",
-    #     ""-p"",
-    #     type=str,
-    #     help=""A comma-separated list of page numbers to parse. ""
-    #     ""Included for legacy applications, use --page-numbers ""
-    #     ""for more idiomatic argument entry."",
-    # )
-    # parse_params.add_argument(
-    #     ""--maxpages"",
-    #     ""-m"",
-    #     type=int,
-    #     default=0,
-    #     help=""The maximum number of pages to parse."",
-    # )
     parse_params.add_argument(
         ""--password"",
         ""-P"",
@@ -191,153 +159,6 @@ def create_parser() -> argparse.ArgumentParser:
         default=4,
         help=""The number of threads to execute translation."",
     )
-    # parse_params.add_argument(
-    #     ""--rotation"",
-    #     ""-R"",
-    #     default=0,
-    #     type=int,
-    #     help=""The number of degrees to rotate the PDF ""
-    #     ""before other types of processing."",
-    # )
-
-    # la_params = LAParams()  # will be used for defaults
-    # la_param_group = parser.add_argument_group(
-    #     ""Layout analysis"",
-    #     description=""Used during layout analysis."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--no-laparams"",
-    #     ""-n"",
-    #     default=False,
-    #     action=""store_true"",
-    #     help=""If layout analysis parameters should be ignored."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--detect-vertical"",
-    #     ""-V"",
-    #     default=la_params.detect_vertical,
-    #     action=""store_true"",
-    #     help=""If vertical text should be considered during layout analysis"",
-    # )
-    # la_param_group.add_argument(
-    #     ""--line-overlap"",
-    #     type=float,
-    #     default=la_params.line_overlap,
-    #     help=""If two characters have more overlap than this they ""
-    #     ""are considered to be on the same line. The overlap is specified ""
-    #     ""relative to the minimum height of both characters."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--char-margin"",
-    #     ""-M"",
-    #     type=float,
-    #     default=la_params.char_margin,
-    #     help=""If two characters are closer together than this margin they ""
-    #     ""are considered to be part of the same line. The margin is ""
-    #     ""specified relative to the width of the character."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--word-margin"",
-    #     ""-W"",
-    #     type=float,
-    #     default=la_params.word_margin,
-    #     help=""If two characters on the same line are further apart than this ""
-    #     ""margin then they are considered to be two separate words, and ""
-    #     ""an intermediate space will be added for readability. The margin ""
-    #     ""is specified relative to the width of the character."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--line-margin"",
-    #     ""-L"",
-    #     type=float,
-    #     default=la_params.line_margin,
-    #     help=""If two lines are close together they are considered to ""
-    #     ""be part of the same paragraph. The margin is specified ""
-    #     ""relative to the height of a line."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--boxes-flow"",
-    #     ""-F"",
-    #     type=float_or_disabled,
-    #     default=la_params.boxes_flow,
-    #     help=""Specifies how much a horizontal and vertical position of a ""
-    #     ""text matters when determining the order of lines. The value ""
-    #     ""should be within the range of -1.0 (only horizontal position ""
-    #     ""matters) to +1.0 (only vertical position matters). You can also ""
-    #     ""pass `disabled` to disable advanced layout analysis, and ""
-    #     ""instead return text based on the position of the bottom left ""
-    #     ""corner of the text box."",
-    # )
-    # la_param_group.add_argument(
-    #     ""--all-texts"",
-    #     ""-A"",
-    #     default=la_params.all_texts,
-    #     action=""store_true"",
-    #     help=""If layout analysis should be performed on text in figures."",
-    # )
-
-    # output_params = parser.add_argument_group(
-    #     ""Output"",
-    #     description=""Used during output generation."",
-    # )
-    # output_params.add_argument(
-    #     ""--outfile"",
-    #     ""-o"",
-    #     type=str,
-    #     default=""-"",
-    #     help=""Path to file where output is written. ""
-    #     'Or ""-"" (default) to write to stdout.',
-    # )
-    # output_params.add_argument(
-    #     ""--output_type"",
-    #     ""-t"",
-    #     type=str,
-    #     default=""text"",
-    #     help=""Type of output to generate {text,html,xml,tag}."",
-    # )
-    # output_params.add_argument(
-    #     ""--codec"",
-    #     ""-c"",
-    #     type=str,
-    #     default=""utf-8"",
-    #     help=""Text encoding to use in output file."",
-    # )
-    # output_params.add_argument(
-    #     ""--output-dir"",
-    #     ""-O"",
-    #     default=None,
-    #     help=""The output directory to put extracted images in. If not given, ""
-    #     ""images are not extracted."",
-    # )
-    # output_params.add_argument(
-    #     ""--layoutmode"",
-    #     ""-Y"",
-    #     default=""normal"",
-    #     type=str,
-    #     help=""Type of layout to use when generating html ""
-    #     ""{normal,exact,loose}. If normal,each line is""
-    #     "" positioned separately in the html. If exact""
-    #     "", each character is positioned separately in""
-    #     "" the html. If loose, same result as normal ""
-    #     ""but with an additional newline after each ""
-    #     ""text line. Only used when output_type is html."",
-    # )
-    # output_params.add_argument(
-    #     ""--scale"",
-    #     ""-s"",
-    #     type=float,
-    #     default=1.0,
-    #     help=""The amount of zoom to use when generating html file. ""
-    #     ""Only used when output_type is html."",
-    # )
-    # output_params.add_argument(
-    #     ""--strip-control"",
-    #     ""-S"",
-    #     default=False,
-    #     action=""store_true"",
-    #     help=""Remove control statement from text. ""
-    #     ""Only used when output_type is xml."",
-    # )
 
     return parser
 
@@ -345,20 +166,6 @@ def create_parser() -> argparse.ArgumentParser:
 def parse_args(args: Optional[List[str]]) -> argparse.Namespace:
     parsed_args = create_parser().parse_args(args=args)
 
-    # Propagate parsed layout parameters to LAParams object
-    # if parsed_args.no_laparams:
-    #     parsed_args.laparams = None
-    # else:
-    #     parsed_args.laparams = LAParams(
-    #         line_overlap=parsed_args.line_overlap,
-    #         char_margin=parsed_args.char_margin,
-    #         line_margin=parsed_args.line_margin,
-    #         word_margin=parsed_args.word_margin,
-    #         boxes_flow=parsed_args.boxes_flow,
-    #         detect_vertical=parsed_args.detect_vertical,
-    #         all_texts=parsed_args.all_texts,
-    #     )
-
     if parsed_args.pages:
         pages = []
         for p in parsed_args.pages.split("",""):
@@ -369,14 +176,6 @@ def parse_args(args: Optional[List[str]]) -> argparse.Namespace:
                 pages.append(int(p) - 1)
         parsed_args.pages = pages
 
-    # if parsed_args.pagenos:
-    #     parsed_args.page_numbers = {int(x) - 1 for x in parsed_args.pagenos.split("","")}
-
-    # if parsed_args.output_type == ""text"" and parsed_args.outfile != ""-"":
-    #     for override, alttype in OUTPUT_TYPES:
-    #         if parsed_args.outfile.endswith(override):
-    #             parsed_args.output_type = alttype
-
     return parsed_args
 
 
",add mfd-tf_efficientdet_d0.pth to the docutils,
b92901d9e36e30a105d52c8041850d6b1eda0633,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.2""
+__version__ = ""1.2.3""
 __author__ = ""Byaidu""
",update version,
b92901d9e36e30a105d52c8041850d6b1eda0633,converter.py,"@@ -90,6 +90,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
         (x1, y1) = apply_matrix_pt(ctm, (x1, y1))
         mediabox = (0, 0, abs(x0 - x1), abs(y0 - y1))
         self.cur_item = LTPage(page.pageno, mediabox)
+        self.cur_item.cropbox=page.cropbox
 
     def end_page(self, page: PDFPage):
         assert not self._stack, str(len(self._stack))
@@ -374,20 +375,25 @@ class TextConverter(PDFConverter[AnyIO]):
             var=[]
             varl=[]
             vlen=[]
-            ops=""""
+            ops=f""1 0 0 1 {ltpage.cropbox[0]} {ltpage.cropbox[1]} cm 0 Tc "" # 重置渲染状态
             def vflag(font,char): # 匹配公式（和角标）字体
                 if self.vfont:
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'.*\+(CM.*|MS.*|XY.*|MT.*|BL.*|.*0700|.*0500|.*Italic)',font):
+                    if re.match(r'.*\+(CM.*|MS.*|XY.*|MT.*|BL.*|RM.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
+                        return True
+                if self.vchar:
+                    if re.match(self.vchar,char):
+                        return True
+                else:
+                    if re.match(r'\d',char):
                         return True
-                if self.vchar and re.match(self.vchar,char):
-                    return True
                 return False
             ptr=0
             item=list(item)
             xt_ind=False
+            v_max=ltpage.width/4 # 行内公式最大宽度
             while ptr<len(item): # 识别文字和公式
                 child=item[ptr]
                 if isinstance(child, LTChar):
@@ -403,7 +409,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
-                    if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and child.x0<vstk[-1].x1-ltpage.width/3): # 公式结束或公式换行截断
+                    if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk[-1]+=f'$v{len(var)}$'
                             var.append(vstk)
@@ -466,7 +472,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
                 elif isinstance(child, LTLine): # 线条
-                    if vstk and child.x1-child.x0<ltpage.width/3: # 公式线条
+                    if vstk and abs(child.x0-xt.x0)<v_max and child.x1-child.x0<v_max and child.y0==child.y1 or xt_ind: # 公式线条
                         vlstk.append(child)
                     else: # 全局线条
                         lstk.append(child)
",add more info to textdev,
b8f0c82e4e13ea55d85436a9c8a97007f2226ff4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.3""
+__version__ = ""1.2.4""
 __author__ = ""Byaidu""
",update version,
b8f0c82e4e13ea55d85436a9c8a97007f2226ff4,converter.py,"@@ -64,6 +64,7 @@ from pdf2zh.utils import (
     enc,
     make_compat_str,
     mult_matrix,
+    matrix_scale,
 )
 
 log = logging.getLogger(__name__)
@@ -178,7 +179,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
                 # Note: 'ml', in conditional above, is a frequent anomaly
                 # that we want to support.
                 line = LTLine(
-                    gstate.linewidth,
+                    gstate.linewidth*matrix_scale(self.ctm),
                     pts[0],
                     pts[1],
                     stroke,
@@ -200,7 +201,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
                 ) or (y0 == y1 and x1 == x2 and y2 == y3 and x3 == x0)
                 if is_closed_loop and has_square_coordinates:
                     rect = LTRect(
-                        gstate.linewidth,
+                        gstate.linewidth*matrix_scale(self.ctm),
                         (*pts[0], *pts[2]),
                         stroke,
                         fill,
@@ -213,7 +214,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
                     self.cur_item.add(rect)
                 else:
                     curve = LTCurve(
-                        gstate.linewidth,
+                        gstate.linewidth*matrix_scale(self.ctm),
                         pts,
                         stroke,
                         fill,
@@ -226,7 +227,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
                     self.cur_item.add(curve)
             else:
                 curve = LTCurve(
-                    gstate.linewidth,
+                    gstate.linewidth*matrix_scale(self.ctm),
                     pts,
                     stroke,
                     fill,
@@ -370,10 +371,12 @@ class TextConverter(PDFConverter[AnyIO]):
             sstk=[]
             vstk=[]
             vlstk=[]
+            vfix=0
             pstk=[]
             lstk=[]
             var=[]
             varl=[]
+            varf=[]
             vlen=[]
             ops=f""1 0 0 1 {ltpage.cropbox[0]} {ltpage.cropbox[1]} cm 0 Tc "" # 重置渲染状态
             def vflag(font,char): # 匹配公式（和角标）字体
@@ -381,13 +384,13 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'.*\+(CM.*|MS.*|XY.*|MT.*|BL.*|RM.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'\d',char):
+                    if re.match(r'(\d|=|[\u0080-\ufaff])',char):
                         return True
                 return False
             ptr=0
@@ -399,7 +402,8 @@ class TextConverter(PDFConverter[AnyIO]):
                 if isinstance(child, LTChar):
                     cur_v=False
                     ind_v=False
-                    if vflag(child.fontname,child.get_text()): # 识别公式和字符
+                    fontname=child.fontname.split('+')[-1]
+                    if vflag(fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
@@ -411,11 +415,18 @@ class TextConverter(PDFConverter[AnyIO]):
                             break
                     if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
+                            sstk_bak=sstk[-1]
+                            vfix_bak=vfix
                             sstk[-1]+=f'$v{len(var)}$'
+                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y0 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正
+                                vfix=vstk[0].y0-child.y0
+                                # print(vfix,vstk[0].get_text(),sstk[-1][-20:],''.join([t.get_text() for t in item[ptr:ptr+20]]))
                             var.append(vstk)
                             varl.append(vlstk)
+                            varf.append(vfix)
                             vstk=[]
                             vlstk=[]
+                            vfix=0
                             if ptr==len(item)-1 and cur_v: # 文档以公式结尾
                                 var[-1].append(child)
                                 break
@@ -435,30 +446,36 @@ class TextConverter(PDFConverter[AnyIO]):
                                 else: # 换行空格
                                     sstk[-1]+=' '
                                     pstk[-1][6]=True # 标记原文段落存在换行
+                            
+                            if child.x0>xt.x0 and child.y0>xt.y0 and cur_v and child.y0-xt.y0<xt.size: # 行内公式修正
+                                vfix=child.y0-xt.y0
                         else: # 基于纵向距离的行间分离
                             lt,rt=child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
+                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式
+                        if sstk: # 没有重开段落
+                            if child.size<pstk[-1][4]*0.9: # 公式内文字，考虑浮点误差
+                                cur_v=True
+                                if sstk[-1][-1]=='$': # 公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
+                                    sstk[-1]=sstk_bak
+                                    vfix=vfix_bak
+                                    vstk=var.pop()
+                                    vlstk=varl.pop()
+                                    varf.pop()
+                                # else:
+                                #     print(sstk[-1])
+                                #     print(f'break {child.get_text()}')
+                            elif child.size>pstk[-1][4]: # 更新正文字体
+                                pstk[-1][4]=child.size
+                                pstk[-1][5]=child.font
                     if not cur_v: # 文字入栈
                         sstk[-1]+=child.get_text()
-                        if vflag(pstk[-1][5].fontname,''): # 公式开头，后续接文字，需要校正字体
+                        if vflag(pstk[-1][5].fontname.split('+')[-1],''): # 公式开头，后续接文字，需要校正字体
+                            pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
                     else: # 公式入栈
                         vstk.append(child)
-                        # if re.match(r'.*\+(CMEX.*)',child.fontname) and child.cid in [40]: # 大括号
-                        #     # ops+=f""ET q 1 0 0 1 0 {child.y0} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
-                        #     # ops+=f""ET q 1 0 0 1 0 {child.y0-child.size*3} cm [] 0 d 0 J 1 w 0 0 m {ltpage.width} 0 l S Q BT ""
-                        #     while ptr+1<len(item):
-                        #         child_=item[ptr+1]
-                        #         if isinstance(child_, LTChar): # 公式字符
-                        #             # print(child_.y0,child.y0-child.size*3,child_.y1,child.y0)
-                        #             if child_.y0>child.y0-child.size*3 and child_.y1<child.y0:
-                        #                 vstk.append(child_)
-                        #             else:
-                        #                 break
-                        #         elif isinstance(child_, LTLine): # 公式线条
-                        #             vlstk.append(child_)
-                        #         ptr+=1
                     xt=child
                     xt_ind=ind_v
                     # 更新左右边界
@@ -529,35 +546,28 @@ class TextConverter(PDFConverter[AnyIO]):
                             continue # 翻译器可能会自动补个越界的公式标记
                     else: # 加载文字
                         ch=new[ptr]
-                        if font.char_width(ord(ch)):
+                        # if font.char_width(ord(ch)):
+                        if font.widths.get(ord(ch)):
                             fcur_=font.fontid
                         else:
                             if ch==' ':
                                 fcur_='helv' # 半角空格
                             else:
                                 fcur_='china-ss'
+                        # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
-                    if fcur_!=fcur or vy_regex or x+adv>rt: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界
+                    if fcur_!=fcur or vy_regex or x+adv>rt+0.1*size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
                         if cstk:
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                             cstk=''
-                    if lb and x+adv>rt: # 到达右边界且原文段落存在换行
+                    if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
                         y-=size*1.5
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正
-                            if re.match(r'.*\+(CMEX.*)',var[vid][0].fontname) and var[vid][0].cid in [80,88,112,33,82]: # 根式、积分与大小求和
-                                fix=var[vid][0].size*0.85
-                            if re.match(r'.*\+(CMSY.*)',var[vid][0].fontname) and var[vid][0].cid in [112]: # 根式
-                                fix=var[vid][0].size*0.85
-                            if re.match(r'.*\+(MSAM.*)',var[vid][0].fontname) and var[vid][0].cid in [97]: # 特殊上标
-                                fix=var[vid][0].size*0.85
-                            if re.match(r'.*\+(CMR.*)',var[vid][0].fontname) and var[vid][0].cid in [94,126]: # 特殊上标
-                                fix=var[vid][0].size*0.25
-                            if re.match(r'.*\+(CM.*)7',var[vid][0].fontname): # 修正分式
-                                fix=var[vid][0].size*0.55
+                            fix=varf[vid]
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
                             ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
",add more text devices to the layout analyzer,
b8f0c82e4e13ea55d85436a9c8a97007f2226ff4,utils.py,"@@ -284,6 +284,9 @@ def apply_matrix_norm(m: Matrix, v: Point) -> Point:
     (p, q) = v
     return a * p + c * q, b * p + d * q
 
+def matrix_scale(m: Matrix) -> float:
+    (a, b, c, d, e, f) = m
+    return (a**2+c*2)**0.5
 
 #  Utility functions
 
",add missing docstring,
f3fee2b08efb5ae4aa3c3458cc0ade4971e70736,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.4""
+__version__ = ""1.2.5""
 __author__ = ""Byaidu""
",update version,
f3fee2b08efb5ae4aa3c3458cc0ade4971e70736,converter.py,"@@ -372,6 +372,7 @@ class TextConverter(PDFConverter[AnyIO]):
             vstk=[]
             vlstk=[]
             vfix=0
+            vbkt=0
             pstk=[]
             lstk=[]
             var=[]
@@ -390,7 +391,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\d|=|[\u0080-\ufaff])',char):
+                    if re.match(r'(\d|\+|=|[\u0080-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
                         return True
                 return False
             ptr=0
@@ -413,14 +414,21 @@ class TextConverter(PDFConverter[AnyIO]):
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
+                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，修正括号匹配
+                        if vstk and child.get_text()=='(':
+                            cur_v=True
+                            vbkt+=1
+                        if vbkt and child.get_text()==')':
+                            cur_v=True
+                            vbkt-=1
                     if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
                             sstk[-1]+=f'$v{len(var)}$'
-                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y0 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正
+                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y0 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正，这里要考虑正好换行的情况
                                 vfix=vstk[0].y0-child.y0
-                                # print(vfix,vstk[0].get_text(),sstk[-1][-20:],''.join([t.get_text() for t in item[ptr:ptr+20]]))
+                                # print(sstk[-1],vfix)
                             var.append(vstk)
                             varl.append(vlstk)
                             varf.append(vfix)
@@ -447,8 +455,9 @@ class TextConverter(PDFConverter[AnyIO]):
                                     sstk[-1]+=' '
                                     pstk[-1][6]=True # 标记原文段落存在换行
                             
-                            if child.x0>xt.x0 and child.y0>xt.y0 and cur_v and child.y0-xt.y0<xt.size: # 行内公式修正
+                            if child.x0>xt.x0 and child.y0>xt.y0 and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
                                 vfix=child.y0-xt.y0
+                                # print(sstk[-1],vfix)
                         else: # 基于纵向距离的行间分离
                             lt,rt=child,child
                             sstk.append("""")
@@ -550,8 +559,8 @@ class TextConverter(PDFConverter[AnyIO]):
                         if font.widths.get(ord(ch)):
                             fcur_=font.fontid
                         else:
-                            if ch==' ':
-                                fcur_='helv' # 半角空格
+                            if re.match(r'[\u0000-\u007f]',ch): # 半角符号
+                                fcur_='helv'
                             else:
                                 fcur_='china-ss'
                         # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
","add support for -413,14,21 for croman and cms",
a91b9c674344710ef37684fe0c00433b8c2f5b00,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.5""
+__version__ = ""1.2.6""
 __author__ = ""Byaidu""
",update version,
a91b9c674344710ef37684fe0c00433b8c2f5b00,converter.py,"@@ -421,7 +421,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         if vbkt and child.get_text()==')':
                             cur_v=True
                             vbkt-=1
-                    if ptr==len(item)-1 or not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
+                    if not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
@@ -435,9 +435,6 @@ class TextConverter(PDFConverter[AnyIO]):
                             vstk=[]
                             vlstk=[]
                             vfix=0
-                            if ptr==len(item)-1 and cur_v: # 文档以公式结尾
-                                var[-1].append(child)
-                                break
                     if not vstk: # 非公式或是公式开头
                         if not ind_v and xt and child.y1 > xt.y0 - child.size*0.5 and child.y0 < xt.y1 + child.size: # 非独立公式且位于同段落
                             if child.x0 > xt.x1 + child.size*2: # 行内分离
@@ -506,6 +503,12 @@ class TextConverter(PDFConverter[AnyIO]):
                     # print(child)
                     pass
                 ptr+=1
+            # 处理结尾
+            if vstk: # 公式出栈
+                sstk[-1]+=f'$v{len(var)}$'
+                var.append(vstk)
+                varl.append(vlstk)
+                varf.append(vfix)
             log.debug('\n==========[VSTACK]==========\n')
             for id,v in enumerate(var):
                 l=max([vch.x1 for vch in v])-v[0].x0
",add support for 公式出栈,
51ed3f0c18500f6c8fcbb184874694df74d555fc,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.6""
+__version__ = ""1.2.7""
 __author__ = ""Byaidu""
",update version,
51ed3f0c18500f6c8fcbb184874694df74d555fc,converter.py,"@@ -391,7 +391,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\d|\+|=|[\u0080-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
+                    if re.match(r'(\d|\+|=|[\u0370-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
                         return True
                 return False
             ptr=0
@@ -549,6 +549,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
                     vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
+                    mod=False
                     if vy_regex: # 加载公式
                         vid=int(vy_regex.group(1).replace(' ',''))
                         ptr+=len(vy_regex.group(0))
@@ -568,6 +569,9 @@ class TextConverter(PDFConverter[AnyIO]):
                                 fcur_='china-ss'
                         # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
+                        if unicodedata.category(ch) in ['Lm','Sk','Mn']: # 文字修饰符
+                            # print(f'mod {ch} {ord(ch)} {fcur_}')
+                            mod=True
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt+0.1*size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
                         if cstk:
@@ -596,6 +600,10 @@ class TextConverter(PDFConverter[AnyIO]):
                         else:
                             cstk+=ch
                     fcur=fcur_
+                    if mod: # 文字修饰符
+                        ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
+                        cstk=''
+                        adv=0
                     x+=adv
             for l in lstk: # 排版全局线条
                 if l.linewidth<5: # hack
",add support for cygwin and cygwin 2.0,
9e8b2519c9cfb76e537bc86e6cef6309f5bae04b,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.7""
+__version__ = ""1.2.8""
 __author__ = ""Byaidu""
",update version,
9e8b2519c9cfb76e537bc86e6cef6309f5bae04b,converter.py,"@@ -391,7 +391,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\d|\+|=|[\u0370-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
+                    if re.match(r'(\d|\+|=|[\u0080-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
                         return True
                 return False
             ptr=0
@@ -557,6 +557,8 @@ class TextConverter(PDFConverter[AnyIO]):
                             adv=vlen[vid]
                         else:
                             continue # 翻译器可能会自动补个越界的公式标记
+                        if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Sk','Mn']: # 文字修饰符，get_text 可能返回 cid，这里截断一下
+                            mod=True
                     else: # 加载文字
                         ch=new[ptr]
                         # if font.char_width(ord(ch)):
@@ -569,9 +571,6 @@ class TextConverter(PDFConverter[AnyIO]):
                                 fcur_='china-ss'
                         # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
-                        if unicodedata.category(ch) in ['Lm','Sk','Mn']: # 文字修饰符
-                            # print(f'mod {ch} {ord(ch)} {fcur_}')
-                            mod=True
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt+0.1*size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
                         if cstk:
@@ -599,11 +598,9 @@ class TextConverter(PDFConverter[AnyIO]):
                                 cstk+=ch
                         else:
                             cstk+=ch
-                    fcur=fcur_
                     if mod: # 文字修饰符
-                        ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
-                        cstk=''
                         adv=0
+                    fcur=fcur_
                     x+=adv
             for l in lstk: # 排版全局线条
                 if l.linewidth<5: # hack
",add support for crazy text,
b8b02a10127be249f05cbc6e0c8f186af27809f9,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.8""
+__version__ = ""1.2.9""
 __author__ = ""Byaidu""
",update version strings,
b8b02a10127be249f05cbc6e0c8f186af27809f9,converter.py,"@@ -365,27 +365,29 @@ class TextConverter(PDFConverter[AnyIO]):
 
     def receive_layout(self, ltpage: LTPage):
         def render(item: LTItem) -> None:
-            xt=None
-            lt=None
-            rt=None
-            sstk=[]
-            vstk=[]
-            vlstk=[]
-            vfix=0
-            vbkt=0
-            pstk=[]
-            lstk=[]
-            var=[]
-            varl=[]
-            varf=[]
-            vlen=[]
+            xt=None # 上一个字符
+            lt=None # 段落左边界
+            rt=None # 段落右边界
+            sstk=[] # 段落文字栈
+            vstk=[] # 公式符号组
+            vlstk=[] # 公式线条组
+            vfix=0 # 公式纵向偏移
+            vbkt=0 # 段落公式括号计数
+            pstk=[] # 段落属性栈
+            lstk=[] # 全局线条栈
+            var=[] # 公式符号组栈
+            varl=[] # 公式线条组栈
+            varf=[] # 公式纵向偏移栈
+            vlen=[] # 公式宽度栈
+            xt_ind=False # 上一个字符是否属于独立公式
+            v_max=ltpage.width/4 # 行内公式最大宽度
             ops=f""1 0 0 1 {ltpage.cropbox[0]} {ltpage.cropbox[1]} cm 0 Tc "" # 重置渲染状态
             def vflag(font,char): # 匹配公式（和角标）字体
                 if self.vfont:
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LMMono.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
@@ -396,8 +398,6 @@ class TextConverter(PDFConverter[AnyIO]):
                 return False
             ptr=0
             item=list(item)
-            xt_ind=False
-            v_max=ltpage.width/4 # 行内公式最大宽度
             while ptr<len(item): # 识别文字和公式
                 child=item[ptr]
                 if isinstance(child, LTChar):
@@ -414,7 +414,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
                             # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
-                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，修正括号匹配
+                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
                             cur_v=True
                             vbkt+=1
@@ -510,7 +510,7 @@ class TextConverter(PDFConverter[AnyIO]):
                 varl.append(vlstk)
                 varf.append(vfix)
             log.debug('\n==========[VSTACK]==========\n')
-            for id,v in enumerate(var):
+            for id,v in enumerate(var): # 计算公式宽度
                 l=max([vch.x1 for vch in v])-v[0].x0
                 log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
                 vlen.append(l)
@@ -520,9 +520,9 @@ class TextConverter(PDFConverter[AnyIO]):
             @retry
             def worker(s): # 多线程翻译
                 try:
-                    if sum(map(str.islower,s))>1:
+                    if sum(map(str.islower,s))>1: # 包含小写字母
                         hash_key_paragraph = cache.deterministic_hash(s)
-                        new = cache.load_paragraph(hash_key, hash_key_paragraph)
+                        new = cache.load_paragraph(hash_key, hash_key_paragraph) # 查询缓存
                         if new is None:
                             new=translator.translate(s,'zh-CN','en')
                             new=remove_control_characters(new)
@@ -536,12 +536,14 @@ class TextConverter(PDFConverter[AnyIO]):
             with concurrent.futures.ThreadPoolExecutor(max_workers=self.thread) as executor:
                 news = list(executor.map(worker, sstk))
             def raw_string(fcur,cstk): # 编码字符串
-                if isinstance(self.fontmap[fcur],PDFCIDFont):
+                if isinstance(self.fontmap[fcur],PDFCIDFont): # 判断编码长度
                     return """".join([""%04x"" % ord(c) for c in cstk])
                 else:
                     return """".join([""%02x"" % ord(c) for c in cstk])
             for id,new in enumerate(news): # 排版文字和公式
-                tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6];cstk='';fcur=fcur_=None
+                tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6] # 段落属性
+                cstk='' # 单行文字栈
+                fcur=fcur_=None # 单行字体
                 log.debug(f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}"")
                 while True:
                     if ptr==len(new): # 到达段落结尾
@@ -549,7 +551,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
                     vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
-                    mod=False
+                    mod=False # 当前公式是否为文字修饰符
                     if vy_regex: # 加载公式
                         vid=int(vy_regex.group(1).replace(' ',''))
                         ptr+=len(vy_regex.group(0))
@@ -562,13 +564,19 @@ class TextConverter(PDFConverter[AnyIO]):
                     else: # 加载文字
                         ch=new[ptr]
                         # if font.char_width(ord(ch)):
-                        if font.widths.get(ord(ch)):
-                            fcur_=font.fontid
-                        else:
+                        fcur_=None
+                        try:
+                            # 1.有些字体会设置非 0 缺省宽度，所以这里直接查一下宽度字典
+                            # 2.有些字体不使用标准 unicode 编码，这里校验一下
+                            if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
+                                fcur_=font.fontid # 原字体
+                        except:
+                            pass
+                        if fcur_==None:
                             if re.match(r'[\u0000-\u007f]',ch): # 半角符号
-                                fcur_='helv'
+                                fcur_='tiro' # 默认英文字体
                             else:
-                                fcur_='china-ss'
+                                fcur_='china-ss' # 默认中文字体
                         # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
@@ -581,7 +589,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         y-=size*1.5
                     if vy_regex: # 插入公式
                         fix=0
-                        if fcur!=None: # 段落内公式修正
+                        if fcur!=None: # 段落内公式修正纵向偏移
                             fix=varf[vid]
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
@@ -590,7 +598,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             if l.linewidth<5: # hack
                                 ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
                     else: # 插入文字缓冲区
-                        if not cstk:
+                        if not cstk: # 单行开头
                             tx=x
                             if x==lt and ch==' ': # 消除段落换行空格
                                 adv=0
",add support for text/plain/text.py,
b8b02a10127be249f05cbc6e0c8f186af27809f9,pdf2zh.py,"@@ -76,7 +76,7 @@ def extract_text(
         page_count=doc_en.page_count
         for page in doc_en:
             page.insert_font('china-ss')
-            page.insert_font('helv')
+            page.insert_font('tiro')
         doc_en.save('output-en.pdf')
 
         with open('output-en.pdf', ""rb"") as fp:
",update extract_text.py,
8e862c4372093e0d2a515ba172eec991ad96f684,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.2.9""
+__version__ = ""1.3.0""
 __author__ = ""Byaidu""
",update version,
8e862c4372093e0d2a515ba172eec991ad96f684,converter.py,"@@ -393,7 +393,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\d|\+|=|[\u0080-\ufaff])',char): # 很神奇，加号对应 CMR，但是减号对应 CMSY
+                    if re.match(r'(\d|\+|=|[\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号。公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
                         return True
                 return False
             ptr=0
",add support for unicode in text converter,
482080e034fc3ba2a5506ad48cefe4f8f3b85e6b,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.0""
+__version__ = ""1.3.1""
 __author__ = ""Byaidu""
",update version,
482080e034fc3ba2a5506ad48cefe4f8f3b85e6b,converter.py,"@@ -380,14 +380,16 @@ class TextConverter(PDFConverter[AnyIO]):
             varf=[] # 公式纵向偏移栈
             vlen=[] # 公式宽度栈
             xt_ind=False # 上一个字符是否属于独立公式
-            v_max=ltpage.width/4 # 行内公式最大宽度
-            ops=f""1 0 0 1 {ltpage.cropbox[0]} {ltpage.cropbox[1]} cm 0 Tc "" # 重置渲染状态
+            vmax=ltpage.width/4 # 行内公式最大宽度
+            ops="""" # 渲染结果
             def vflag(font,char): # 匹配公式（和角标）字体
+                if re.match(r'\(cid:',char):
+                    return True
                 if self.vfont:
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LMMono.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
@@ -408,20 +410,20 @@ class TextConverter(PDFConverter[AnyIO]):
                         cur_v=True
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
-                        if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1:
+                        if child.x1>b.x_1+ltpage.cropbox[0] and child.x0<b.x_2+ltpage.cropbox[0] and child.y1>ltpage.height-(b.y_2+ltpage.cropbox[1]) and child.y0<ltpage.height-(b.y_1+ltpage.cropbox[1]): # 图像识别的坐标是裁剪之后的，所以需要补偿回去
                             cur_v=True
                             ind_v=True
-                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
-                            # lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
+                            # lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1]))))
+                            # lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1]))))
                             break
-                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
+                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
                             cur_v=True
                             vbkt+=1
                         if vbkt and child.get_text()==')':
                             cur_v=True
                             vbkt-=1
-                    if not cur_v or (ind_v and not xt_ind) or (vstk and abs(child.x0-xt.x0)>v_max and not ind_v): # 公式结束或公式换行截断
+                    if not cur_v or (ind_v and not xt_ind) or (vstk and (abs(child.x0-xt.x0)>vmax or abs(child.y0-xt.y0)>vmax) and not ind_v): # 公式结束或公式换行截断
                         if vstk: # 公式出栈
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
@@ -459,7 +461,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             lt,rt=child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                    if not cur_v and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式
+                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式
                         if sstk: # 没有重开段落
                             if child.size<pstk[-1][4]*0.9: # 公式内文字，考虑浮点误差
                                 cur_v=True
@@ -469,9 +471,6 @@ class TextConverter(PDFConverter[AnyIO]):
                                     vstk=var.pop()
                                     vlstk=varl.pop()
                                     varf.pop()
-                                # else:
-                                #     print(sstk[-1])
-                                #     print(f'break {child.get_text()}')
                             elif child.size>pstk[-1][4]: # 更新正文字体
                                 pstk[-1][4]=child.size
                                 pstk[-1][5]=child.font
@@ -495,7 +494,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
                 elif isinstance(child, LTLine): # 线条
-                    if vstk and abs(child.x0-xt.x0)<v_max and child.x1-child.x0<v_max and child.y0==child.y1 or xt_ind: # 公式线条
+                    if vstk and abs(child.x0-xt.x0)<vmax and child.x1-child.x0<vmax and child.y0==child.y1 or xt_ind: # 公式线条
                         vlstk.append(child)
                     else: # 全局线条
                         lstk.append(child)
@@ -550,14 +549,14 @@ class TextConverter(PDFConverter[AnyIO]):
                         if cstk:
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
-                    vy_regex=re.match(r'\$\s*v([\d\s]*)\$',new[ptr:]) # 匹配 $vn$ 公式标记
+                    vy_regex=re.match(r'\$?\s*v([\d\s]+)\$',new[ptr:]) # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
                     mod=False # 当前公式是否为文字修饰符
                     if vy_regex: # 加载公式
-                        vid=int(vy_regex.group(1).replace(' ',''))
                         ptr+=len(vy_regex.group(0))
-                        if vid<len(vlen):
+                        try:
+                            vid=int(vy_regex.group(1).replace(' ',''))
                             adv=vlen[vid]
-                        else:
+                        except:
                             continue # 翻译器可能会自动补个越界的公式标记
                         if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Sk','Mn']: # 文字修饰符，get_text 可能返回 cid，这里截断一下
                             mod=True
",add support for vflag and vchar,
482080e034fc3ba2a5506ad48cefe4f8f3b85e6b,pdfinterp.py,"@@ -979,7 +979,7 @@ class PDFPageInterpreter:
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
-        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\n{ops_base}{ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面
+        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
         if log.isEnabledFor(logging.DEBUG):
             log.debug(f'OP_BASE {ops_base}')
             log.debug(f'OP_NEW {ops_new}')
",fix crash when printing new ops,
7fa544040059219e143455543f95c242ccb105dd,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.1""
+__version__ = ""1.3.2""
 __author__ = ""Byaidu""
",update version,
7fa544040059219e143455543f95c242ccb105dd,converter.py,"@@ -462,7 +462,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式
-                        if sstk: # 没有重开段落
+                        if sstk[-1]: # 没有重开段落
                             if child.size<pstk[-1][4]*0.9: # 公式内文字，考虑浮点误差
                                 cur_v=True
                                 if sstk[-1][-1]=='$': # 公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
",add support for CMR,
c90bf830aec08fe1c71495785158b935141b861b,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.3""
+__version__ = ""1.3.4""
 __author__ = ""Byaidu""
",update version,
c90bf830aec08fe1c71495785158b935141b861b,converter.py,"@@ -442,7 +442,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             vlstk=[]
                             vfix=0
                     if not vstk: # 非公式或是公式开头
-                        if not ind_v and xt and child.y1 > xt.y0 - child.size*0.5 and child.y0 < xt.y1 + child.size: # 非独立公式且位于同段落
+                        if not ind_v and xt and child.y1 > xt.y0 - child.size*0.45 and child.y0 < xt.y1 + child.size: # 非独立公式且位于同段落
                             if child.x0 > xt.x1 + child.size*2: # 行内分离
                                 lt,rt=child,child
                                 sstk.append("""")
@@ -465,7 +465,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             lt,rt=child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式
+                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式。因为经常会有 CMR 以外的其他小角标比如 d_model，所以这里不锁字体
                         if sstk[-1]: # 没有重开段落
                             if child.size<pstk[-1][4]*0.9: # 公式内文字，考虑浮点误差
                                 cur_v=True
@@ -480,7 +480,7 @@ class TextConverter(PDFConverter[AnyIO]):
                                 pstk[-1][5]=child.font
                     if not cur_v: # 文字入栈
                         sstk[-1]+=child.get_text()
-                        if vflag(pstk[-1][5].fontname.split('+')[-1],''): # 公式开头，后续接文字，需要校正字体
+                        if vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 公式或粗体开头，后续接文字，需要校正字体
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
                     else: # 公式入栈
",add support for 公式且位于同段落公式且位于同段落公式+ 公式且位于同段落公式+ 公式,
83e3a940f173292691c376943c73989c1450bd31,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.4""
+__version__ = ""1.3.5""
 __author__ = ""Byaidu""
",update version,
83e3a940f173292691c376943c73989c1450bd31,converter.py,"@@ -412,6 +412,9 @@ class TextConverter(PDFConverter[AnyIO]):
                     fontname=child.fontname.split('+')[-1]
                     if vflag(fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
+                    if child.matrix[:4]!=(1,0,0,1): # 非水平段落
+                        cur_v=True
+                        ind_v=True
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
                         if child.x1>b.x_1+ltpage.cropbox[0] and child.x0<b.x_2+ltpage.cropbox[0] and child.y1>ltpage.height-(b.y_2+ltpage.cropbox[1]) and child.y0<ltpage.height-(b.y_1+ltpage.cropbox[1]): # 图像识别的坐标是裁剪之后的，所以需要补偿回去
",add support for vflag in textconverter,
4914bd95c4b5a7e66d0e14ada8e2267bcf23ca96,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.5""
+__version__ = ""1.3.6""
 __author__ = ""Byaidu""
",update version,
4914bd95c4b5a7e66d0e14ada8e2267bcf23ca96,converter.py,"@@ -412,9 +412,10 @@ class TextConverter(PDFConverter[AnyIO]):
                     fontname=child.fontname.split('+')[-1]
                     if vflag(fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
-                    if child.matrix[:4]!=(1,0,0,1): # 非水平段落
+                    if child.matrix[:4]==(0,1,-1,0): # 竖直段落
                         cur_v=True
                         ind_v=True
+                        # print(child.get_text(),child.matrix[:4])
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
                         if child.x1>b.x_1+ltpage.cropbox[0] and child.x0<b.x_2+ltpage.cropbox[0] and child.y1>ltpage.height-(b.y_2+ltpage.cropbox[1]) and child.y0<ltpage.height-(b.y_1+ltpage.cropbox[1]): # 图像识别的坐标是裁剪之后的，所以需要补偿回去
",add support for vflag in textconverter,
2075f82143ef969e01a853a8156420ee645fa73e,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.6""
+__version__ = ""1.3.7""
 __author__ = ""Byaidu""
",update version,
2075f82143ef969e01a853a8156420ee645fa73e,converter.py,"@@ -399,7 +399,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\d|\+|=|[\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号。公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
+                    if re.match(r'([\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号
                         return True
                 return False
             ptr=0
@@ -421,8 +421,9 @@ class TextConverter(PDFConverter[AnyIO]):
                         if child.x1>b.x_1+ltpage.cropbox[0] and child.x0<b.x_2+ltpage.cropbox[0] and child.y1>ltpage.height-(b.y_2+ltpage.cropbox[1]) and child.y0<ltpage.height-(b.y_1+ltpage.cropbox[1]): # 图像识别的坐标是裁剪之后的，所以需要补偿回去
                             cur_v=True
                             ind_v=True
-                            # lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1]))))
-                            # lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1]))))
+                            if log.isEnabledFor(logging.DEBUG):
+                                lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1]))))
+                                lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1]))))
                             break
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
@@ -431,7 +432,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         if vbkt and child.get_text()==')':
                             cur_v=True
                             vbkt-=1
-                    if not cur_v or (ind_v and not xt_ind) or (vstk and (abs(child.x0-xt.x0)>vmax or abs(child.y0-xt.y0)>vmax) and not ind_v): # 公式结束或公式换行截断
+                    if not cur_v or (ind_v ^ xt_ind) or (vstk and (abs(child.x0-xt.x0)>vmax or abs(child.y0-xt.y0)>vmax) and not ind_v): # 公式结束、独立公式边界或公式换行截断
                         if vstk: # 公式出栈
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
@@ -446,7 +447,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             vlstk=[]
                             vfix=0
                     if not vstk: # 非公式或是公式开头
-                        if not ind_v and xt and child.y1 > xt.y0 - child.size*0.45 and child.y0 < xt.y1 + child.size: # 非独立公式且位于同段落
+                        if not (ind_v ^ xt_ind) and xt and child.y1 > xt.y0 - child.size*0.45 and child.y0 < xt.y1 + child.size: # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
                             if child.x0 > xt.x1 + child.size*2: # 行内分离
                                 lt,rt=child,child
                                 sstk.append("""")
@@ -461,33 +462,30 @@ class TextConverter(PDFConverter[AnyIO]):
                                 else: # 换行空格
                                     sstk[-1]+=' '
                                     pstk[-1][6]=True # 标记原文段落存在换行
-                            
-                            if child.x0>xt.x0 and child.y0>xt.y0 and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
-                                vfix=child.y0-xt.y0
-                                # print(sstk[-1],vfix)
                         else: # 基于纵向距离的行间分离
                             lt,rt=child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式。因为经常会有 CMR 以外的其他小角标比如 d_model，所以这里不锁字体
-                        if sstk[-1]: # 没有重开段落
-                            if child.size<pstk[-1][4]*0.9: # 公式内文字，考虑浮点误差
-                                cur_v=True
-                                if sstk[-1][-1]=='$': # 公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
-                                    sstk[-1]=sstk_bak
-                                    vfix=vfix_bak
-                                    vstk=var.pop()
-                                    vlstk=varl.pop()
-                                    varf.pop()
-                            elif child.size>pstk[-1][4]: # 更新正文字体
-                                pstk[-1][4]=child.size
-                                pstk[-1][5]=child.font
+                        if child.size<pstk[-1][4]*0.9: # and sstk[-1]: # 公式内文字，考虑浮点误差，如果比段落字体小，说明肯定没有重开段落，不需要再判断一次
+                            cur_v=True
+                            if sstk[-1][-1]=='$': # 结尾是 $ 说明触发了上面的出栈，公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
+                                sstk[-1]=sstk_bak
+                                vfix=vfix_bak
+                                vstk=var.pop()
+                                vlstk=varl.pop()
+                                varf.pop()
                     if not cur_v: # 文字入栈
-                        sstk[-1]+=child.get_text()
-                        if vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 公式或粗体开头，后续接文字，需要校正字体
+                        if child.size>pstk[-1][4]*1.1 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
+                            pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
+                        sstk[-1]+=child.get_text()
                     else: # 公式入栈
+                        # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正
+                        if not vstk and sstk[-1]: # 公式开头，不是段落开头
+                            if child.x0>xt.x0 and child.y0>xt.y0: # and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
+                                vfix=child.y0-xt.y0
                         vstk.append(child)
                     xt=child
                     xt_ind=ind_v
@@ -547,6 +545,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     return """".join([""%04x"" % ord(c) for c in cstk])
                 else:
                     return """".join([""%02x"" % ord(c) for c in cstk])
+            _x,_y=0,0
             for id,new in enumerate(news): # 排版文字和公式
                 tx=x=pstk[id][1];y=pstk[id][0];lt=pstk[id][2];rt=pstk[id][3];ptr=0;size=pstk[id][4];font=pstk[id][5];lb=pstk[id][6] # 段落属性
                 cstk='' # 单行文字栈
@@ -601,6 +600,9 @@ class TextConverter(PDFConverter[AnyIO]):
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
                             ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
+                            if log.isEnabledFor(logging.DEBUG):
+                                lstk.append(LTLine(0.1,(_x,_y),(x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0)))
+                                _x,_y=x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0
                         for l in varl[vid]: # 排版公式线条
                             if l.linewidth<5: # hack
                                 ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
@@ -617,6 +619,9 @@ class TextConverter(PDFConverter[AnyIO]):
                         adv=0
                     fcur=fcur_
                     x+=adv
+                    if log.isEnabledFor(logging.DEBUG):
+                        lstk.append(LTLine(0.1,(_x,_y),(x,y)))
+                        _x,_y=x,y
             for l in lstk: # 排版全局线条
                 if l.linewidth<5: # hack
                     ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
",add support for cromacs and crls,
2075f82143ef969e01a853a8156420ee645fa73e,pdfinterp.py,"@@ -265,8 +265,8 @@ class PDFContentParser(PSStackParser[Union[PSKeyword, PDFStream]]):
             else:
                 raise PSEOF(""Unexpected EOF, file truncated?"")
             self.fp = BytesIO(strm.get_data())
-            if log.isEnabledFor(logging.DEBUG):
-                log.debug(f'STREAM DATA {strm.get_data()}')
+            # if log.isEnabledFor(logging.DEBUG):
+            #     log.debug(f'STREAM DATA {strm.get_data()}')
 
     def seek(self, pos: int) -> None:
         self.fillfp()
@@ -980,10 +980,10 @@ class PDFPageInterpreter:
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
         ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
-        if log.isEnabledFor(logging.DEBUG):
-            log.debug(f'OP_BASE {ops_base}')
-            log.debug(f'OP_NEW {ops_new}')
-            log.debug(f'OP_FULL {ops_full}')
+        # if log.isEnabledFor(logging.DEBUG):
+        #     log.debug(f'OP_BASE {ops_base}')
+        #     log.debug(f'OP_NEW {ops_new}')
+        #     log.debug(f'OP_FULL {ops_full}')
         return page_objids,ops_full
 
     def render_contents(
",add more info to the stream class,
d263c9a837ceabed77853b682e1b6f6ea4067555,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.7""
+__version__ = ""1.3.8""
 __author__ = ""Byaidu""
",update version,
d263c9a837ceabed77853b682e1b6f6ea4067555,converter.py,"@@ -454,7 +454,7 @@ class TextConverter(PDFConverter[AnyIO]):
                                 pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                             elif child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
-                            elif child.x1 < xt.x0: # 换行，这里需要考虑一下字母修饰符的情况
+                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9): # 换行，这里需要考虑一下字母修饰符的情况，小字体不换行解决分式问题
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
",add support for 基于初始位置的行间分离,
43dde7662084e58d7a9f55601cfb195d41006dc4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.8""
+__version__ = ""1.3.9""
 __author__ = ""Byaidu""
",update version strings,
43dde7662084e58d7a9f55601cfb195d41006dc4,converter.py,"@@ -454,7 +454,7 @@ class TextConverter(PDFConverter[AnyIO]):
                                 pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                             elif child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
-                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9): # 换行，这里需要考虑一下字母修饰符的情况，小字体不换行解决分式问题
+                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9 and abs(child.x0-xt.x0)<vmax): # 换行，这里需要考虑一下字母修饰符的情况，小字体不换行解决分式问题
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
",add support for 基于初始位置的行间分离,
bd5952cecbfa4f022837186edd4f61daa09dc97c,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.3.9""
+__version__ = ""1.4.0""
 __author__ = ""Byaidu""
",update version,
bd5952cecbfa4f022837186edd4f61daa09dc97c,converter.py,"@@ -399,7 +399,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'([\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号
+                    if re.match(r'(\+|=|[\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号。公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
                         return True
                 return False
             ptr=0
",add support for crl/cmsy to text converter,
6836412f34195c525ba84e85f0ebedfdd66c13ea,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.0""
+__version__ = ""1.4.1""
 __author__ = ""Byaidu""
",update version,
6836412f34195c525ba84e85f0ebedfdd66c13ea,converter.py,"@@ -437,7 +437,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
                             sstk[-1]+=f'$v{len(var)}$'
-                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y0 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正，这里要考虑正好换行的情况
+                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y1 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正，这里要考虑正好换行的情况
                                 vfix=vstk[0].y0-child.y0
                                 # print(sstk[-1],vfix)
                             var.append(vstk)
@@ -447,7 +447,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             vlstk=[]
                             vfix=0
                     if not vstk: # 非公式或是公式开头
-                        if not (ind_v ^ xt_ind) and xt and child.y1 > xt.y0 - child.size*0.45 and child.y0 < xt.y1 + child.size: # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
+                        if not (ind_v ^ xt_ind) and xt and child.y1 > xt.y0 - min(child.size,xt.size)*0.45 and child.y0 < xt.y1 + min(child.size,xt.size): # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
                             if child.x0 > xt.x1 + child.size*2: # 行内分离
                                 lt,rt=child,child
                                 sstk.append("""")
@@ -482,9 +482,9 @@ class TextConverter(PDFConverter[AnyIO]):
                             pstk[-1][5]=child.font
                         sstk[-1]+=child.get_text()
                     else: # 公式入栈
-                        # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正
+                        # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正，有些下角标可能需要向下的修正
                         if not vstk and sstk[-1]: # 公式开头，不是段落开头
-                            if child.x0>xt.x0 and child.y0>xt.y0: # and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
+                            if child.x0>xt.x0 and child.y1>xt.y0: # and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
                                 vfix=child.y0-xt.y0
                         vstk.append(child)
                     xt=child
",add more examples to text converter,
6d9ef55de7ad2d2be38c34f19ecd43af5c194ac9,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.1""
+__version__ = ""1.4.2""
 __author__ = ""Byaidu""
",update version strings,
6d9ef55de7ad2d2be38c34f19ecd43af5c194ac9,converter.py,"@@ -393,7 +393,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|.*0700|.*0500|.*Italic|.*Symbol)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|.*0700|.*0500|.*Ital|.*Symbol|.*math)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
@@ -452,9 +452,9 @@ class TextConverter(PDFConverter[AnyIO]):
                                 lt,rt=child,child
                                 sstk.append("""")
                                 pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                            elif child.x0 > xt.x1 + 1: # 行内空格
+                            elif child.x0 > xt.x1 + 1 and not (child.size<pstk[-1][4]*0.9): # 行内空格，小字体不加空格，因为可能会影响到下面的还原操作
                                 sstk[-1]+=' '
-                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9 and abs(child.x0-xt.x0)<vmax): # 换行，这里需要考虑一下字母修饰符的情况，小字体不换行解决分式问题
+                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9 and abs(child.x0-xt.x0)<vmax): # 换行，这里需要考虑一下字母修饰符的情况，连续小字体不换行解决分式问题
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
                                     lt,rt=child,child
                                     sstk.append("""")
@@ -469,6 +469,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式。因为经常会有 CMR 以外的其他小角标比如 d_model，所以这里不锁字体
                         if child.size<pstk[-1][4]*0.9: # and sstk[-1]: # 公式内文字，考虑浮点误差，如果比段落字体小，说明肯定没有重开段落，不需要再判断一次
                             cur_v=True
+                            # 这里应该保证行内公式不要被空格随意打断变成两个连着的公式标记，要不然根据 xt 计算 vfix 修正的策略就不对了
                             if sstk[-1][-1]=='$': # 结尾是 $ 说明触发了上面的出栈，公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
                                 sstk[-1]=sstk_bak
                                 vfix=vfix_bak
",add more support for vfont and vchar,
7017e94b2f8f06f59bde0409d7c71f864b163cef,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.2""
+__version__ = ""1.4.3""
 __author__ = ""Byaidu""
",update version strings,
7017e94b2f8f06f59bde0409d7c71f864b163cef,converter.py,"@@ -393,7 +393,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|.*0700|.*0500|.*Ital|.*Symbol|.*math)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|rsfs.*|txsy.*|.*0700|.*0500|.*Ital|.*Sym|.*math)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
",add more support for text converter,
4221ed7e01a878f719306c0363974bb03892965c,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.3""
+__version__ = ""1.4.4""
 __author__ = ""Byaidu""
",update version strings,
4221ed7e01a878f719306c0363974bb03892965c,converter.py,"@@ -372,6 +372,7 @@ class TextConverter(PDFConverter[AnyIO]):
             xt=None # 上一个字符
             lt=None # 段落左边界
             rt=None # 段落右边界
+            dt=None # 段落下边界
             sstk=[] # 段落文字栈
             vstk=[] # 公式符号组
             vlstk=[] # 公式线条组
@@ -393,7 +394,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|LMMono.*|rsfs.*|txsy.*|.*0700|.*0500|.*Ital|.*Sym|.*math)',font):
+                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|rsfs.*|txsy.*|.*0700|.*0500|.*Mono|.*Ital|.*Sym|.*math)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
@@ -436,6 +437,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         if vstk: # 公式出栈
                             sstk_bak=sstk[-1]
                             vfix_bak=vfix
+                            lt_bak,rt_bak,dt_bak=lt,rt,dt
                             sstk[-1]+=f'$v{len(var)}$'
                             if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y1 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正，这里要考虑正好换行的情况
                                 vfix=vstk[0].y0-child.y0
@@ -447,23 +449,23 @@ class TextConverter(PDFConverter[AnyIO]):
                             vlstk=[]
                             vfix=0
                     if not vstk: # 非公式或是公式开头
-                        if not (ind_v ^ xt_ind) and xt and child.y1 > xt.y0 - min(child.size,xt.size)*0.45 and child.y0 < xt.y1 + min(child.size,xt.size): # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
+                        if not (ind_v ^ xt_ind) and xt and child.y1 > dt.y0 - min(child.size,xt.size)*0.45 and child.y0 < xt.y1 + min(child.size,xt.size): # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
                             if child.x0 > xt.x1 + child.size*2: # 行内分离
-                                lt,rt=child,child
+                                lt,rt,dt=child,child,child
                                 sstk.append("""")
                                 pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                             elif child.x0 > xt.x1 + 1 and not (child.size<pstk[-1][4]*0.9): # 行内空格，小字体不加空格，因为可能会影响到下面的还原操作
                                 sstk[-1]+=' '
                             elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9 and abs(child.x0-xt.x0)<vmax): # 换行，这里需要考虑一下字母修饰符的情况，连续小字体不换行解决分式问题
                                 if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
-                                    lt,rt=child,child
+                                    lt,rt,dt=child,child,child
                                     sstk.append("""")
                                     pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                                 else: # 换行空格
                                     sstk[-1]+=' '
                                     pstk[-1][6]=True # 标记原文段落存在换行
                         else: # 基于纵向距离的行间分离
-                            lt,rt=child,child
+                            lt,rt,dt=child,child,child
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式。因为经常会有 CMR 以外的其他小角标比如 d_model，所以这里不锁字体
@@ -476,11 +478,21 @@ class TextConverter(PDFConverter[AnyIO]):
                                 vstk=var.pop()
                                 vlstk=varl.pop()
                                 varf.pop()
+                                lt,rt,dt=lt_bak,rt_bak,dt_bak
                     if not cur_v: # 文字入栈
                         if child.size>pstk[-1][4]*1.1 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
                             pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
+                        # 更新段落边界
+                        if child.x0<lt.x0:
+                            pstk[-1][2]=child.x0
+                            lt=child
+                        if child.x1>rt.x1:
+                            pstk[-1][3]=child.x1
+                            rt=child
+                        if child.y0<dt.y0:
+                            dt=child
                         sstk[-1]+=child.get_text()
                     else: # 公式入栈
                         # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正，有些下角标可能需要向下的修正
@@ -490,13 +502,6 @@ class TextConverter(PDFConverter[AnyIO]):
                         vstk.append(child)
                     xt=child
                     xt_ind=ind_v
-                    # 更新左右边界
-                    if child.x0<lt.x0:
-                        pstk[-1][2]=child.x0
-                        lt=child
-                    if child.x1>rt.x1:
-                        pstk[-1][3]=child.x1
-                        rt=child
                 elif isinstance(child, LTFigure): # 图表
                     # print(f'\n\n[FIGURE] {child.name}')
                     pass
@@ -530,6 +535,16 @@ class TextConverter(PDFConverter[AnyIO]):
                         hash_key_paragraph = cache.deterministic_hash((s,self.lang_in,self.lang_out))
                         new = cache.load_paragraph(hash_key, hash_key_paragraph) # 查询缓存
                         if new is None:
+                            # import ollama
+                            # response = ollama.chat(model='llama3.2', messages=[
+                            #     {
+                            #         'role': 'system',
+                            #         'content':
+                            #             'You are a professional translation engine, please translate the text into a colloquial, professional, elegant and fluent content, without the style of machine translation. You must only translate the text content, never interpret it.',
+                            #     },
+                            #     { 'role': 'user', 'content': f'Translate into {self.lang_out}:\n""\n{s}\n""' },
+                            # ])
+                            # new=response['message']['content']
                             new=translator.translate(s,self.lang_out,self.lang_in)
                             new=remove_control_characters(new)
                             cache.write_paragraph(hash_key, hash_key_paragraph, new)
@@ -593,7 +608,8 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
-                        y-=size*1.5
+                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2}
+                        y-=size*lang_space.get(self.lang_out,1.4)
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正纵向偏移
","add 公式出栈, 公式出栈, 公式出栈, 公式出栈, 公式出栈, 公式出栈, 公式出栈",
722e01ed0ffef299fcd62d0c011758d755a45cff,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.4""
+__version__ = ""1.4.5""
 __author__ = ""Byaidu""
",update version strings,
722e01ed0ffef299fcd62d0c011758d755a45cff,converter.py,"@@ -91,7 +91,6 @@ class PDFLayoutAnalyzer(PDFTextDevice):
         (x1, y1) = apply_matrix_pt(ctm, (x1, y1))
         mediabox = (0, 0, abs(x0 - x1), abs(y0 - y1))
         self.cur_item = LTPage(page.pageno, mediabox)
-        self.cur_item.cropbox=page.cropbox
 
     def end_page(self, page: PDFPage):
         assert not self._stack, str(len(self._stack))
@@ -419,12 +418,12 @@ class TextConverter(PDFConverter[AnyIO]):
                         # print(child.get_text(),child.matrix[:4])
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
-                        if child.x1>b.x_1+ltpage.cropbox[0] and child.x0<b.x_2+ltpage.cropbox[0] and child.y1>ltpage.height-(b.y_2+ltpage.cropbox[1]) and child.y0<ltpage.height-(b.y_1+ltpage.cropbox[1]): # 图像识别的坐标是裁剪之后的，所以需要补偿回去
+                        if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1: # 图像识别的坐标是裁剪之后的，所以需要补偿回去
                             cur_v=True
                             ind_v=True
                             if log.isEnabledFor(logging.DEBUG):
-                                lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_2+ltpage.cropbox[1]))))
-                                lstk.append(LTLine(1,(b.x_1+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1])),(b.x_2+ltpage.cropbox[0],ltpage.height-(b.y_1+ltpage.cropbox[1]))))
+                                lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_2),(b.x_2,ltpage.height-b.y_2)))
+                                lstk.append(LTLine(1,(b.x_1,ltpage.height-b.y_1),(b.x_2,ltpage.height-b.y_1)))
                             break
                     if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
",add more examples to the layout analyzer,
722e01ed0ffef299fcd62d0c011758d755a45cff,pdfinterp.py,"@@ -979,7 +979,8 @@ class PDFPageInterpreter:
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
-        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
+        # 上面渲染的时候会根据 mediabox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
+        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
         # if log.isEnabledFor(logging.DEBUG):
         #     log.debug(f'OP_BASE {ops_base}')
         #     log.debug(f'OP_NEW {ops_new}')
",add support for mediabox support,
d1e561821d64cffe100a1bc04f7682e8f0914afd,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.5""
+__version__ = ""1.4.6""
 __author__ = ""Byaidu""
",update version,
d1e561821d64cffe100a1bc04f7682e8f0914afd,converter.py,"@@ -418,7 +418,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         # print(child.get_text(),child.matrix[:4])
                     for box in self.layout[ltpage.pageid]: # 识别独立公式
                         b=box.block
-                        if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1: # 图像识别的坐标是裁剪之后的，所以需要补偿回去
+                        if child.x1>b.x_1 and child.x0<b.x_2 and child.y1>ltpage.height-b.y_2 and child.y0<ltpage.height-b.y_1:
                             cur_v=True
                             ind_v=True
                             if log.isEnabledFor(logging.DEBUG):
@@ -483,15 +483,6 @@ class TextConverter(PDFConverter[AnyIO]):
                             pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
-                        # 更新段落边界
-                        if child.x0<lt.x0:
-                            pstk[-1][2]=child.x0
-                            lt=child
-                        if child.x1>rt.x1:
-                            pstk[-1][3]=child.x1
-                            rt=child
-                        if child.y0<dt.y0:
-                            dt=child
                         sstk[-1]+=child.get_text()
                     else: # 公式入栈
                         # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正，有些下角标可能需要向下的修正
@@ -499,6 +490,15 @@ class TextConverter(PDFConverter[AnyIO]):
                             if child.x0>xt.x0 and child.y1>xt.y0: # and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
                                 vfix=child.y0-xt.y0
                         vstk.append(child)
+                    # 更新段落边界，段落内换行之后可能是公式开头，如果不更新 dt 后面换行检测会出错
+                    if child.x0<lt.x0:
+                        pstk[-1][2]=child.x0
+                        lt=child
+                    if child.x1>rt.x1:
+                        pstk[-1][3]=child.x1
+                        rt=child
+                    if child.y0<dt.y0:
+                        dt=child
                     xt=child
                     xt_ind=ind_v
                 elif isinstance(child, LTFigure): # 图表
",add support for text in page content,
d1e561821d64cffe100a1bc04f7682e8f0914afd,pdfinterp.py,"@@ -46,6 +46,7 @@ from pdf2zh.utils import (
     Rect,
     choplist,
     mult_matrix,
+    apply_matrix_pt,
 )
 
 log = logging.getLogger(__name__)
@@ -566,8 +567,18 @@ class PDFPageInterpreter:
 
     def do_S(self) -> None:
         """"""Stroke path""""""
-        self.device.paint_path(self.graphicstate, True, False, False, self.curpath)
-        self.curpath = []
+        def is_black(color: Color) -> bool:
+            if isinstance(color, Tuple):
+                return sum(color)==0
+            else:
+                return color==0
+        if len(self.curpath)==2 and self.curpath[0][0]=='m' and self.curpath[1][0]=='l' and apply_matrix_pt(self.ctm,self.curpath[0][-2:])[1]==apply_matrix_pt(self.ctm,self.curpath[1][-2:])[1] and is_black(self.graphicstate.scolor): # 独立直线，水平，黑色
+            # print(apply_matrix_pt(self.ctm,self.curpath[0][-2:]),apply_matrix_pt(self.ctm,self.curpath[1][-2:]),self.graphicstate.scolor)
+            self.device.paint_path(self.graphicstate, True, False, False, self.curpath)
+            self.curpath = []
+            return 'n'
+        else:
+            self.curpath = []
 
     def do_s(self) -> None:
         """"""Close and stroke path""""""
@@ -576,7 +587,7 @@ class PDFPageInterpreter:
 
     def do_f(self) -> None:
         """"""Fill path using nonzero winding number rule""""""
-        self.device.paint_path(self.graphicstate, False, True, False, self.curpath)
+        # self.device.paint_path(self.graphicstate, False, True, False, self.curpath)
         self.curpath = []
 
     def do_F(self) -> None:
@@ -584,17 +595,17 @@ class PDFPageInterpreter:
 
     def do_f_a(self) -> None:
         """"""Fill path using even-odd rule""""""
-        self.device.paint_path(self.graphicstate, False, True, True, self.curpath)
+        # self.device.paint_path(self.graphicstate, False, True, True, self.curpath)
         self.curpath = []
 
     def do_B(self) -> None:
         """"""Fill and stroke path using nonzero winding number rule""""""
-        self.device.paint_path(self.graphicstate, True, True, False, self.curpath)
+        # self.device.paint_path(self.graphicstate, True, True, False, self.curpath)
         self.curpath = []
 
     def do_B_a(self) -> None:
         """"""Fill and stroke path using even-odd rule""""""
-        self.device.paint_path(self.graphicstate, True, True, True, self.curpath)
+        # self.device.paint_path(self.graphicstate, True, True, True, self.curpath)
         self.curpath = []
 
     def do_b(self) -> None:
@@ -1033,7 +1044,7 @@ class PDFPageInterpreter:
                         # log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
-                            if not name in ['TJ','Tj','Tm','Tf','l']:
+                            if not name in ['TJ','Tj','Tm','Tf']:
                                 p="" "".join([str(x).replace(""\'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
",add more documentation to the pageinterpreter,
eb700c4a5be8c5623b6f7dcdaa0e0904cb8461d1,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.6""
+__version__ = ""1.4.7""
 __author__ = ""Byaidu""
",update version,
eb700c4a5be8c5623b6f7dcdaa0e0904cb8461d1,converter.py,"@@ -86,7 +86,8 @@ class PDFLayoutAnalyzer(PDFTextDevice):
         self._stack: List[LTLayoutContainer] = []
 
     def begin_page(self, page: PDFPage, ctm: Matrix) -> None:
-        (x0, y0, x1, y1) = page.mediabox
+        # (x0, y0, x1, y1) = page.mediabox
+        (x0, y0, x1, y1) = page.cropbox
         (x0, y0) = apply_matrix_pt(ctm, (x0, y0))
         (x1, y1) = apply_matrix_pt(ctm, (x1, y1))
         mediabox = (0, 0, abs(x0 - x1), abs(y0 - y1))
@@ -407,8 +408,8 @@ class TextConverter(PDFConverter[AnyIO]):
             while ptr<len(item): # 识别文字和公式
                 child=item[ptr]
                 if isinstance(child, LTChar):
-                    cur_v=False
-                    ind_v=False
+                    cur_v=False # 公式
+                    ind_v=False # 独立公式
                     fontname=child.fontname.split('+')[-1]
                     if vflag(fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
",add more tests to the textdevice analyzer,
eb700c4a5be8c5623b6f7dcdaa0e0904cb8461d1,pdfinterp.py,"@@ -976,7 +976,9 @@ class PDFPageInterpreter:
 
     def process_page(self, page: PDFPage) -> None:
         # log.debug(""Processing page: %r"", page)
-        (x0, y0, x1, y1) = page.mediabox
+        # print(page.mediabox,page.cropbox)
+        # (x0, y0, x1, y1) = page.mediabox
+        (x0, y0, x1, y1) = page.cropbox
         if page.rotate == 90:
             ctm = (0, -1, 1, 0, -y0, x1)
         elif page.rotate == 180:
@@ -990,7 +992,7 @@ class PDFPageInterpreter:
         self.device.fontmap=self.fontmap # hack
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
-        # 上面渲染的时候会根据 mediabox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
+        # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
         ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
         # if log.isEnabledFor(logging.DEBUG):
         #     log.debug(f'OP_BASE {ops_base}')
",fix pdf page interprettion,
eb7d93c63ecb48928dd5a02d11542fec556aa170,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.7""
+__version__ = ""1.4.8""
 __author__ = ""Byaidu""
",update version,
eb7d93c63ecb48928dd5a02d11542fec556aa170,converter.py,"@@ -572,7 +572,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         if cstk:
                             ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
-                    vy_regex=re.match(r'\$?\s*v([\d\s]+)\$',new[ptr:]) # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
+                    vy_regex=re.match(r'\$?\s*v([\d\s]+)\$',new[ptr:],re.IGNORECASE) # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
                     mod=False # 当前公式是否为文字修饰符
                     if vy_regex: # 加载公式
                         ptr+=len(vy_regex.group(0))
",add breakon,
acea685986f839606859efb736deee512c4c3efd,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.4.9""
+__version__ = ""1.5.0""
 __author__ = ""Byaidu""
",update version,
acea685986f839606859efb736deee512c4c3efd,converter.py,"@@ -120,12 +120,14 @@ class PDFLayoutAnalyzer(PDFTextDevice):
     def begin_figure(self, name: str, bbox: Rect, matrix: Matrix) -> None:
         self._stack.append(self.cur_item)
         self.cur_item = LTFigure(name, bbox, mult_matrix(matrix, self.ctm))
+        self.cur_item.pageid = self._stack[-1].pageid
 
     def end_figure(self, _: str) -> None:
         fig = self.cur_item
         assert isinstance(self.cur_item, LTFigure), str(type(self.cur_item))
         self.cur_item = self._stack.pop()
         self.cur_item.add(fig)
+        return self.receive_layout(fig)
 
     def render_image(self, name: str, stream: PDFStream) -> None:
         assert isinstance(self.cur_item, LTFigure), str(type(self.cur_item))
@@ -429,7 +431,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     fontname=child.fontname.split('+')[-1]
                     if vflag(fontname,child.get_text()): # 识别公式和字符
                         cur_v=True
-                    if child.matrix[:4]==(0,1,-1,0): # 竖直段落
+                    if child.matrix[0]==0 and child.matrix[3]==0: # 竖直段落
                         cur_v=True
                         ind_v=True
                         # print(child.get_text(),child.matrix[:4])
@@ -519,7 +521,6 @@ class TextConverter(PDFConverter[AnyIO]):
                     xt=child
                     xt_ind=ind_v
                 elif isinstance(child, LTFigure): # 图表
-                    # print(f'\n\n[FIGURE] {child.name}')
                     pass
                 elif isinstance(child, LTLine): # 线条
                     if vstk and abs(child.x0-xt.x0)<vmax and child.x1-child.x0<vmax and child.y0==child.y1 or xt_ind: # 公式线条
",add more info about the display,
acea685986f839606859efb736deee512c4c3efd,high_level.py,"@@ -147,8 +147,8 @@ def extract_text_to_fp(
         raise PDFValueError(msg)
 
     assert device is not None
-    interpreter = PDFPageInterpreter(rsrcmgr, device)
     obj_patch={}
+    interpreter = PDFPageInterpreter(rsrcmgr, device, obj_patch)
     if pages:
         total_pages=len(pages)
     else:
@@ -166,32 +166,10 @@ def extract_text_to_fp(
         layout[page.pageno]=page_layout
         # print(page.number,page_layout)
         page.rotate = (page.rotate + rotation) % 360
-        page_objids,ops_full=interpreter.process_page(page)
-        obj_patch[page_objids[0]]=ops_full
-        for objid in range(1,len(page_objids)):
-            obj_patch[page_objids[objid]]=f'{page_objids[objid]} 0 obj\n<<>>\nendobj\n'
-
-    # 用最后一页的page来解析doc
-    objs=[]
-    trailer=page.doc.xrefs[0].get_trailer()
-    for objid in range(1,trailer['Size']):
-        if objid in page.doc.xrefs[0].offsets:
-            (_, start, _) = page.doc.xrefs[0].get_pos(objid)
-            fp=page.doc._parser.fp
-            end, _=page.doc._getobj_parse(start,objid)
-            fp.seek(start)
-            raw=fp.read(end-start)
-            objs.append(raw)
-        else:
-            # print(f'OBJ {objid} missing')
-            objs.append(b'')
-    # 更新页面内容
-    for id,ops in obj_patch.items():
-        objs[id-1]=ops.encode()
-    # 编译文档
-    pdf_compile('output-zh.pdf',objs,trailer)
+        interpreter.process_page(page)
 
     device.close()
+    return obj_patch
 
 
 def extract_text(
",add extract_text_to_fp,
acea685986f839606859efb736deee512c4c3efd,pdf2zh.py,"@@ -76,17 +76,32 @@ def extract_text(
 
         doc_en = pymupdf.open(file)
         page_count=doc_en.page_count
+        font_list=['china-ss','tiro']
+        font_id={}
         for page in doc_en:
-            page.insert_font('china-ss')
-            page.insert_font('tiro')
-        doc_en.save('output-en.pdf')
-
-        with open('output-en.pdf', ""rb"") as fp:
-            pdf2zh.high_level.extract_text_to_fp(fp, **locals())
-
-        doc_en.close()
-        doc_zh = pymupdf.open('output-zh.pdf')
-        doc_dual = pymupdf.open('output-en.pdf')
+            for font in font_list:
+                font_id[font]=page.insert_font(font)
+        xreflen = doc_en.xref_length()
+        for xref in range(1, xreflen):
+            font_res=doc_en.xref_get_key(xref,'Resources/Font')
+            if font_res[0]=='dict':
+                for font in font_list:
+                    font_exist=doc_en.xref_get_key(xref,f'Resources/Font/{font}')
+                    if font_exist[0]=='null':
+                        try:
+                            doc_en.xref_set_key(xref,f'Resources/Font/{font}',f'{font_id[font]} 0 R')
+                        except:
+                            pass
+        doc_en.save(f'{filename}-en.pdf')
+
+        with open(f'{filename}-en.pdf', ""rb"") as fp:
+            obj_patch:dict=pdf2zh.high_level.extract_text_to_fp(fp, **locals())
+
+        for obj_id,ops_full in obj_patch.items():
+            doc_en.update_stream(obj_id,ops_full.encode())
+
+        doc_zh = doc_en
+        doc_dual = pymupdf.open(f'{filename}-en.pdf')
         doc_dual.insert_file(doc_zh)
         for id in range(page_count):
             doc_dual.move_page(page_count+id,id*2+1)
@@ -95,8 +110,7 @@ def extract_text(
         doc_zh.close()
         doc_dual.close()
 
-        os.remove('output-en.pdf')
-        os.remove('output-zh.pdf')
+        os.remove(f'{filename}-en.pdf')
 
     return
 
",add new extract_text function,
acea685986f839606859efb736deee512c4c3efd,pdfinterp.py,"@@ -367,12 +367,13 @@ class PDFPageInterpreter:
     Reference: PDF Reference, Appendix A, Operator Summary
     """"""
 
-    def __init__(self, rsrcmgr: PDFResourceManager, device: PDFDevice) -> None:
+    def __init__(self, rsrcmgr: PDFResourceManager, device: PDFDevice, obj_patch) -> None:
         self.rsrcmgr = rsrcmgr
         self.device = device
+        self.obj_patch = obj_patch
 
     def dup(self) -> ""PDFPageInterpreter"":
-        return self.__class__(self.rsrcmgr, self.device)
+        return self.__class__(self.rsrcmgr, self.device, self.obj_patch)
 
     def init_resources(self, resources: Dict[object, object]) -> None:
         """"""Prepare the fonts and XObjects listed in the Resource attribute.""""""
@@ -960,12 +961,18 @@ class PDFPageInterpreter:
             else:
                 resources = self.resources.copy()
             self.device.begin_figure(xobjid, bbox, matrix)
-            interpreter.render_contents(
+            ops_base=interpreter.render_contents(
                 resources,
                 [xobj],
                 ctm=mult_matrix(matrix, self.ctm),
             )
-            self.device.end_figure(xobjid)
+            self.device.fontmap=interpreter.fontmap # hack
+            try: # 有的时候 form 字体加不上这里会烂掉
+                ops_new=self.device.end_figure(xobjid)
+                xobjid=self.xobjmap[xobjid].objid
+                self.obj_patch[xobjid]=f'q {ops_base}Q 1 0 0 1 {-self.ctm[4]} {-self.ctm[5]} cm {ops_new}'
+            except:
+                pass
         elif subtype is LITERAL_IMAGE and ""Width"" in xobj and ""Height"" in xobj:
             self.device.begin_figure(xobjid, (0, 0, 1, 1), MATRIX_IDENTITY)
             self.device.render_image(xobjid, xobj)
@@ -993,12 +1000,9 @@ class PDFPageInterpreter:
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
         # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
-        ops_full=f'{page_objids[0]} 0 obj\n<<>>stream\nq {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}\nendstream\nendobj\n' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
-        # if log.isEnabledFor(logging.DEBUG):
-        #     log.debug(f'OP_BASE {ops_base}')
-        #     log.debug(f'OP_NEW {ops_new}')
-        #     log.debug(f'OP_FULL {ops_full}')
-        return page_objids,ops_full
+        self.obj_patch[page_objids[0]]=f'q {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
+        for objid in range(1,len(page_objids)):
+            self.obj_patch[page_objids[objid]]=''
 
     def render_contents(
         self,
",add support for xobj map in pdf page interpreter,
acea685986f839606859efb736deee512c4c3efd,utils.py,"@@ -286,7 +286,7 @@ def apply_matrix_norm(m: Matrix, v: Point) -> Point:
 
 def matrix_scale(m: Matrix) -> float:
     (a, b, c, d, e, f) = m
-    return (a**2+c*2)**0.5
+    return (a**2+c**2)**0.5
 
 #  Utility functions
 
",add missing docstring,
72f2c608e2b85cf6ce7b7d2a447fd0439b2d3c04,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.0""
+__version__ = ""1.5.1""
 __author__ = ""Byaidu""
",update version,
72f2c608e2b85cf6ce7b7d2a447fd0439b2d3c04,high_level.py,"@@ -5,7 +5,6 @@ import sys
 from io import StringIO
 from typing import Any, BinaryIO, Container, Iterator, Optional, cast
 import tqdm
-from pdf2zh.pdfcompiler import pdf_compile
 
 from pdf2zh.converter import (
     HOCRConverter,
",add missing import,
72f2c608e2b85cf6ce7b7d2a447fd0439b2d3c04,pdfcompiler.py,"@@ -1,17 +0,0 @@
-def pdf_compile(file:str,objs:list,trailer):
-    with open(file,'wb') as f:
-        xrefs=[]
-        f.write('%PDF-1.7\n'.encode())
-        for obj in objs:
-            xrefs.append(f.tell())
-            f.write(obj)
-        startxref=f.tell()
-        f.write(f'xref\n0 {len(objs)+1}\n0000000000 65536 f\n'.encode())
-        for id,xref in enumerate(xrefs):
-            if objs[id]==b'':
-                f.write(f'{xref:0>10d} 00001 f\n'.encode())
-            else:
-                f.write(f'{xref:0>10d} 00000 n\n'.encode())
-        f.write(f""trailer<<\n/Root {trailer['Root'].objid} 0 R\n/Info {trailer['Info'].objid} 0 R\n/Size {trailer['Size']}>>\n"".encode())
-        f.write(f'startxref\n{startxref}\n'.encode())
-        f.write('%%EOF\n'.encode())
\ No newline at end of file
",add support for xrefs in pdf_compile,
72f2c608e2b85cf6ce7b7d2a447fd0439b2d3c04,pdfinterp.py,"@@ -2,6 +2,7 @@ import logging
 import re
 from io import BytesIO
 from typing import Dict, List, Mapping, Optional, Sequence, Tuple, Union, cast
+import numpy as np
 
 from pdf2zh import settings
 from pdf2zh.casting import safe_float
@@ -961,16 +962,20 @@ class PDFPageInterpreter:
             else:
                 resources = self.resources.copy()
             self.device.begin_figure(xobjid, bbox, matrix)
+            ctm=mult_matrix(matrix, self.ctm)
             ops_base=interpreter.render_contents(
                 resources,
                 [xobj],
-                ctm=mult_matrix(matrix, self.ctm),
+                ctm=ctm,
             )
+            ctm_inv=np.linalg.inv(np.array(ctm[:4]).reshape(2,2))
             self.device.fontmap=interpreter.fontmap # hack
             try: # 有的时候 form 字体加不上这里会烂掉
                 ops_new=self.device.end_figure(xobjid)
-                xobjid=self.xobjmap[xobjid].objid
-                self.obj_patch[xobjid]=f'q {ops_base}Q 1 0 0 1 {-self.ctm[4]} {-self.ctm[5]} cm {ops_new}'
+                pos_inv=-np.mat(ctm[4:])*ctm_inv
+                a,b,c,d=ctm_inv.reshape(4).tolist()
+                e,f=pos_inv.tolist()[0]
+                self.obj_patch[self.xobjmap[xobjid].objid]=f'q {ops_base}Q {a} {b} {c} {d} {e} {f} cm {ops_new}'
             except:
                 pass
         elif subtype is LITERAL_IMAGE and ""Width"" in xobj and ""Height"" in xobj:
",add support for xobj with width and height,
29df2ce82d9bbd01800e5041652a13725bdf6460,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.1""
+__version__ = ""1.5.2""
 __author__ = ""Byaidu""
",update version,
29df2ce82d9bbd01800e5041652a13725bdf6460,converter.py,"@@ -412,7 +412,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R].*|MS.*|XY.*|MT.*|BL.*|RM.*|EU.*|LINE.*|rsfs.*|txsy.*|.*0700|.*0500|.*Mono|.*Ital|.*Sym|.*math)',font):
+                    if re.match(r'(CM[^R]|MS|XY|MT|BL|RM|EU|LA|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
",add more support for text converter,
29df2ce82d9bbd01800e5041652a13725bdf6460,pdfinterp.py,"@@ -968,10 +968,10 @@ class PDFPageInterpreter:
                 [xobj],
                 ctm=ctm,
             )
-            ctm_inv=np.linalg.inv(np.array(ctm[:4]).reshape(2,2))
-            self.device.fontmap=interpreter.fontmap # hack
             try: # 有的时候 form 字体加不上这里会烂掉
+                self.device.fontmap=interpreter.fontmap # hack
                 ops_new=self.device.end_figure(xobjid)
+                ctm_inv=np.linalg.inv(np.array(ctm[:4]).reshape(2,2))
                 pos_inv=-np.mat(ctm[4:])*ctm_inv
                 a,b,c,d=ctm_inv.reshape(4).tolist()
                 e,f=pos_inv.tolist()[0]
",fix bug in pdfpageinterpreter,
257f153628ab073403cbb1b168dd7d97389626f4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.3""
+__version__ = ""1.5.4""
 __author__ = ""Byaidu""
",update version,
257f153628ab073403cbb1b168dd7d97389626f4,converter.py,"@@ -436,10 +436,18 @@ class TextConverter(PDFConverter[AnyIO]):
                         cur_v=True
                         ind_v=True
                     layout=self.layout[ltpage.pageid]
-                    x0,y0,x1,y1=int(child.x0),int(ltpage.height-child.y0),int(child.x1),int(ltpage.height-child.y1)
-                    h,w=layout.shape
+                    h,w=layout.shape # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
+                    x0,y0,x1,y1=int(child.x0),int(h-child.y0),int(child.x1),int(h-child.y1)
                     y0=np.clip(y0,0,h-1);y1=np.clip(y1,0,h-1)
                     x0=np.clip(x0,0,w-1);x1=np.clip(x1,0,w-1)
+                    # if child.get_text()=='2':
+                    #     from PIL import Image, ImageDraw
+                    #     img=Image.fromarray(layout*255)
+                    #     img=img.convert('RGB')
+                    #     draw=ImageDraw.Draw(img)
+                    #     draw.rectangle([(x0,y1),(x1,y0)],ImageDraw.ImageColor.colormap['red'],ImageDraw.ImageColor.colormap['red'])
+                    #     img.show()
+                    #     input()
                     if layout[y0,x0] or layout[y0,x1] or layout[y1,x0] or layout[y1,x1]: # 识别图表和独立公式
                         cur_v=True
                         ind_v=True
",add text converter,
4d47beb7964b954c7a3e37ce0fd245edbec20a32,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.4""
+__version__ = ""1.5.5""
 __author__ = ""Byaidu""
",update version,
4d47beb7964b954c7a3e37ce0fd245edbec20a32,converter.py,"@@ -78,10 +78,11 @@ class Translator:
         self.headers = {'User-Agent':'Mozilla/4.0 (compatible;MSIE 6.0;Windows NT 5.1;SV1;.NET CLR 1.1.4322;.NET CLR 2.0.50727;.NET CLR 3.0.04506.30)'}
     
     def translate(self, to_translate, to_language=""auto"", from_language=""auto""):
+        to_translate=to_translate[:5000] # Max Length
         response = self.session.get(self.base_link, params={'tl':to_language,'sl':from_language,'q':to_translate}, headers=self.headers)
         re_result = re.findall(r'(?s)class=""(?:t0|result-container)"">(.*?)<', response.text)
         if len(re_result) == 0:
-            result = """"
+            raise ValueError('Empty translation result')
         else:
             result = html.unescape(re_result[0])
         return result
@@ -389,9 +390,6 @@ class TextConverter(PDFConverter[AnyIO]):
     def receive_layout(self, ltpage: LTPage):
         def render(item: LTItem) -> None:
             xt=None # 上一个字符
-            lt=None # 段落左边界
-            rt=None # 段落右边界
-            dt=None # 段落下边界
             sstk=[] # 段落文字栈
             vstk=[] # 公式符号组
             vlstk=[] # 公式线条组
@@ -403,7 +401,7 @@ class TextConverter(PDFConverter[AnyIO]):
             varl=[] # 公式线条组栈
             varf=[] # 公式纵向偏移栈
             vlen=[] # 公式宽度栈
-            xt_ind=False # 上一个字符是否属于独立公式
+            xt_cls=-1 # 上一个字符是否属于独立公式
             vmax=ltpage.width/4 # 行内公式最大宽度
             ops="""" # 渲染结果
             def vflag(font,char): # 匹配公式（和角标）字体
@@ -428,45 +426,27 @@ class TextConverter(PDFConverter[AnyIO]):
                 child=item[ptr]
                 if isinstance(child, LTChar):
                     cur_v=False # 公式
-                    ind_v=False # 独立公式
                     fontname=child.fontname.split('+')[-1]
-                    if vflag(fontname,child.get_text()): # 识别公式和字符
-                        cur_v=True
-                    if child.matrix[0]==0 and child.matrix[3]==0: # 竖直段落
-                        cur_v=True
-                        ind_v=True
                     layout=self.layout[ltpage.pageid]
                     h,w=layout.shape # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
-                    x0,y0,x1,y1=int(child.x0),int(h-child.y0),int(child.x1),int(h-child.y1)
-                    y0=np.clip(y0,0,h-1);y1=np.clip(y1,0,h-1)
-                    x0=np.clip(x0,0,w-1);x1=np.clip(x1,0,w-1)
-                    # if child.get_text()=='2':
-                    #     from PIL import Image, ImageDraw
-                    #     img=Image.fromarray(layout*255)
-                    #     img=img.convert('RGB')
-                    #     draw=ImageDraw.Draw(img)
-                    #     draw.rectangle([(x0,y1),(x1,y0)],ImageDraw.ImageColor.colormap['red'],ImageDraw.ImageColor.colormap['red'])
-                    #     img.show()
-                    #     input()
-                    if layout[y0,x0] or layout[y0,x1] or layout[y1,x0] or layout[y1,x1]: # 识别图表和独立公式
+                    cx,cy=np.clip(int(child.x0),0,w-1),np.clip(int(child.y0),0,h-1)
+                    cls=layout[cy,cx]
+                    # if log.isEnabledFor(logging.DEBUG):
+                    #     ops+=f'ET [] 0 d 0 J 0.1 w {child.x0} {child.y0} {child.x1-child.x0} {child.y1-child.y0} re S Q BT '
+                    if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.8) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0):
                         cur_v=True
-                        ind_v=True
-                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，判定括号组是否属于公式
+                    if not cur_v: # 判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
                             cur_v=True
                             vbkt+=1
                         if vbkt and child.get_text()==')':
                             cur_v=True
                             vbkt-=1
-                    if not cur_v or (ind_v ^ xt_ind) or (vstk and (abs(child.x0-xt.x0)>vmax or abs(child.y0-xt.y0)>vmax) and not ind_v): # 公式结束、独立公式边界或公式换行截断
+                    if not cur_v or cls!=xt_cls or (abs(child.x0-xt.x0)>vmax and cls!=0): # 公式结束、段落边界、公式换行
                         if vstk: # 公式出栈
-                            sstk_bak=sstk[-1]
-                            vfix_bak=vfix
-                            lt_bak,rt_bak,dt_bak=lt,rt,dt
                             sstk[-1]+=f'$v{len(var)}$'
-                            if child.x0>max([vch.x0 for vch in vstk]) and child.y0<vstk[0].y1 and not cur_v and vstk[0].y0-child.y0<child.size: # 行内公式修正，这里要考虑正好换行的情况
+                            if not cur_v and cls==xt_cls and child.x0>max([vch.x0 for vch in vstk]): # and child.y1>vstk[0].y0: # 段落内公式转文字，行内公式修正
                                 vfix=vstk[0].y0-child.y0
-                                # print(sstk[-1],vfix)
                             var.append(vstk)
                             varl.append(vlstk)
                             varf.append(vfix)
@@ -474,63 +454,38 @@ class TextConverter(PDFConverter[AnyIO]):
                             vlstk=[]
                             vfix=0
                     if not vstk: # 非公式或是公式开头
-                        if not (ind_v ^ xt_ind) and xt and child.y1 > dt.y0 - min(child.size,xt.size)*0.45 and child.y0 < xt.y1 + min(child.size,xt.size): # 非独立公式边界且位于同段落，事实上不存在 ind_v 与 xt_ind 同真但 vstk 被出栈清空的情况，所以这里用 or 也是可以的
-                            if child.x0 > xt.x1 + child.size*2: # 行内分离
-                                lt,rt,dt=child,child,child
-                                sstk.append("""")
-                                pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                            elif child.x0 > xt.x1 + 1 and not (child.size<pstk[-1][4]*0.9): # 行内空格，小字体不加空格，因为可能会影响到下面的还原操作
+                        if cls==xt_cls: # 同一段落
+                            if child.x0 > xt.x1 + 1: # 行内空格
                                 sstk[-1]+=' '
-                            elif child.x1 < xt.x0 and not (child.size<pstk[-1][4]*0.9 and xt.size<pstk[-1][4]*0.9 and abs(child.x0-xt.x0)<vmax): # 换行，这里需要考虑一下字母修饰符的情况，连续小字体不换行解决分式问题
-                                if child.x0 < lt.x0 - child.size*2 or child.x0 > lt.x0 + child.size*1: # 基于初始位置的行间分离
-                                    lt,rt,dt=child,child,child
-                                    sstk.append("""")
-                                    pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                                else: # 换行空格
-                                    sstk[-1]+=' '
-                                    pstk[-1][6]=True # 标记原文段落存在换行
-                        else: # 基于纵向距离的行间分离
-                            lt,rt,dt=child,child,child
+                            elif child.x1 < xt.x0: # 换行空格
+                                sstk[-1]+=' '
+                                pstk[-1][6]=True # 标记原文段落存在换行
+                        else:
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
-                    if not cur_v: #and re.match(r'CMR',fontname): # 根治正文 CMR 字体的懒狗编译器，这里先排除一下独立公式。因为经常会有 CMR 以外的其他小角标比如 d_model，所以这里不锁字体
-                        if child.size<pstk[-1][4]*0.9: # and sstk[-1]: # 公式内文字，考虑浮点误差，如果比段落字体小，说明肯定没有重开段落，不需要再判断一次
-                            cur_v=True
-                            # 这里应该保证行内公式不要被空格随意打断变成两个连着的公式标记，要不然根据 xt 计算 vfix 修正的策略就不对了
-                            if sstk[-1][-1]=='$': # 结尾是 $ 说明触发了上面的出栈，公式被错误打断（如果公式换行结尾会是空格），这里需要还原状态
-                                sstk[-1]=sstk_bak
-                                vfix=vfix_bak
-                                vstk=var.pop()
-                                vlstk=varl.pop()
-                                varf.pop()
-                                lt,rt,dt=lt_bak,rt_bak,dt_bak
                     if not cur_v: # 文字入栈
-                        if child.size>pstk[-1][4]*1.1 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
+                        if child.size>pstk[-1][4]/0.8 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
                             pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
                         sstk[-1]+=child.get_text()
                     else: # 公式入栈
-                        # 可能是 CMR 角标，需要在完全确定 cur_v 之后再计算修正，有些下角标可能需要向下的修正
-                        if not vstk and sstk[-1]: # 公式开头，不是段落开头
-                            if child.x0>xt.x0 and child.y1>xt.y0: # and cur_v: # and child.y0-xt.y0<xt.size: # 行内公式修正，前面已经判定过位于同一段落，所以不需要限制 y 范围
-                                vfix=child.y0-xt.y0
+                        if not vstk and cls==xt_cls and child.x0>xt.x0: # and child.y1>xt.y0: # 段落内文字转公式，行内公式修正
+                            vfix=child.y0-xt.y0
                         vstk.append(child)
-                    # 更新段落边界，段落内换行之后可能是公式开头，如果不更新 dt 后面换行检测会出错
-                    if child.x0<lt.x0:
-                        pstk[-1][2]=child.x0
-                        lt=child
-                    if child.x1>rt.x1:
-                        pstk[-1][3]=child.x1
-                        rt=child
-                    if child.y0<dt.y0:
-                        dt=child
+                    # 更新段落边界，段落内换行之后可能是公式开头
+                    pstk[-1][2]=min(pstk[-1][2],child.x0)
+                    pstk[-1][3]=max(pstk[-1][3],child.x1)
                     xt=child
-                    xt_ind=ind_v
+                    xt_cls=cls
                 elif isinstance(child, LTFigure): # 图表
                     pass
                 elif isinstance(child, LTLine): # 线条
-                    if vstk and abs(child.x0-xt.x0)<vmax and child.x1-child.x0<vmax and child.y0==child.y1 or xt_ind: # 公式线条
+                    layout=self.layout[ltpage.pageid]
+                    h,w=layout.shape # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
+                    cx,cy=np.clip(int(child.x0),0,w-1),np.clip(int(child.y0),0,h-1)
+                    cls=layout[cy,cx]
+                    if vstk and cls==xt_cls: # 公式线条
                         vlstk.append(child)
                     else: # 全局线条
                         lstk.append(child)
@@ -619,7 +574,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
-                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2}
+                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2}
                         y-=size*lang_space.get(self.lang_out,1.4)
                     if vy_regex: # 插入公式
                         fix=0
",add docstrings for tools/text.py,
4d47beb7964b954c7a3e37ce0fd245edbec20a32,high_level.py,"@@ -163,14 +163,19 @@ def extract_text_to_fp(
         image = np.fromstring(pix.samples, np.uint8).reshape(pix.height, pix.width, 3)
         page_layout=model.predict(image)[0]
         # kdtree 是不可能 kdtree 的，不如直接渲染成图片，用空间换时间
-        box=np.zeros((pix.height, pix.width))
+        box=np.ones((pix.height, pix.width))
         h,w=box.shape
-        for d in page_layout.boxes:
-            if page_layout.names[int(d.cls)] in ['abandon','figure','table','isolate_formula','formula_caption']:
-                x0,y0,x1,y1=[int(i) for i in d.xyxy.squeeze().long()]
-                y0=np.clip(y0,0,h-1);y1=np.clip(y1,0,h-1)
-                x0=np.clip(x0,0,w-1);x1=np.clip(x1,0,w-1)
-                box[y0:y1,x0:x1]=1
+        vcls=['abandon','figure','table','isolate_formula','formula_caption']
+        for i,d in enumerate(page_layout.boxes):
+            if not page_layout.names[int(d.cls)] in vcls:
+                x0,y0,x1,y1=d.xyxy.squeeze()
+                x0,y0,x1,y1=np.clip(int(x0-1),0,w-1),np.clip(int(h-y1-1),0,h-1),np.clip(int(x1+1),0,w-1),np.clip(int(h-y0+1),0,h-1)
+                box[y0:y1,x0:x1]=i+2
+        for i,d in enumerate(page_layout.boxes):
+            if page_layout.names[int(d.cls)] in vcls:
+                x0,y0,x1,y1=d.xyxy.squeeze()
+                x0,y0,x1,y1=np.clip(int(x0-1),0,w-1),np.clip(int(h-y1-1),0,h-1),np.clip(int(x1+1),0,w-1),np.clip(int(h-y0+1),0,h-1)
+                box[y0:y1,x0:x1]=0
         layout[page.pageno]=box
         # print(page.number,page_layout)
         page.rotate = (page.rotate + rotation) % 360
",add kdtree,
af86fbbac83eee7960bed030d66f816ecd3cf429,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.5""
+__version__ = ""1.5.6""
 __author__ = ""Byaidu""
",update version,
af86fbbac83eee7960bed030d66f816ecd3cf429,converter.py,"@@ -417,7 +417,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\+|=|[\u0080-\u2017]|[\u2020-\ufaff])',char): # 过滤半角字符、风格连字以及 unicode 引号。公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
+                    if re.match(r'(\+|=)',char) or (char and unicodedata.category(char[0]) in ['Lm','Sk','Mn']): # 公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
                         return True
                 return False
             ptr=0
@@ -554,17 +554,17 @@ class TextConverter(PDFConverter[AnyIO]):
                         # if font.char_width(ord(ch)):
                         fcur_=None
                         try:
-                            # 1.有些字体会设置非 0 缺省宽度，所以这里直接查一下宽度字典
-                            # 2.有些字体不使用标准 unicode 编码，这里校验一下
                             if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
                                 fcur_=font.fontid # 原字体
                         except:
                             pass
-                        if fcur_==None:
-                            if re.match(r'[\u0000-\u007f]',ch): # 半角符号
+                        try:
+                            if fcur_==None and self.fontmap['tiro'].to_unichr(ord(ch))==ch:
                                 fcur_='tiro' # 默认英文字体
-                            else:
-                                fcur_='china-ss' # 默认中文字体
+                        except:
+                            pass
+                        if fcur_==None:
+                            fcur_='china-ss' # 默认中文字体
                         # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
@@ -574,8 +574,8 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
-                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2}
-                        y-=size*lang_space.get(self.lang_out,1.4)
+                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2,'it':1.0}
+                        y-=size*lang_space.get(self.lang_out,1.2)
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正纵向偏移
",add support for CMR and CMY,
124ce13893e8ad78d2b7ed7555b22e36bb7460bb,converter.py,"@@ -417,7 +417,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if re.match(r'(\+|=)',char) or (char and unicodedata.category(char[0]) in ['Lm','Sk','Mn']): # 公式加号和等号对应 CMR 而且不会出现在正文，公式减号对应 CMSY 不用考虑
+                    if char and unicodedata.category(char[0]) in ['Lm','Mn','Sk','Sm']:
                         return True
                 return False
             ptr=0
@@ -547,7 +547,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             adv=vlen[vid]
                         except:
                             continue # 翻译器可能会自动补个越界的公式标记
-                        if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Sk','Mn']: # 文字修饰符，get_text 可能返回 cid，这里截断一下
+                        if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Mn','Sk']: # 文字修饰符，get_text 可能返回 cid，这里截断一下
                             mod=True
                     else: # 加载文字
                         ch=new[ptr]
",add support for cierarian text,
40b0560bd214fa39d39af89c243b106f453fcdae,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.6""
+__version__ = ""1.5.7""
 __author__ = ""Byaidu""
",update version,
40b0560bd214fa39d39af89c243b106f453fcdae,converter.py,"@@ -401,7 +401,7 @@ class TextConverter(PDFConverter[AnyIO]):
             varl=[] # 公式线条组栈
             varf=[] # 公式纵向偏移栈
             vlen=[] # 公式宽度栈
-            xt_cls=-1 # 上一个字符是否属于独立公式
+            xt_cls=-1 # 上一个字符所属段落
             vmax=ltpage.width/4 # 行内公式最大宽度
             ops="""" # 渲染结果
             def vflag(font,char): # 匹配公式（和角标）字体
@@ -417,7 +417,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if char and unicodedata.category(char[0]) in ['Lm','Mn','Sk','Sm']:
+                    if char and char!=' ' and unicodedata.category(char[0]) in ['Lm','Mn','Sk','Sm','Zl','Zp','Zs']: # 文字修饰符、数学符号、分隔符号
                         return True
                 return False
             ptr=0
@@ -547,7 +547,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             adv=vlen[vid]
                         except:
                             continue # 翻译器可能会自动补个越界的公式标记
-                        if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Mn','Sk']: # 文字修饰符，get_text 可能返回 cid，这里截断一下
+                        if len(var[vid])==1 and unicodedata.category(var[vid][0].get_text()[0]) in ['Lm','Mn','Sk']: # 文字修饰符
                             mod=True
                     else: # 加载文字
                         ch=new[ptr]
","add support for 公式线条组栈, 公式线条组栈, 公式线条组栈, 公式线条组栈, 公式线条�",
3739721285b580654d119518212e0173668b2eae,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.7""
+__version__ = ""1.5.8""
 __author__ = ""Byaidu""
",update version,
3739721285b580654d119518212e0173668b2eae,converter.py,"@@ -574,7 +574,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
-                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2,'it':1.0}
+                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2,'it':1.1}
                         y-=size*lang_space.get(self.lang_out,1.2)
                     if vy_regex: # 插入公式
                         fix=0
",add support for japanese language space,
3739721285b580654d119518212e0173668b2eae,high_level.py,"@@ -161,7 +161,10 @@ def extract_text_to_fp(
     ), total=total_pages, position=0):
         pix = doc_en[page.pageno].get_pixmap()
         image = np.fromstring(pix.samples, np.uint8).reshape(pix.height, pix.width, 3)
-        page_layout=model.predict(image)[0]
+        page_layout=model.predict(
+            image,
+            imgsz=int(pix.height/32)*32,
+        )[0]
         # kdtree 是不可能 kdtree 的，不如直接渲染成图片，用空间换时间
         box=np.ones((pix.height, pix.width))
         h,w=box.shape
",add kdtree,
5c0434a62f4cc983a41351249550817a6113f445,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.5.8""
+__version__ = ""1.5.9""
 __author__ = ""Byaidu""
",update version,
5c0434a62f4cc983a41351249550817a6113f445,converter.py,"@@ -555,7 +555,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         fcur_=None
                         try:
                             if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
-                                fcur_=font.fontid # 原字体
+                                fcur_=self.fontid[font] # 原字体
                         except:
                             pass
                         try:
@@ -565,7 +565,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             pass
                         if fcur_==None:
                             fcur_='china-ss' # 默认中文字体
-                        # print(font.fontid,fcur_,ch,font.char_width(ord(ch)))
+                        # print(self.fontid[font],fcur_,ch,font.char_width(ord(ch)))
                         adv=self.fontmap[fcur_].char_width(ord(ch))*size
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt+0.1*size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
@@ -582,7 +582,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             fix=varf[vid]
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
-                            ops+=f""/{vch.font.fontid} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(vch.font.fontid,vc)}>] TJ ""
+                            ops+=f""/{self.fontid[vch.font]} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(self.fontid[vch.font],vc)}>] TJ ""
                             if log.isEnabledFor(logging.DEBUG):
                                 lstk.append(LTLine(0.1,(_x,_y),(x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0)))
                                 _x,_y=x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0
",add fix for text converter,
5c0434a62f4cc983a41351249550817a6113f445,pdf2zh.py,"@@ -85,15 +85,16 @@ def extract_text(
                 font_id[font]=page.insert_font(font)
         xreflen = doc_en.xref_length()
         for xref in range(1, xreflen):
-            font_res=doc_en.xref_get_key(xref,'Resources/Font')
-            if font_res[0]=='dict':
-                for font in font_list:
-                    font_exist=doc_en.xref_get_key(xref,f'Resources/Font/{font}')
-                    if font_exist[0]=='null':
-                        try:
-                            doc_en.xref_set_key(xref,f'Resources/Font/{font}',f'{font_id[font]} 0 R')
-                        except:
-                            pass
+            for label in ['Resources/','']: # 可能是基于 xobj 的 res
+                font_res=doc_en.xref_get_key(xref,f'{label}Font')
+                if font_res[0]=='dict':
+                    for font in font_list:
+                        font_exist=doc_en.xref_get_key(xref,f'{label}Font/{font}')
+                        if font_exist[0]=='null':
+                            try:
+                                doc_en.xref_set_key(xref,f'{label}Font/{font}',f'{font_id[font]} 0 R')
+                            except:
+                                pass
         doc_en.save(f'{filename}-en.pdf')
 
         with open(f'{filename}-en.pdf', ""rb"") as fp:
",add missing xobj,
5c0434a62f4cc983a41351249550817a6113f445,pdfinterp.py,"@@ -380,6 +380,7 @@ class PDFPageInterpreter:
         """"""Prepare the fonts and XObjects listed in the Resource attribute.""""""
         self.resources = resources
         self.fontmap: Dict[object, PDFFont] = {}
+        self.fontid: Dict[PDFFont, object] = {}
         self.xobjmap = {}
         self.csmap: Dict[str, PDFColorSpace] = PREDEFINED_COLORSPACE.copy()
         if not resources:
@@ -406,7 +407,7 @@ class PDFPageInterpreter:
                         objid = spec.objid
                     spec = dict_value(spec)
                     self.fontmap[fontid] = self.rsrcmgr.get_font(objid, spec)
-                    self.fontmap[fontid].fontid=fontid # hack
+                    self.fontid[self.fontmap[fontid]]=fontid
             elif k == ""ColorSpace"":
                 for csid, spec in dict_value(v).items():
                     colorspace = get_colorspace(resolve1(spec))
@@ -969,7 +970,8 @@ class PDFPageInterpreter:
                 ctm=ctm,
             )
             try: # 有的时候 form 字体加不上这里会烂掉
-                self.device.fontmap=interpreter.fontmap # hack
+                self.device.fontid=interpreter.fontid
+                self.device.fontmap=interpreter.fontmap
                 ops_new=self.device.end_figure(xobjid)
                 ctm_inv=np.linalg.inv(np.array(ctm[:4]).reshape(2,2))
                 pos_inv=-np.mat(ctm[4:])*ctm_inv
@@ -1001,7 +1003,8 @@ class PDFPageInterpreter:
             ctm = (1, 0, 0, 1, -x0, -y0)
         self.device.begin_page(page, ctm)
         ops_base=self.render_contents(page.resources, page.contents, ctm=ctm)
-        self.device.fontmap=self.fontmap # hack
+        self.device.fontid=self.fontid
+        self.device.fontmap=self.fontmap
         ops_new=self.device.end_page(page)
         page_objids=[i.objid for i in page.contents]
         # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
",add support for colorspace and fontmap,
7e40cbf437010b281e882841ba8105443271405a,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.1""
+__version__ = ""1.6.2""
 __author__ = ""Byaidu""
",update version,
7e40cbf437010b281e882841ba8105443271405a,converter.py,"@@ -416,7 +416,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     cx,cy=np.clip(int(child.x0),0,w-1),np.clip(int(child.y0),0,h-1)
                     cls=layout[cy,cx]
                     # if log.isEnabledFor(logging.DEBUG):
-                    #     ops+=f'ET [] 0 d 0 J 0.1 w {child.x0} {child.y0} {child.x1-child.x0} {child.y1-child.y0} re S Q BT '
+                    #     ops+=f'ET [] 0 d 0 J 0.1 w {child.x0:f} {child.y0:f} {child.x1-child.x0:f} {child.y1-child.y0:f} re S Q BT '
                     if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.8) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0):
                         cur_v=True
                     if not cur_v: # 判定括号组是否属于公式
@@ -520,7 +520,7 @@ class TextConverter(PDFConverter[AnyIO]):
                 while True:
                     if ptr==len(new): # 到达段落结尾
                         if cstk:
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
+                            ops+=f'/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur,cstk)}>] TJ '
                         break
                     vy_regex=re.match(r'\$?\s*v([\d\s]+)\$',new[ptr:],re.IGNORECASE) # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
                     mod=False # 当前公式是否为文字修饰符
@@ -554,7 +554,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         ptr+=1
                     if fcur_!=fcur or vy_regex or x+adv>rt+0.1*size: # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
                         if cstk:
-                            ops+=f'/{fcur} {size} Tf 1 0 0 1 {tx} {y} Tm [<{raw_string(fcur,cstk)}>] TJ '
+                            ops+=f'/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur,cstk)}>] TJ '
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
@@ -566,13 +566,13 @@ class TextConverter(PDFConverter[AnyIO]):
                             fix=varf[vid]
                         for vch in var[vid]: # 排版公式字符
                             vc=chr(vch.cid)
-                            ops+=f""/{self.fontid[vch.font]} {vch.size} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0} {fix+y+vch.y0-var[vid][0].y0} Tm [<{raw_string(self.fontid[vch.font],vc)}>] TJ ""
+                            ops+=f""/{self.fontid[vch.font]} {vch.size:f} Tf 1 0 0 1 {x+vch.x0-var[vid][0].x0:f} {fix+y+vch.y0-var[vid][0].y0:f} Tm [<{raw_string(self.fontid[vch.font],vc)}>] TJ ""
                             if log.isEnabledFor(logging.DEBUG):
                                 lstk.append(LTLine(0.1,(_x,_y),(x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0)))
                                 _x,_y=x+vch.x0-var[vid][0].x0,fix+y+vch.y0-var[vid][0].y0
                         for l in varl[vid]: # 排版公式线条
                             if l.linewidth<5: # hack
-                                ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0} {l.pts[0][1]+fix+y-var[vid][0].y0} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
+                                ops+=f""ET q 1 0 0 1 {l.pts[0][0]+x-var[vid][0].x0:f} {l.pts[0][1]+fix+y-var[vid][0].y0:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0]-l.pts[0][0]:f} {l.pts[1][1]-l.pts[0][1]:f} l S Q BT ""
                     else: # 插入文字缓冲区
                         if not cstk: # 单行开头
                             tx=x
@@ -591,7 +591,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         _x,_y=x,y
             for l in lstk: # 排版全局线条
                 if l.linewidth<5: # hack
-                    ops+=f""ET q 1 0 0 1 {l.pts[0][0]} {l.pts[0][1]} cm [] 0 d 0 J {l.linewidth} w 0 0 m {l.pts[1][0]-l.pts[0][0]} {l.pts[1][1]-l.pts[0][1]} l S Q BT ""
+                    ops+=f""ET q 1 0 0 1 {l.pts[0][0]:f} {l.pts[0][1]:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0]-l.pts[0][0]:f} {l.pts[1][1]-l.pts[0][1]:f} l S Q BT ""
             ops=f'BT {ops}ET '
             return ops
         ops=render(ltpage)
",add support for vflag in text converter,
7e40cbf437010b281e882841ba8105443271405a,pdf2zh.py,"@@ -101,8 +101,12 @@ def extract_text(
         with open(f'{filename}-en.pdf', ""rb"") as fp:
             obj_patch:dict=pdf2zh.high_level.extract_text_to_fp(fp, **locals())
 
-        for obj_id,ops_full in obj_patch.items():
-            doc_en.update_stream(obj_id,ops_full.encode())
+        for obj_id,ops_new in obj_patch.items():
+            # ops_old=doc_en.xref_stream(obj_id)
+            doc_en.update_stream(obj_id,ops_new.encode())
+            # print(obj_id)
+            # print(ops_old)
+            # print(ops_new.encode())
 
         doc_zh = doc_en
         doc_dual = pymupdf.open(f'{filename}-en.pdf')
",add example,
7e40cbf437010b281e882841ba8105443271405a,pdfinterp.py,"@@ -1058,15 +1058,15 @@ class PDFPageInterpreter:
                         # log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
-                            if not name in ['TJ','Tj','Tm','Tf']:
-                                p="" "".join([str(x).replace(""\'"","""") for x in args])
+                            if not (name[0]=='T' or name in ['""',""'"",'EI']): # 过滤 T 系列文字指令，因为 EI 的参数是 obj 所以也需要过滤（只在少数文档中画横线时使用）
+                                p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""\'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
                         # log.debug(""exec: %s"", name)
                         targs=func()
                         if targs==None:
                             targs=[]
-                        p="" "".join([str(x).replace(""\'"","""") for x in targs])
+                        p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""\'"","""") for x in targs])
                         ops+=f'{p} {name} '
                 elif settings.STRICT:
                     error_msg = ""Unknown operator: %r"" % name
",add support for t j m f and t jm,
d45bffa04a94dfff74877685004147dbf6e17750,converter.py,"@@ -417,7 +417,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     cls=layout[cy,cx]
                     # if log.isEnabledFor(logging.DEBUG):
                     #     ops+=f'ET [] 0 d 0 J 0.1 w {child.x0:f} {child.y0:f} {child.x1-child.x0:f} {child.y1-child.y0:f} re S Q BT '
-                    if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.8) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0):
+                    if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.75) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0):
                         cur_v=True
                     if not cur_v: # 判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
@@ -448,7 +448,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                     if not cur_v: # 文字入栈
-                        if child.size>pstk[-1][4]/0.8 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
+                        if child.size>pstk[-1][4]/0.75 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
                             pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
",add support for text converter with no matrix,
d45bffa04a94dfff74877685004147dbf6e17750,pdfinterp.py,"@@ -1059,14 +1059,14 @@ class PDFPageInterpreter:
                         if len(args) == nargs:
                             func(*args)
                             if not (name[0]=='T' or name in ['""',""'"",'EI']): # 过滤 T 系列文字指令，因为 EI 的参数是 obj 所以也需要过滤（只在少数文档中画横线时使用）
-                                p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""\'"","""") for x in args])
+                                p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
                         # log.debug(""exec: %s"", name)
                         targs=func()
                         if targs==None:
                             targs=[]
-                        p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""\'"","""") for x in targs])
+                        p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in targs])
                         ops+=f'{p} {name} '
                 elif settings.STRICT:
                     error_msg = ""Unknown operator: %r"" % name
",add support for t and ei operators,
f458a0c742d2bbbc396803a603cab9ee755541e5,converter.py,"@@ -558,8 +558,8 @@ class TextConverter(PDFConverter[AnyIO]):
                             cstk=''
                     if lb and x+adv>rt+0.1*size: # 到达右边界且原文段落存在换行
                         x=lt
-                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2,'it':1.1}
-                        y-=size*lang_space.get(self.translator.lang_out,1.2)
+                        lang_space={'zh-CN':1.4,'zh-TW':1.4,'ja':1.1,'ko':1.2,'en':1.2} # CJK
+                        y-=size*lang_space.get(self.translator.lang_out,1.1) # 小语种大多适配 1.1
                     if vy_regex: # 插入公式
                         fix=0
                         if fcur!=None: # 段落内公式修正纵向偏移
",add support for japanese and japanese japanese,
6a4a05161e213222c5d41e07f2ebef9b25885afe,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.3""
+__version__ = ""1.6.4""
 __author__ = ""Byaidu""
",update version,
6a4a05161e213222c5d41e07f2ebef9b25885afe,converter.py,"@@ -395,7 +395,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vfont,font):
                         return True
                 else:
-                    if re.match(r'(CM[^R]|MS|XY|MT|BL|RM|EU|LA|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)',font):
+                    if re.match(r'(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)',font):
                         return True
                 if self.vchar:
                     if re.match(self.vchar,char):
@@ -417,7 +417,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     cls=layout[cy,cx]
                     # if log.isEnabledFor(logging.DEBUG):
                     #     ops+=f'ET [] 0 d 0 J 0.1 w {child.x0:f} {child.y0:f} {child.x1-child.x0:f} {child.y1-child.y0:f} re S Q BT '
-                    if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.75) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0):
+                    if cls==0 or (cls==xt_cls and child.size<pstk[-1][4]*0.79) or vflag(fontname,child.get_text()) or (child.matrix[0]==0 and child.matrix[3]==0): # 有 0.76 的角标和 0.799 的大写，这里用 0.79 取中
                         cur_v=True
                     if not cur_v: # 判定括号组是否属于公式
                         if vstk and child.get_text()=='(':
@@ -448,7 +448,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             sstk.append("""")
                             pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False])
                     if not cur_v: # 文字入栈
-                        if child.size>pstk[-1][4]/0.75 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
+                        if child.size>pstk[-1][4]/0.79 or vflag(pstk[-1][5].fontname.split('+')[-1],'') or re.match(r'(.*Medi|.*Bold)',pstk[-1][5].fontname.split('+')[-1],re.IGNORECASE): # 小字体、公式或粗体开头，后续接文字，需要校正字体
                             pstk[-1][0]-=child.size-pstk[-1][4]
                             pstk[-1][4]=child.size
                             pstk[-1][5]=child.font
",add v flag to text converter,
0d008f1f4d7d5bd561a729accdd37f7f676fbfc5,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.4""
+__version__ = ""1.6.5""
 __author__ = ""Byaidu""
",update version,
0d008f1f4d7d5bd561a729accdd37f7f676fbfc5,converter.py,"@@ -537,11 +537,12 @@ class TextConverter(PDFConverter[AnyIO]):
                         ch=new[ptr]
                         # if font.char_width(ord(ch)):
                         fcur_=None
-                        try:
-                            if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
-                                fcur_=self.fontid[font] # 原字体
-                        except:
-                            pass
+                        # 原字体编码容易出问题，这里直接放弃掉
+                        # try:
+                        #     if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
+                        #         fcur_=self.fontid[font] # 原字体
+                        # except:
+                        #     pass
                         try:
                             if fcur_==None and self.fontmap['tiro'].to_unichr(ord(ch))==ch:
                                 fcur_='tiro' # 默认英文字体
",add support for titan font,
96ffb2827360a8c3e4e8ff81403e92747656aa14,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.5""
+__version__ = ""1.6.6""
 __author__ = ""Byaidu""
",update version,
96ffb2827360a8c3e4e8ff81403e92747656aa14,pdf2zh.py,"@@ -103,10 +103,10 @@ def extract_text(
 
         for obj_id,ops_new in obj_patch.items():
             # ops_old=doc_en.xref_stream(obj_id)
-            doc_en.update_stream(obj_id,ops_new.encode())
             # print(obj_id)
             # print(ops_old)
             # print(ops_new.encode())
+            doc_en.update_stream(obj_id,ops_new.encode())
 
         doc_zh = doc_en
         doc_dual = pymupdf.open(f'{filename}-en.pdf')
",update text.py,
96ffb2827360a8c3e4e8ff81403e92747656aa14,pdfinterp.py,"@@ -1058,7 +1058,7 @@ class PDFPageInterpreter:
                         # log.debug(""exec: %s %r"", name, args)
                         if len(args) == nargs:
                             func(*args)
-                            if not (name[0]=='T' or name in ['""',""'"",'EI']): # 过滤 T 系列文字指令，因为 EI 的参数是 obj 所以也需要过滤（只在少数文档中画横线时使用）
+                            if not (name[0]=='T' or name in ['""',""'"",'EI','MP','DP','BMC','BDC']): # 过滤 T 系列文字指令，因为 EI 的参数是 obj 所以也需要过滤（只在少数文档中画横线时使用），过滤 marked 系列指令
                                 p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in args])
                                 ops+=f'{p} {name} '
                     else:
@@ -1066,8 +1066,9 @@ class PDFPageInterpreter:
                         targs=func()
                         if targs==None:
                             targs=[]
-                        p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in targs])
-                        ops+=f'{p} {name} '
+                        if not name in ['EMC']:
+                            p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in targs])
+                            ops+=f'{p} {name} '
                 elif settings.STRICT:
                     error_msg = ""Unknown operator: %r"" % name
                     raise PDFInterpreterError(error_msg)
",add 参数指令参数指令参数指令参数指令参数指令参数指令参数指令参数指令,
01071869285d83d58b4d7f0957f7d75bbb7b4b7d,pdfinterp.py,"@@ -1066,7 +1066,7 @@ class PDFPageInterpreter:
                         targs=func()
                         if targs==None:
                             targs=[]
-                        if not name in ['EMC']:
+                        if not (name[0]=='T' or name in ['BI','ID','EMC']):
                             p="" "".join([f'{x:f}' if isinstance(x,float) else str(x).replace(""'"","""") for x in targs])
                             ops+=f'{p} {name} '
                 elif settings.STRICT:
",update pdfpageinterpreter.py,
d1c246c0e95703cd167e3006aac947b6cac6db46,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.6""
+__version__ = ""1.6.7""
 __author__ = ""Byaidu""
",update version,
d1c246c0e95703cd167e3006aac947b6cac6db46,converter.py,"@@ -514,7 +514,10 @@ class TextConverter(PDFConverter[AnyIO]):
                         cache.write_paragraph(hash_key, hash_key_paragraph, new)
                     return new
                 except BaseException as e:
-                    log.exception(e,exc_info=False)
+                    if log.isEnabledFor(logging.DEBUG):
+                        log.exception(e)
+                    else:
+                        log.exception(e,exc_info=False)
                     raise e
             with concurrent.futures.ThreadPoolExecutor(max_workers=self.thread) as executor:
                 news = list(executor.map(worker, sstk))
",add debug log to textconverter,
108e24de66872a51910ed8e145cd2e8f3b141ea7,README.md,"@@ -5,15 +5,12 @@ English | [简体中文](README_zh-CN.md)
 <p align=""center"">
   <!-- PyPI -->
   <a href=""https://pypi.org/project/pdf2zh/"">
-    <img src=""https://img.shields.io/pypi/v/pdf2zh""/>
-  </a>
+    <img src=""https://img.shields.io/pypi/v/pdf2zh""/></a>
   <!-- License -->
   <a href=""./LICENSE"">
-    <img src=""https://img.shields.io/github/license/Byaidu/PDFMathTranslate""/>
-  </a>
+    <img src=""https://img.shields.io/github/license/Byaidu/PDFMathTranslate""/></a>
   <a href=""https://t.me/+kXx8BQCnUTc3NDM9"">
-    <img src=""https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white""/>
-  </a>
+    <img src=""https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white""/></a>
 </p>
 
 PDF scientific paper translation and bilingual comparison.
",add tme link to the telegram badge,
108e24de66872a51910ed8e145cd2e8f3b141ea7,README_zh-CN.md,"@@ -5,15 +5,12 @@
 <p align=""center"">
   <!-- PyPI -->
   <a href=""https://pypi.org/project/pdf2zh/"">
-    <img src=""https://img.shields.io/pypi/v/pdf2zh""/>
-  </a>
+    <img src=""https://img.shields.io/pypi/v/pdf2zh""/></a>
   <!-- License -->
   <a href=""./LICENSE"">
-    <img src=""https://img.shields.io/github/license/Byaidu/PDFMathTranslate""/>
-  </a>
+    <img src=""https://img.shields.io/github/license/Byaidu/PDFMathTranslate""/></a>
   <a href=""https://t.me/+kXx8BQCnUTc3NDM9"">
-    <img src=""https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white""/>
-  </a>
+    <img src=""https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white""/></a>
 </p>
 
 PDF 文档翻译及双语对照
@@ -93,17 +90,17 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 
 ## 致谢
 
-文档合并: [PyMuPDF](https://github.com/pymupdf/PyMuPDF)
+文档合并：[PyMuPDF](https://github.com/pymupdf/PyMuPDF)
 
-文档解析: [Pdfminer.six](https://github.com/pdfminer/pdfminer.six)
+文档解析：[Pdfminer.six](https://github.com/pdfminer/pdfminer.six)
 
-文档提取: [MinerU](https://github.com/opendatalab/MinerU)
+文档提取：[MinerU](https://github.com/opendatalab/MinerU)
 
-多线程翻译: [MathTranslate](https://github.com/SUSYUSTC/MathTranslate)
+多线程翻译：[MathTranslate](https://github.com/SUSYUSTC/MathTranslate)
 
-布局解析: [DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO)
+布局解析：[DocLayout-YOLO](https://github.com/opendatalab/DocLayout-YOLO)
 
-文档标准: [PDF Explained](https://zxyle.github.io/PDF-Explained/), [PDF Cheat Sheets](https://pdfa.org/resource/pdf-cheat-sheets/)
+文档标准：[PDF Explained](https://zxyle.github.io/PDF-Explained/), [PDF Cheat Sheets](https://pdfa.org/resource/pdf-cheat-sheets/)
 
 ## Star History
 
",add pdf2zh example,
e15de84dd37ad5e3290971d9f86ac046df324985,README_zh-CN.md,"@@ -31,7 +31,7 @@ pip install -U ""pdf2zh>=1.5.3""
 
 ## 使用
 
-命令行中执行翻译指令，在工作目录下生成翻译文档 `example-zh.pdf` 和双语对照文档 `example-dual.pdf`。
+命令行中执行翻译指令，在工作目录下生成翻译文档 `example-zh.pdf` 和双语对照文档 `example-dual.pdf`
 
 ### 翻译完整文档
 
@@ -69,7 +69,7 @@ pdf2zh example.pdf -s gemma2
    - `DEEPLX_URL`, e.g., `export DEEPLX_URL=https://api.deeplx.org`
    - `DEEPLX_TOKEN`, e.g., `export DEEPLX_TOKEN=ABCDEFG`
 
-2. 执行:
+2. 执行：
 ```bash
 pdf2zh example.pdf -s deeplx
 ```
",add examples for the new version of pdf2zh,
658449e72c92242d7a22635a2b117a019dd69151,README_zh-CN.md,"@@ -65,7 +65,7 @@ pdf2zh example.pdf -s gemma2
 
 参考 [DeepLX](https://github.com/OwO-Network/DeepLX)
 
-1. 设置环境变量构建 endpoint：`{DEEPLX_URL}/{DEEPLX_TOKEN}/translate`:
+1. 设置环境变量构建 endpoint：`{DEEPLX_URL}/{DEEPLX_TOKEN}/translate`
    - `DEEPLX_URL`, e.g., `export DEEPLX_URL=https://api.deeplx.org`
    - `DEEPLX_TOKEN`, e.g., `export DEEPLX_TOKEN=ABCDEFG`
 
",add missing word to example,
cf657c66e9e076ddac4c0ad13378e411d76fa2ae,README.md,"@@ -9,7 +9,7 @@ English | [简体中文](README_zh-CN.md)
   <!-- License -->
   <a href=""./LICENSE"">
     <img src=""https://img.shields.io/github/license/Byaidu/PDFMathTranslate""/></a>
-  <a href=""https://t.me/+kXx8BQCnUTc3NDM9"">
+  <a href=""https://t.me/+Z9_SgnxmsmA5NzBl"">
     <img src=""https://img.shields.io/badge/Telegram-2CA5E0?style=flat-squeare&logo=telegram&logoColor=white""/></a>
 </p>
 
",add link to telegram page,
162ec343559949ea226b9ac91a9be63ca7579bd4,README.md,"@@ -53,17 +53,6 @@ See [Google Languages Codes](https://developers.google.com/admin-sdk/directory/v
 pdf2zh example.pdf -li en -lo ja
 ```
 
-### Translate with Ollama
-
-See [Ollama](https://github.com/ollama/ollama).
-
-Set ENVs to construct an endpoint like: `{OLLAMA_HOST}/api/chat`
-- `OLLAMA_HOST` (Optional), e.g., `export OLLAMA_HOST=https://localhost:11434`
-
-```bash
-pdf2zh example.pdf -s ollama:gemma2
-```
-
 ### Translate with DeepL/DeepLX
 
 See [DeepLX](https://github.com/OwO-Network/DeepLX).
@@ -76,6 +65,17 @@ Set ENVs to construct an endpoint like: `{DEEPL_SERVER_URL}/{DEEPL_AUTH_KEY}/tra
 pdf2zh example.pdf -s deepl
 ```
 
+### Translate with Ollama
+
+See [Ollama](https://github.com/ollama/ollama).
+
+Set ENVs to construct an endpoint like: `{OLLAMA_HOST}/api/chat`
+- `OLLAMA_HOST` (Optional), e.g., `export OLLAMA_HOST=https://localhost:11434`
+
+```bash
+pdf2zh example.pdf -s ollama:gemma2
+```
+
 ### Translate with OpenAI/SiliconCloud
 
 See [OpenAI](https://platform.openai.com/docs/overview).
",add missing docs,
162ec343559949ea226b9ac91a9be63ca7579bd4,README_zh-CN.md,"@@ -53,17 +53,6 @@ pdf2zh example.pdf -p 1-3,5
 pdf2zh example.pdf -li en -lo ja
 ```
 
-### 使用 Ollama 翻译
-
-参考 [Ollama](https://github.com/ollama/ollama)
-
-设置环境变量构建接入点：`{OLLAMA_HOST}/api/chat`
-- `OLLAMA_HOST`（可选）, e.g., `export OLLAMA_HOST=https://localhost:11434`
-
-```bash
-pdf2zh example.pdf -s ollama:gemma2
-```
-
 ### 使用 DeepL/DeepLX 翻译
 
 参考 [DeepLX](https://github.com/OwO-Network/DeepLX)
@@ -76,6 +65,17 @@ pdf2zh example.pdf -s ollama:gemma2
 pdf2zh example.pdf -s deepl
 ```
 
+### 使用 Ollama 翻译
+
+参考 [Ollama](https://github.com/ollama/ollama)
+
+设置环境变量构建接入点：`{OLLAMA_HOST}/api/chat`
+- `OLLAMA_HOST`（可选）, e.g., `export OLLAMA_HOST=https://localhost:11434`
+
+```bash
+pdf2zh example.pdf -s ollama:gemma2
+```
+
 ### 使用 OpenAI/SiliconCloud 翻译
 
 参考 [OpenAI](https://platform.openai.com/docs/overview)
",add examples for ollama_host,
162ec343559949ea226b9ac91a9be63ca7579bd4,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.8""
+__version__ = ""1.6.9""
 __author__ = ""Byaidu""
",update version strings,
162ec343559949ea226b9ac91a9be63ca7579bd4,setup.py,"@@ -27,6 +27,8 @@ setup(
         ""doclayout-yolo"",
         ""numpy"",
         ""ollama"",
+        ""deepl"",
+        ""openai"",
     ],
     classifiers=[
         ""Programming Language :: Python :: 3"",
",add missing package-info,
50552afc4291cfb1d86fc050bd4e730950de3348,bug_report.md,"@@ -0,0 +1,19 @@
+---
+name: Bug report
+about: Create a report to help us improve
+title: ''
+labels: bug
+assignees: ''
+
+---
+
+**问题描述**
+请对问题进行描述，并提供日志或截图
+本项目不处理网络环境引发的问题
+
+**环境信息**
+ - OS: [e.g. iOS]
+ - Version [e.g. 22]
+
+**测试文档**
+请提供用于复现测试的 PDF 文件
",add more info to bug report,
50552afc4291cfb1d86fc050bd4e730950de3348,custom.md,"@@ -0,0 +1,10 @@
+---
+name: Custom issue template
+about: Describe this issue template's purpose here.
+title: ''
+labels: ''
+assignees: ''
+
+---
+
+
",add missing missing tag,
50552afc4291cfb1d86fc050bd4e730950de3348,feature_request.md,"@@ -0,0 +1,20 @@
+---
+name: Feature request
+about: Suggest an idea for this project
+title: ''
+labels: enhancement
+assignees: ''
+
+---
+
+**Is your feature request related to a problem? Please describe.**
+A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
+
+**Describe the solution you'd like**
+A clear and concise description of what you want to happen.
+
+**Describe alternatives you've considered**
+A clear and concise description of any alternative solutions or features you've considered.
+
+**Additional context**
+Add any other context or screenshots about the feature request here.
",add more info to feature request,
6ddca277a42ad62f32ab71ab1584ab100a181a4d,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.6.9""
+__version__ = ""1.7.0""
 __author__ = ""Byaidu""
",update version,
6ddca277a42ad62f32ab71ab1584ab100a181a4d,pdfinterp.py,"@@ -1006,11 +1006,12 @@ class PDFPageInterpreter:
         self.device.fontid=self.fontid
         self.device.fontmap=self.fontmap
         ops_new=self.device.end_page(page)
-        page_objids=[i.objid for i in page.contents]
-        # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
-        self.obj_patch[page_objids[0]]=f'q {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
-        for objid in range(1,len(page_objids)):
-            self.obj_patch[page_objids[objid]]=''
+        if page.contents:
+            page_objids=[i.objid for i in page.contents]
+            # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
+            self.obj_patch[page_objids[0]]=f'q {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
+            for objid in range(1,len(page_objids)):
+                self.obj_patch[page_objids[objid]]=''
 
     def render_contents(
         self,
",add support for new page content,
191d7776004eed7286159de6e86fc48d3923e29e,bug_report.md,"@@ -7,13 +7,13 @@ assignees: ''
 
 ---
 
-**问题描述**
+## 问题描述
 请对问题进行描述，并提供日志或截图
-本项目不处理网络环境引发的问题
+**本项目不处理网络环境引发的问题**（例如 Empty translation result/Connection reset）
 
-**环境信息**
+## 环境信息
  - OS: [e.g. iOS]
  - Version [e.g. 22]
 
-**测试文档**
+## 测试文档
 请提供用于复现测试的 PDF 文件
",add missing comments,
c28e674917e90688cbdb976602a512cda3530dcd,custom.md,"@@ -1,10 +0,0 @@
----
-name: Custom issue template
-about: Describe this issue template's purpose here.
-title: ''
-labels: ''
-assignees: ''
-
----
-
-
",add missing description,
c28e674917e90688cbdb976602a512cda3530dcd,feature_request.md,"@@ -1,20 +0,0 @@
----
-name: Feature request
-about: Suggest an idea for this project
-title: ''
-labels: enhancement
-assignees: ''
-
----
-
-**Is your feature request related to a problem? Please describe.**
-A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
-
-**Describe the solution you'd like**
-A clear and concise description of what you want to happen.
-
-**Describe alternatives you've considered**
-A clear and concise description of any alternative solutions or features you've considered.
-
-**Additional context**
-Add any other context or screenshots about the feature request here.
",add missing section in doc for missing nelem,
c28e674917e90688cbdb976602a512cda3530dcd,功能请求.md,"@@ -0,0 +1,11 @@
+---
+name: 功能请求
+about: Suggest an idea for this project
+title: ''
+labels: enhancement
+assignees: ''
+
+---
+
+## 功能描述
+请描述需要添加的功能，以及是否有类似项目可以参考
",add missing description,
c28e674917e90688cbdb976602a512cda3530dcd,问题反馈.md,"@@ -1,5 +1,5 @@
 ---
-name: Bug report
+name: 问题反馈
 about: Create a report to help us improve
 title: ''
 labels: bug
@@ -11,9 +11,5 @@ assignees: ''
 请对问题进行描述，并提供日志或截图
 **本项目不处理网络环境引发的问题**（例如 Empty translation result/Connection reset）
 
-## 环境信息
- - OS: [e.g. iOS]
- - Version [e.g. 22]
-
 ## 测试文档
-请提供用于复现测试的 PDF 文件
+请提供用于复现测试的 PDF 文档
",add missing description,
5ac8526f0886995bc0538d820b8f6ce4e4fde69e,问题反馈.md,"@@ -12,4 +12,5 @@ assignees: ''
 **本项目不处理网络环境引发的问题**（例如 Empty translation result/Connection reset）
 
 ## 测试文档
-请提供用于复现测试的 PDF 文档
+> [!IMPORTANT]
+> 请提供用于复现测试的 PDF 文档
",add missing doc block,
642597c6e49731f526b01ce56cec7f28b02d8319,pdf2zh.py,"@@ -87,15 +87,15 @@ def extract_text(
         xreflen = doc_en.xref_length()
         for xref in range(1, xreflen):
             for label in ['Resources/','']: # 可能是基于 xobj 的 res
-                font_res=doc_en.xref_get_key(xref,f'{label}Font')
-                if font_res[0]=='dict':
-                    for font in font_list:
-                        font_exist=doc_en.xref_get_key(xref,f'{label}Font/{font}')
-                        if font_exist[0]=='null':
-                            try:
+                try: # xref 读写可能出错
+                    font_res=doc_en.xref_get_key(xref,f'{label}Font')
+                    if font_res[0]=='dict':
+                        for font in font_list:
+                            font_exist=doc_en.xref_get_key(xref,f'{label}Font/{font}')
+                            if font_exist[0]=='null':
                                 doc_en.xref_set_key(xref,f'{label}Font/{font}',f'{font_id[font]} 0 R')
-                            except:
-                                pass
+                except:
+                    pass
         doc_en.save(f'{filename}-en.pdf')
 
         with open(f'{filename}-en.pdf', ""rb"") as fp:
",add missing try/except,
94d5559b116a24382b8a545b459114a2650387f5,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.0""
+__version__ = ""1.7.1""
 __author__ = ""Byaidu""
",update version,
94d5559b116a24382b8a545b459114a2650387f5,high_level.py,"@@ -21,6 +21,7 @@ from pdf2zh.pdfinterp import PDFPageInterpreter, PDFResourceManager
 from pdf2zh.pdfpage import PDFPage
 from pdf2zh.utils import AnyIO, FileOrName, open_filename
 import numpy as np
+from pymupdf import Document
 
 
 def extract_text_to_fp(
@@ -43,7 +44,7 @@ def extract_text_to_fp(
     vfont: str = """",
     vchar: str = """",
     thread: int = 0,
-    doc_en = None,
+    doc_en: Document = None,
     model = None,
     lang_in: str = """",
     lang_out: str = """",
@@ -184,6 +185,11 @@ def extract_text_to_fp(
         layout[page.pageno]=box
         # print(page.number,page_layout)
         page.rotate = (page.rotate + rotation) % 360
+        # 新建一个 xref 存放新指令流
+        page.page_xref = doc_en.get_new_xref() # hack
+        doc_en.update_object(page.page_xref, ""<<>>"")
+        doc_en.update_stream(page.page_xref,b'')
+        doc_en[page.pageno].set_contents(page.page_xref)
         interpreter.process_page(page)
 
     device.close()
","add support for -12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,13,13,",
94d5559b116a24382b8a545b459114a2650387f5,pdfinterp.py,"@@ -1006,12 +1006,10 @@ class PDFPageInterpreter:
         self.device.fontid=self.fontid
         self.device.fontmap=self.fontmap
         ops_new=self.device.end_page(page)
-        if page.contents:
-            page_objids=[i.objid for i in page.contents]
-            # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
-            self.obj_patch[page_objids[0]]=f'q {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
-            for objid in range(1,len(page_objids)):
-                self.obj_patch[page_objids[objid]]=''
+        # 上面渲染的时候会根据 cropbox 减掉页面偏移得到真实坐标，这里输出的时候需要用 cm 把页面偏移加回来
+        self.obj_patch[page.page_xref]=f'q {ops_base}Q 1 0 0 1 {x0} {y0} cm {ops_new}' # ops_base 里可能有图，需要让 ops_new 里的文字覆盖在上面，使用 q/Q 重置位置矩阵
+        for obj in page.contents:
+            self.obj_patch[obj.objid]=''
 
     def render_contents(
         self,
",add support for more than one page,
3fedd47cdb4ea619bc40522db794a1b5a501c9ae,README_zh-CN.md,"@@ -86,7 +86,7 @@ pdf2zh example.pdf -s deepl
 pdf2zh example.pdf -s ollama:gemma2
 ```
 
-### 使用 OpenAI/SiliconCloud 翻译
+### 使用 OpenAI/SiliconCloud/Zhipu 翻译
 
 参考 [SiliconCloud](https://docs.siliconflow.cn/quickstart), [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)
 
",add example for zhipu in the docs,
b5a58e697b15f81d59aa29542dfcc5744b615175,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.1""
+__version__ = ""1.7.2""
 __author__ = ""Byaidu""
",update version,
b5a58e697b15f81d59aa29542dfcc5744b615175,setup.py,"@@ -27,7 +27,7 @@ setup(
         ""doclayout-yolo"",
         ""numpy"",
         ""ollama"",
-        ""deepl"",
+        ""deepl<1.19.1"",
         ""openai"",
     ],
     classifiers=[
",add missing test,
e068ee42310e0347b01b47282174a3300484dd6e,README.md,"@@ -67,7 +67,7 @@ pdf2zh example.pdf -li en -lo ja
 
 See [DeepLX](https://github.com/OwO-Network/DeepLX)
 
-Set ENVs to construct an endpoint like: `{DEEPL_SERVER_URL}/{DEEPL_AUTH_KEY}/translate`
+Set ENVs to construct an endpoint like: `{DEEPL_SERVER_URL}/translate`
 - `DEEPL_SERVER_URL` (Optional), e.g., `export DEEPL_SERVER_URL=https://api.deepl.com`
 - `DEEPL_AUTH_KEY`, e.g., `export DEEPL_AUTH_KEY=xxx`
 
",add missing quotes to the example,
e068ee42310e0347b01b47282174a3300484dd6e,README_zh-CN.md,"@@ -67,7 +67,7 @@ pdf2zh example.pdf -li en -lo ja
 
 参考 [DeepLX](https://github.com/OwO-Network/DeepLX)
 
-设置环境变量构建接入点：`{DEEPL_SERVER_URL}/{DEEPL_AUTH_KEY}/translate`
+设置环境变量构建接入点：`{DEEPL_SERVER_URL}/translate`
 - `DEEPL_SERVER_URL`（可选）, e.g., `export DEEPL_SERVER_URL=https://api.deepl.com`
 - `DEEPL_AUTH_KEY`, e.g., `export DEEPL_AUTH_KEY=xxx`
 
",add examples for deeplx,
2d3b430cc70533f751b759161e922e8389f15baf,README.md,"@@ -137,7 +137,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 
 ### Using GUI
 
-<img src=""./gui/img/before.png"" width=""650"" alt=""Original"">
+<img src=""./gui/img/before.png"" width=""650"" alt=""Original""/>
 See [the documentation for the GUI for more details](./gui/README.md)
 
 ## Preview
",add example for the previous version of the nation,
38213ad15fb8ad18f956d14755bf75c904951d49,README.md,"@@ -116,9 +116,9 @@ pdf2zh example.pdf -li en -lo ja
 
 - **Azure**
 
-  See [What is Azure Text Translation?](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)
+  See [Azure Text Translation](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)
 
-  Following ENVs are required.
+  Following ENVs are required:
   - `AZURE_APIKEY`, e.g., `export AZURE_APIKEY=xxx`
   - `AZURE_ENDPOINT`, e.g, `export AZURE_ENDPOINT=https://api.translator.azure.cn/`
   - `AZURE_REGION`, e.g., `export AZURE_REGION=chinaeast2`
@@ -129,7 +129,7 @@ pdf2zh example.pdf -li en -lo ja
   ```
 
 ### Translation wih exceptions
-Use regex to specify formula fonts and characters that need to be preserved
+Use regex to specify formula fonts and characters that need to be preserved.
 
 ```bash
 pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\ufaff])""
@@ -137,8 +137,9 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 
 ### Using GUI
 
-<img src=""./gui/img/before.png"" width=""650"" alt=""Original""/>
-See [the documentation for the GUI for more details](./gui/README.md)
+![image](./gui/img/before.png)
+
+See [documentation for GUI](./gui/README.md) for more details.
 
 ## Preview
 
",add examples for the exception translation example,
ad6b3506a4f4aaeef19e0b4555754c178b5e0f3e,README.md,"@@ -128,7 +128,7 @@ pdf2zh example.pdf -li en -lo ja
   pdf2zh example.pdf -s azure
   ```
 
-### Translation wih exceptions
+### Translate wih exceptions
 Use regex to specify formula fonts and characters that need to be preserved.
 
 ```bash
",add missing line to example,
ad6b3506a4f4aaeef19e0b4555754c178b5e0f3e,README_zh-CN.md,"@@ -19,7 +19,7 @@
 
 </div>
 
-PDF 文档翻译及双语对照
+PDF 文档翻译及双语对照工具
 
 - 📊 保留公式和图表
 
@@ -27,7 +27,7 @@ PDF 文档翻译及双语对照
 
 - 🌐 支持多种翻译服务
 
-欢迎在 [issues](https://github.com/Byaidu/PDFMathTranslate/issues) 或 [user group](https://t.me/+Z9_SgnxmsmA5NzBl) 中提供反馈
+欢迎在 [issues](https://github.com/Byaidu/PDFMathTranslate/issues) 或 [用户群](https://t.me/+Z9_SgnxmsmA5NzBl) 中提供反馈
 
 ## 安装
 
@@ -39,23 +39,25 @@ pip install pdf2zh
 
 ## 使用
 
-命令行中执行翻译指令，在工作目录下生成翻译文档 `example-zh.pdf` 和双语对照文档 `example-dual.pdf`，默认使用 Google 作为翻译服务
+在命令行中执行翻译命令，生成译文文档 `example-zh.pdf` 和双语对照文档 `example-dual.pdf`，默认使用 Google 翻译服务
 
-有关如何设置环境变量，请参考 [ChatGPT](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4)
+关于设置环境变量的详细说明，请参考 [ChatGPT](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4)
 
-### 翻译完整文档
+### 全文或部分文档翻译
+
+- **全文翻译**
 
 ```bash
 pdf2zh example.pdf
 ```
 
-### 翻译部分文档
+- **部分翻译**
 
 ```bash
 pdf2zh example.pdf -p 1-3,5
 ```
 
-### 使用指定语言翻译
+### 指定源语言和目标语言
 
 参考 [Google Languages Codes](https://developers.google.com/admin-sdk/directory/v1/languages), [DeepL Languages Codes](https://developers.deepl.com/docs/resources/supported-languages)
 
@@ -63,9 +65,11 @@ pdf2zh example.pdf -p 1-3,5
 pdf2zh example.pdf -li en -lo ja
 ```
 
-### 使用 DeepL/DeepLX 翻译
+### 使用不同的翻译服务
 
-参考 [DeepLX](https://github.com/OwO-Network/DeepLX)
+- **DeepL**
+
+参考 [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)
 
 设置环境变量构建接入点：`{DEEPL_SERVER_URL}/translate`
 - `DEEPL_SERVER_URL`（可选）, e.g., `export DEEPL_SERVER_URL=https://api.deepl.com`
@@ -75,7 +79,19 @@ pdf2zh example.pdf -li en -lo ja
 pdf2zh example.pdf -s deepl
 ```
 
-### 使用 Ollama 翻译
+- **DeepLX**
+
+参考 [DeepLX](https://github.com/OwO-Network/DeepLX)
+
+设置环境变量构建接入点：`{DEEPLX_SERVER_URL}/translate`
+- `DEEPLX_SERVER_URL`（可选）, e.g., `export DEEPLX_SERVER_URL=https://api.deepl.com`
+- `DEEPLX_AUTH_KEY`, e.g., `export DEEPLX_AUTH_KEY=xxx`
+
+```bash
+pdf2zh example.pdf -s deepl
+```
+
+- **Ollama**
 
 参考 [Ollama](https://github.com/ollama/ollama)
 
@@ -86,7 +102,7 @@ pdf2zh example.pdf -s deepl
 pdf2zh example.pdf -s ollama:gemma2
 ```
 
-### 使用 OpenAI/SiliconCloud/Zhipu 翻译
+- **支持 OpenAI 协议的 LLM（如 OpenAI、SiliconCloud、Zhipu）**
 
 参考 [SiliconCloud](https://docs.siliconflow.cn/quickstart), [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)
 
@@ -98,12 +114,37 @@ pdf2zh example.pdf -s ollama:gemma2
 pdf2zh example.pdf -s openai:gpt-4o
 ```
 
-### 使用正则表达式指定需要保留样式的字体和字符
+- **Azure**
+
+参考 [Azure Text Translation](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)
+
+需设置以下环境变量：
+- `AZURE_APIKEY`, e.g., `export AZURE_APIKEY=xxx`
+- `AZURE_ENDPOINT`, e.g., `export AZURE_ENDPOINT=https://api.translator.azure.cn/`
+- `AZURE_REGION`, e.g., `export AZURE_REGION=chinaeast2`
+
+```bash
+pdf2zh example.pdf -s azure
+```
+
+### 指定例外规则
+
+使用正则表达式指定需保留的公式字体与字符
 
 ```bash
 pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\ufaff])""
 ```
 
+### 图形化交互界面
+
+<img src=""./docs/images/before.png"" height=""500""/>
+
+```bash
+pdf2zh -i
+```
+
+详见 [GUI 文档](./docs/README_GUI.md)
+
 ## 预览
 
 ![image](https://github.com/user-attachments/assets/57e1cde6-c647-4af8-8f8f-587a40050dde)
",add examples,
ca7a64944a21883035256f4e89c4b6f94f41c961,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.3""
+__version__ = ""1.7.4""
 __author__ = ""Byaidu""
",update version,
ca7a64944a21883035256f4e89c4b6f94f41c961,translator.py,"@@ -50,7 +50,9 @@ class GoogleTranslator(BaseTranslator):
         re_result = re.findall(
             r'(?s)class=""(?:t0|result-container)"">(.*?)<', response.text
         )
-        if len(re_result) == 0:
+        if response.status_code == 400:
+            result = 'IRREPARABLE TRANSLATION ERROR'
+        elif len(re_result) == 0:
             raise ValueError(""Empty translation result"")
         else:
             result = html.unescape(re_result[0])
",add missing exception message,
608fda90aff326a875b52f94551e4161be1b1d5e,README.md,"@@ -137,7 +137,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 
 ### Interact with GUI
 
-<img src=""./docs/images/before.png"" height=""500""/>
+<img src=""./docs/images/before.png"" width=""500""/>
 
 ```bash
 pdf2zh -i
",add example for pdf2zh,
608fda90aff326a875b52f94551e4161be1b1d5e,README_zh-CN.md,"@@ -137,7 +137,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 
 ### 图形化交互界面
 
-<img src=""./docs/images/before.png"" height=""500""/>
+<img src=""./docs/images/before.png"" width=""500""/>
 
 ```bash
 pdf2zh -i
",update example.pdf,
608fda90aff326a875b52f94551e4161be1b1d5e,README_GUI.md,"@@ -10,8 +10,8 @@ This subfolder provides the GUI mode of `pdf2zh`.
 
 ## Preview
 
-<img src=""./images/before.png"" height=""500""/>
-<img src=""./images/after.png"" height=""500""/>
+<img src=""./images/before.png"" width=""500""/>
+<img src=""./images/after.png"" width=""500""/>
 
 ## Maintainance
 
",add missing tabs in the list of subfolders,
fd9f1abf5f002843eba48c212c1ffb63ee74b523,converter.py,"@@ -432,7 +432,7 @@ class TextConverter(PDFConverter[AnyIO]):
                     if re.match(self.vchar,char):
                         return True
                 else:
-                    if char and char!=' ' and unicodedata.category(char[0]) in ['Lm','Mn','Sk','Sm','Zl','Zp','Zs']: # 文字修饰符、数学符号、分隔符号
+                    if char and char!=' ' and (unicodedata.category(char[0]) in ['Lm','Mn','Sk','Sm','Zl','Zp','Zs'] or ord(char[0]) in range(0x370,0x400)): # 文字修饰符、数学符号、分隔符号、希腊字母
                         return True
                 return False
             ptr=0
",add support for 修饰符、希腊字母,
022039f5f45693df7d6293ed6c9dad5aa847af8d,gui.py,"@@ -34,7 +34,7 @@ def upload_file(file, service, progress=gr.Progress()):
 
 
 def translate(
-    file_path, service, lang_tgt, page_range, extra_args, progress=gr.Progress()
+    file_path, service, lang_to, page_range, extra_args, progress=gr.Progress()
 ):
     """"""Translate PDF content using selected service.""""""
     if not file_path:
@@ -73,25 +73,25 @@ def translate(
         final_output = output_dir / f""translated_{os.path.basename(file_path)}""
         # Prepare extra arguments
         extra_args = extra_args.strip()
-        lang_tgt = lang_tgt.lower()
-        if lang_tgt == ""chinese"":
-            lang_tgt = ""zh""
-        elif lang_tgt == ""english"":
-            lang_tgt = ""en""
-        elif lang_tgt == ""french"":
-            lang_tgt = ""fr""
-        elif lang_tgt == ""german"":
-            lang_tgt = ""de""
-        elif lang_tgt == ""japanese"":
-            lang_tgt = ""ja""
-        elif lang_tgt == ""korean"":
-            lang_tgt = ""ko""
-        elif lang_tgt == ""russian"":
-            lang_tgt = ""ru""
-        elif lang_tgt == ""spanish"":
-            lang_tgt = ""es""
+        lang_to = lang_to.lower()
+        if lang_to == ""chinese"":
+            lang_to = ""zh""
+        elif lang_to == ""english"":
+            lang_to = ""en""
+        elif lang_to == ""french"":
+            lang_to = ""fr""
+        elif lang_to == ""german"":
+            lang_to = ""de""
+        elif lang_to == ""japanese"":
+            lang_to = ""ja""
+        elif lang_to == ""korean"":
+            lang_to = ""ko""
+        elif lang_to == ""russian"":
+            lang_to = ""ru""
+        elif lang_to == ""spanish"":
+            lang_to = ""es""
         else:
-            lang_tgt = ""zh""  # Default to Chinese
+            lang_to = ""zh""  # Default to Chinese
         # Add page range arguments
         if page_range == ""All"":
             extra_args += """"
@@ -101,7 +101,12 @@ def translate(
             extra_args += "" -p 1-5""
 
         # Execute translation command
-        command = f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo {lang_tgt} -s {selected_service} {extra_args}'
+        if selected_service == ""google"" and lang_to == ""zh"":
+            command = (
+                f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo ""zh-CN"" {extra_args}'
+            )
+        else:
+            command = f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo {lang_to} -s {selected_service} {extra_args}'
         print(f""Executing command: {command}"")
         print(f""Files in temp directory: {os.listdir(temp_path)}"")
 
@@ -191,7 +196,7 @@ with gr.Blocks(
             #     choices=[""Google"", ""DeepL"", ""DeepLX"", ""Ollama"", ""Azure""],
             #     value=""Google"",
             # )
-            lang_tgt = gr.Dropdown(
+            lang_to = gr.Dropdown(
                 label=""Translate to"",
                 info=""Which language to translate to (optional)"",
                 choices=[
@@ -289,7 +294,7 @@ with gr.Blocks(
 
     translate_btn.click(
         translate,
-        inputs=[file_input, service, lang_tgt, page_range, extra_args],
+        inputs=[file_input, service, lang_to, page_range, extra_args],
         outputs=[output_file, preview, output_file],
     )
 
",add support for language-to and language-tgt,
64424e936eb878d4c99673cf94b2c7f8f08992af,Dockerfile,"@@ -2,6 +2,8 @@ FROM python:3.12-slim
 
 WORKDIR /app
 
+ENV PYTHONUNBUFFERED=1
+
 RUN pip install pdf2zh
 
 CMD [""pdf2zh"", ""-i""]
\ No newline at end of file
",add missing --pdf2zh to app/test.py,
64424e936eb878d4c99673cf94b2c7f8f08992af,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.5""
+__version__ = ""1.7.6""
 __author__ = ""Byaidu""
",update version,
64424e936eb878d4c99673cf94b2c7f8f08992af,gui.py,"@@ -300,9 +300,9 @@ with gr.Blocks(
 
 
 def setup_gui():
-    demo.launch(debug=True, inbrowser=True, share=False)
+    demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
 
 
 # For auto-reloading while developing
 if __name__ == ""__main__"":
-    demo.launch(debug=True, inbrowser=True, share=False)
+    demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
",fix the test,
993f9d8ae9732b58c0970729c61c72e0396af741,Dockerfile,"@@ -1,9 +1,12 @@
-FROM python:3.12-slim
+FROM python:3.12
 
 WORKDIR /app
 
 ENV PYTHONUNBUFFERED=1
 
+RUN apt-get update && apt-get install -y libgl1 \
+    && rm -rf /var/lib/apt/lists/*
+
 RUN pip install pdf2zh
 
 CMD [""pdf2zh"", ""-i""]
\ No newline at end of file
",add missing pdf2zh to the list of pdf files,
aa51b092b9c6b4750330dc5df871476ffdfaa888,README.md,"@@ -31,10 +31,10 @@ Feel free to provide feedback in [GitHub Issues](https://github.com/Byaidu/PDFMa
 
 <h2 id=""updates"">Updates</h2>
 
-- [Nov. 20 2024] Support Docker  
-- [Nov. 20 2024] Support multiple-threads  
+- [Nov. 20 2024] Supports Docker  
+- [Nov. 20 2024] Supports multiple-threads  
 - [Nov. 19 2024] Provides an graphical user interface  
-- [Nov. 18 2024] Supports DeepL, DeepLX, and Azure  
+- [Nov. 18 2024] Supports more services, DeepL, DeepLX, and Azure  
 
 <h2 id=""install"">Installation</h2>
 
",add more examples to the pdfmarcanview,
610bef1ba893b9d369de4baaf4578ef2644eb43b,问题反馈.md,"@@ -9,7 +9,8 @@ assignees: ''
 
 ## 问题描述
 请对问题进行描述，并提供日志或截图
-**本项目不处理网络环境引发的问题**（例如 Empty translation result/Connection reset）
+请确认 issues 中没有相同问题且完整阅读 wiki
+**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed）
 
 ## 测试文档
 > [!IMPORTANT]
",add missing comment,
24bff394c1892b9aafe52647565ddfdf5eaa20f4,gui.py,"@@ -300,9 +300,33 @@ with gr.Blocks(
 
 
 def setup_gui():
-    demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
+    try:
+        demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
+    except Exception as e:
+        print(f""Error launching GUI usin 0.0.0.0, using localhost instead: {e}"")
+        try:
+            demo.launch(
+                server_name=""127.0.0.1"", debug=True, inbrowser=True, share=False
+            )
+        except Exception as e:
+            print(
+                f""Error launching GUI using localhost, creating a shareable link instead: {e}""
+            )
+            demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=True)
 
 
 # For auto-reloading while developing
 if __name__ == ""__main__"":
-    demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
+    try:
+        demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
+    except Exception as e:
+        print(f""Error launching GUI usin 0.0.0.0, using localhost instead: {e}"")
+        try:
+            demo.launch(
+                server_name=""127.0.0.1"", debug=True, inbrowser=True, share=False
+            )
+        except Exception as e:
+            print(
+                f""Error launching GUI using localhost, creating a shareable link instead: {e}""
+            )
+            demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=True)
",add tests for the new usin script,
882ce19fdd62f15fc6d8c3f57615849ab47f6abd,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.6""
+__version__ = ""1.7.7""
 __author__ = ""Byaidu""
",update version,
882ce19fdd62f15fc6d8c3f57615849ab47f6abd,gui.py,"@@ -303,30 +303,14 @@ def setup_gui():
     try:
         demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
     except Exception as e:
-        print(f""Error launching GUI usin 0.0.0.0, using localhost instead: {e}"")
+        print(f""Error launching GUI using 0.0.0.0.\nThis may be caused by global mode of proxy software."")
         try:
-            demo.launch(
-                server_name=""127.0.0.1"", debug=True, inbrowser=True, share=False
-            )
+            demo.launch(server_name=""127.0.0.1"", debug=True, inbrowser=True, share=False)
         except Exception as e:
-            print(
-                f""Error launching GUI using localhost, creating a shareable link instead: {e}""
-            )
+            print(f""Error launching GUI using 127.0.0.1.\nThis may be caused by global mode of proxy software."")
             demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=True)
 
 
 # For auto-reloading while developing
 if __name__ == ""__main__"":
-    try:
-        demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=False)
-    except Exception as e:
-        print(f""Error launching GUI usin 0.0.0.0, using localhost instead: {e}"")
-        try:
-            demo.launch(
-                server_name=""127.0.0.1"", debug=True, inbrowser=True, share=False
-            )
-        except Exception as e:
-            print(
-                f""Error launching GUI using localhost, creating a shareable link instead: {e}""
-            )
-            demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=True)
+    setup_gui()
\ No newline at end of file
",add tests for the new cli script,
69c1ae94d57d6c93c04e90ac8374289ddc0c05d0,README.md,"@@ -106,20 +106,16 @@ See [documentation for GUI](./docs/README_GUI.md) for more details.
 For docker deployment on cloud service:
 
 <a href=""https://www.heroku.com/deploy?template=https://github.com/Byaidu/PDFMathTranslate"">
-  <img src=""https://www.herokucdn.com/deploy/button.svg"" alt=""Deploy"" height=""26"">
-</a>
+  <img src=""https://www.herokucdn.com/deploy/button.svg"" alt=""Deploy"" height=""26""></a>
 
 <a href=""https://render.com/deploy"">
-  <img src=""https://render.com/images/deploy-to-render-button.svg"" alt=""Deploy to Koyeb"" height=""26"">
-</a>
+  <img src=""https://render.com/images/deploy-to-render-button.svg"" alt=""Deploy to Koyeb"" height=""26""></a>
 
 <a href=""https://zeabur.com/templates/5FQIGX?referralCode=reycn"">
-  <img src=""https://zeabur.com/button.svg"" alt=""Deploy on Zeabur"" height=""26"">
-</a>
+  <img src=""https://zeabur.com/button.svg"" alt=""Deploy on Zeabur"" height=""26""></a>
 
 <a href=""https://app.koyeb.com/deploy?type=git&builder=buildpack&repository=github.com/Byaidu/PDFMathTranslate&branch=main&name=pdf-math-translate"">
-  <img src=""https://www.koyeb.com/static/images/deploy/button.svg"" alt=""Deploy to Koyeb"" height=""26"">
-</a>
+  <img src=""https://www.koyeb.com/static/images/deploy/button.svg"" alt=""Deploy to Koyeb"" height=""26""></a>
 
 <h2 id=""usage"">Advanced Options</h2>
 
",add more examples to the tools/docs/help.rb,
69c1ae94d57d6c93c04e90ac8374289ddc0c05d0,README_zh-CN.md,"@@ -106,20 +106,16 @@
 用于在云服务上部署容器镜像：
 
 <a href=""https://www.heroku.com/deploy?template=https://github.com/Byaidu/PDFMathTranslate"">
-  <img src=""https://www.herokucdn.com/deploy/button.svg"" alt=""Deploy"" height=""26"">
-</a>
+  <img src=""https://www.herokucdn.com/deploy/button.svg"" alt=""Deploy"" height=""26""></a>
 
 <a href=""https://render.com/deploy"">
-  <img src=""https://render.com/images/deploy-to-render-button.svg"" alt=""Deploy to Koyeb"" height=""26"">
-</a>
+  <img src=""https://render.com/images/deploy-to-render-button.svg"" alt=""Deploy to Koyeb"" height=""26""></a>
 
 <a href=""https://zeabur.com/templates/5FQIGX?referralCode=reycn"">
-  <img src=""https://zeabur.com/button.svg"" alt=""Deploy on Zeabur"" height=""26"">
-</a>
+  <img src=""https://zeabur.com/button.svg"" alt=""Deploy on Zeabur"" height=""26""></a>
 
 <a href=""https://app.koyeb.com/deploy?type=git&builder=buildpack&repository=github.com/Byaidu/PDFMathTranslate&branch=main&name=pdf-math-translate"">
-  <img src=""https://www.koyeb.com/static/images/deploy/button.svg"" alt=""Deploy to Koyeb"" height=""26"">
-</a>
+  <img src=""https://www.koyeb.com/static/images/deploy/button.svg"" alt=""Deploy to Koyeb"" height=""26""></a>
 
 <h2 id=""usage"">高级选项</h2>
 
",add 高级项 to the index page,
469f300b05cd82d2cb1c8fe09405806c00c094cb,gui.py,"@@ -8,6 +8,25 @@ import gradio as gr
 import numpy as np
 import pymupdf
 
+# Map service names to pdf2zh service options
+service_map = {
+    ""Google"": ""google"",
+    ""DeepL"": ""deepl"",
+    ""DeepLX"": ""deeplx"",
+    ""Ollama"": ""ollama"",
+    ""OpenAI"": ""openai"",
+    ""Azure"": ""azure"",
+}
+lang_map = {
+    ""Chinese"": ""zh"",
+    ""English"": ""en"",
+    ""French"": ""fr"",
+    ""German"": ""de"",
+    ""Japanese"": ""ja"",
+    ""Korean"": ""ko"",
+    ""Russian"": ""ru"",
+    ""Spanish"": ""es"",
+}
 
 def pdf_preview(file):
     doc = pymupdf.open(file)
@@ -34,7 +53,7 @@ def upload_file(file, service, progress=gr.Progress()):
 
 
 def translate(
-    file_path, service, model_id, lang_to, page_range, extra_args, progress=gr.Progress()
+    file_path, service, model_id, lang, page_range, extra_args, progress=gr.Progress()
 ):
     """"""Translate PDF content using selected service.""""""
     if not file_path:
@@ -53,17 +72,8 @@ def translate(
         with open(file_path, ""rb"") as src, open(input_pdf, ""wb"") as dst:
             dst.write(src.read())
 
-        # Map service names to pdf2zh service options
-        service_map = {
-            ""Google"": ""google"",
-            ""DeepL"": ""deepl"",
-            ""DeepLX"": ""deeplx"",
-            ""Ollama"": ""ollama"",
-            ""OpenAI"": ""openai"",
-            ""Azure"": ""azure"",
-        }
         selected_service = service_map.get(service, ""google"")
-        lang_to = ""zh""
+        lang_to = lang_map.get(lang, ""zh"")
 
         # Execute translation in temp directory with real-time progress
         progress(0.3, desc=f""Starting translation with {selected_service}..."")
@@ -75,25 +85,6 @@ def translate(
         # [] TODO: Add support for fuzzy matching of language names
         # Prepare extra arguments
         extra_args = extra_args.strip()
-        lang_to = lang_to.lower()
-        if lang_to == ""chinese"":
-            lang_to = ""zh""
-        elif lang_to == ""english"":
-            lang_to = ""en""
-        elif lang_to == ""french"":
-            lang_to = ""fr""
-        elif lang_to == ""german"":
-            lang_to = ""de""
-        elif lang_to == ""japanese"":
-            lang_to = ""ja""
-        elif lang_to == ""korean"":
-            lang_to = ""ko""
-        elif lang_to == ""russian"":
-            lang_to = ""ru""
-        elif lang_to == ""spanish"":
-            lang_to = ""es""
-        else:
-            lang_to = ""zh""  # Default to Chinese
         # Add page range arguments
         if page_range == ""All"":
             extra_args += """"
@@ -103,11 +94,10 @@ def translate(
             extra_args += "" -p 1-5""
 
         # Execute translation command
-        if selected_service == ""google"" and lang_to == ""zh"":
-            command = (
-                f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo ""zh-CN"" {extra_args}'
-            )
-        elif selected_service in [""ollama"",""openai""]:
+        if selected_service == ""google"":
+            lang_to=""zh-CN"" if lang_to==""zh"" else lang_to
+
+        if selected_service in [""ollama"",""openai""]:
             command = f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo {lang_to} -s {selected_service}:{model_id} {extra_args}'
         else:
             command = f'cd ""{temp_path}"" && pdf2zh ""{input_pdf}"" -lo {lang_to} -s {selected_service} {extra_args}'
@@ -142,7 +132,7 @@ def translate(
         print(f""Command completed with return code: {return_code}"")
 
         # Check if translation was successful
-        translated_file = temp_path / f""input-{lang_to}.pdf""
+        translated_file = temp_path / f""input-zh.pdf"" # 输出文件名是固定的
         print(f""Files after translation: {os.listdir(temp_path)}"")
 
         if not translated_file.exists():
@@ -191,7 +181,7 @@ with gr.Blocks(
             service = gr.Dropdown(
                 label=""Service"",
                 info=""Which translation service to use. Some require keys"",
-                choices=[""Google"", ""DeepL"", ""DeepLX"", ""Ollama"", ""OpenAI"", ""Azure""],
+                choices=service_map.keys(),
                 value=""Google"",
             )
             # lang_src = gr.Dropdown(
@@ -203,16 +193,7 @@ with gr.Blocks(
             lang_to = gr.Dropdown(
                 label=""Translate to"",
                 info=""Which language to translate to (optional)"",
-                choices=[
-                    ""Chinese"",
-                    ""English"",
-                    ""French"",
-                    ""German"",
-                    ""Japanese"",
-                    ""Korean"",
-                    ""Russian"",
-                    ""Spanish"",
-                ],
+                choices=lang_map.keys(),
                 value=""Chinese"",
             )
             page_range = gr.Radio(
","add support for -53,17 +72,8",
bfa59391bfd54c29bc78d196981a3dc7ddd7e13f,gui.py,"@@ -141,7 +141,7 @@ def translate(
         print(f""Command completed with return code: {return_code}"")
 
         # Check if translation was successful
-        translated_file = temp_path / f""input-{lang_to}.pdf""
+        translated_file = temp_path / ""input-zh.pdf"" # <= Do not change filename
         dual_file = temp_path / ""input-dual.pdf""
         print(f""Files after translation: {os.listdir(temp_path)}"")
 
",update input.py,
8a66da7842c660d5e666193267ec3c563a8e3ced,pdf2zh.py,"@@ -9,16 +9,17 @@ import argparse
 import logging
 import os
 import sys
+from typing import TYPE_CHECKING, Any, Container, Iterable, List, Optional
+
 import pymupdf
 from huggingface_hub import hf_hub_download
 
 from pdf2zh import __version__
 from pdf2zh.pdfexceptions import PDFValueError
-from typing import Any, Container, Iterable, List, Optional, TYPE_CHECKING
 
 if TYPE_CHECKING:
-    from pdf2zh.utils import AnyIO
     from pdf2zh.layout import LAParams
+    from pdf2zh.utils import AnyIO
 
 OUTPUT_TYPES = (("".htm"", ""html""), ("".html"", ""html""), ("".xml"", ""xml""), ("".tag"", ""tag""))
 
@@ -69,6 +70,7 @@ def extract_text(
     **kwargs: Any,
 ) -> AnyIO:
     import doclayout_yolo
+
     import pdf2zh.high_level
 
     if not files:
@@ -84,55 +86,64 @@ def extract_text(
     # if not os.path.exists(pth):
     #     print('Downloading...')
     #     urllib.request.urlretrieve(""http://huggingface.co/juliozhao/DocLayout-YOLO-DocStructBench/resolve/main/doclayout_yolo_docstructbench_imgsz1024.pt"",pth)
-    pth = hf_hub_download(repo_id=""juliozhao/DocLayout-YOLO-DocStructBench"", filename=""doclayout_yolo_docstructbench_imgsz1024.pt"")
+    pth = hf_hub_download(
+        repo_id=""juliozhao/DocLayout-YOLO-DocStructBench"",
+        filename=""doclayout_yolo_docstructbench_imgsz1024.pt"",
+    )
     model = doclayout_yolo.YOLOv10(pth)
 
     for file in files:
-
         filename = os.path.splitext(os.path.basename(file))[0]
 
         doc_en = pymupdf.open(file)
-        page_count=doc_en.page_count
-        font_list=['china-ss','tiro']
-        font_id={}
+        page_count = doc_en.page_count
+        font_list = [""china-ss"", ""tiro""]
+        font_id = {}
         for page in doc_en:
             for font in font_list:
-                font_id[font]=page.insert_font(font)
+                font_id[font] = page.insert_font(font)
         xreflen = doc_en.xref_length()
         for xref in range(1, xreflen):
-            for label in ['Resources/','']: # 可能是基于 xobj 的 res
-                try: # xref 读写可能出错
-                    font_res=doc_en.xref_get_key(xref,f'{label}Font')
-                    if font_res[0]=='dict':
+            for label in [""Resources/"", """"]:  # 可能是基于 xobj 的 res
+                try:  # xref 读写可能出错
+                    font_res = doc_en.xref_get_key(xref, f""{label}Font"")
+                    if font_res[0] == ""dict"":
                         for font in font_list:
-                            font_exist=doc_en.xref_get_key(xref,f'{label}Font/{font}')
-                            if font_exist[0]=='null':
-                                doc_en.xref_set_key(xref,f'{label}Font/{font}',f'{font_id[font]} 0 R')
+                            font_exist = doc_en.xref_get_key(
+                                xref, f""{label}Font/{font}""
+                            )
+                            if font_exist[0] == ""null"":
+                                doc_en.xref_set_key(
+                                    xref, f""{label}Font/{font}"", f""{font_id[font]} 0 R""
+                                )
                 except:
                     pass
-        doc_en.save(f'{filename}-en.pdf')
+        doc_en.save(f""{filename}-en.pdf"")
 
-        with open(f'{filename}-en.pdf', ""rb"") as fp:
-            obj_patch:dict=pdf2zh.high_level.extract_text_to_fp(fp, **locals())
+        with open(f""{filename}-en.pdf"", ""rb"") as fp:
+            obj_patch: dict = pdf2zh.high_level.extract_text_to_fp(fp, **locals())
 
-        for obj_id,ops_new in obj_patch.items():
+        for obj_id, ops_new in obj_patch.items():
             # ops_old=doc_en.xref_stream(obj_id)
             # print(obj_id)
             # print(ops_old)
             # print(ops_new.encode())
-            doc_en.update_stream(obj_id,ops_new.encode())
+            doc_en.update_stream(obj_id, ops_new.encode())
 
         doc_zh = doc_en
-        doc_dual = pymupdf.open(f'{filename}-en.pdf')
+        doc_dual = pymupdf.open(f""{filename}-en.pdf"")
         doc_dual.insert_file(doc_zh)
         for id in range(page_count):
-            doc_dual.move_page(page_count+id,id*2+1)
-        doc_zh.save(f'{filename}-zh.pdf',deflate=1)
-        doc_dual.save(f'{filename}-dual.pdf',deflate=1)
+            doc_dual.move_page(page_count + id, id * 2 + 1)
+        doc_zh.save(f""{filename}-zh.pdf"", deflate=1)
+        doc_dual.save(f""{filename}-dual.pdf"", deflate=1)
         doc_zh.close()
         doc_dual.close()
-
-        os.remove(f'{filename}-en.pdf')
+        try:  # fix (main): permission error @ https://github.com/Byaidu/PDFMathTranslate/issues/84
+            os.remove(f""{filename}-en.pdf"")
+        except Exception as e:
+            print(f""File removal failed due to occupation / not existing, pass.\n{e}"")
+            pass
 
     return
 
@@ -249,12 +260,13 @@ def main(args: Optional[List[str]] = None) -> int:
 
     missing_files = check_files(parsed_args.files)
     if missing_files:
-        print(f""The following files do not exist:"", file=sys.stderr)
+        print(""The following files do not exist:"", file=sys.stderr)
         for file in missing_files:
             print(f""  {file}"", file=sys.stderr)
         return -1
     if parsed_args.interactive:
         from pdf2zh.gui import setup_gui
+
         setup_gui()
         return 0
 
",add yolo docbench,
dabab77ec18d870d9f23f4038bc5e06ae0430391,docker-publish.yml,"@@ -6,20 +6,15 @@ name: Docker
 # documentation.
 
 on:
-  schedule:
-    - cron: '24 15 * * *'
   push:
-    branches: [ ""main"" ]
     # Publish semver tags as releases.
     tags: [ 'v*.*.*' ]
-  pull_request:
-    branches: [ ""main"" ]
 
 env:
   # Use docker.io for Docker Hub if empty
-  REGISTRY: ghcr.io
+  REGISTRY: docker.io
   # github.repository as <account>/<repo>
-  IMAGE_NAME: ${{ github.repository }}
+  IMAGE_NAME: byaidu/pdf2zh
 
 
 jobs:
@@ -39,11 +34,6 @@ jobs:
 
       # Install the cosign tool except on PR
       # https://github.com/sigstore/cosign-installer
-      - name: Install cosign
-        if: github.event_name != 'pull_request'
-        uses: sigstore/cosign-installer@59acb6260d9c0ba8f4a2f9d9b48431a222b68e20 #v3.5.0
-        with:
-          cosign-release: 'v2.2.4'
 
       # Set up BuildKit Docker container builder to be able to build
       # multi-platform images and export cache
@@ -58,8 +48,8 @@ jobs:
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           registry: ${{ env.REGISTRY }}
-          username: ${{ github.actor }}
-          password: ${{ secrets.GITHUB_TOKEN }}
+          username: ${{ secrets.DOCKER_USERNAME }}
+          password: ${{ secrets.DOCKER_PASSWORD }}
 
       # Extract metadata (tags, labels) for Docker
       # https://github.com/docker/metadata-action
@@ -81,18 +71,3 @@ jobs:
           labels: ${{ steps.meta.outputs.labels }}
           cache-from: type=gha
           cache-to: type=gha,mode=max
-
-      # Sign the resulting Docker image digest except on PRs.
-      # This will only write to the public Rekor transparency log when the Docker
-      # repository is public to avoid leaking data.  If you would like to publish
-      # transparency data even for private images, pass --force to cosign below.
-      # https://github.com/sigstore/cosign
-      - name: Sign the published Docker image
-        if: ${{ github.event_name != 'pull_request' }}
-        env:
-          # https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#using-an-intermediate-environment-variable
-          TAGS: ${{ steps.meta.outputs.tags }}
-          DIGEST: ${{ steps.build-and-push.outputs.digest }}
-        # This step uses the identity token to provision an ephemeral certificate
-        # against the sigstore community Fulcio instance.
-        run: echo ""${TAGS}"" | xargs -I {} cosign sign --yes {}@${DIGEST}
",add missing docs to docker cache action,
4f45be5952156dd44e33ac627f5031dbf0855d9b,docker-publish.yml,"@@ -1,4 +1,4 @@
-name: Docker
+name: Upload Docker Image
 
 # This workflow uses actions that are not certified by GitHub.
 # They are provided by a third-party and are governed by
",add missing comment,
4f45be5952156dd44e33ac627f5031dbf0855d9b,python-publish.yml,"@@ -9,8 +9,9 @@
 name: Upload Python Package
 
 on:
-  release:
-    types: [published]
+  push:
+    # Publish semver tags as releases.
+    tags: [ 'v*.*.*' ]
 
 permissions:
   contents: read
@@ -34,6 +35,3 @@ jobs:
       run: python -m build
     - name: Publish package
       uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29
-      with:
-        user: __token__
-        password: ${{ secrets.PYPI_API_TOKEN }}
","add docs for -34,6 +35",
e908a3aac483f52b29ddb1a6e12832d78abd4ac8,high_level.py,"@@ -164,7 +164,7 @@ def extract_text_to_fp(
         caching=not disable_caching,
     ), total=total_pages, position=0):
         pix = doc_en[page.pageno].get_pixmap()
-        image = np.fromstring(pix.samples, np.uint8).reshape(pix.height, pix.width, 3)
+        image = np.fromstring(pix.samples, np.uint8).reshape(pix.height, pix.width, 3)[:, :, ::-1]
         page_layout=model.predict(
             image,
             imgsz=int(pix.height/32)*32,
",add missing `#to_fp`,
92ea6808ab84a4fb919ff557b038310fca22507e,问题反馈.md,"@@ -10,7 +10,7 @@ assignees: ''
 ## 问题描述
 请对问题进行描述，并提供日志或截图
 请确认 issues 中没有相同问题且完整阅读 wiki
-**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed）
+**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed/unable to connect to proxy）
 
 ## 测试文档
 > [!IMPORTANT]
",add missing comment,
54d6c9160c048d4283eec257ed1c52bee069c72a,docker-publish.yml,"@@ -6,9 +6,8 @@ name: Upload Docker Image
 # documentation.
 
 on:
-  push:
-    # Publish semver tags as releases.
-    tags: [ 'v*.*.*' ]
+  release:
+    types: [published]
 
 env:
   # Use docker.io for Docker Hub if empty
@@ -39,13 +38,12 @@ jobs:
       # multi-platform images and export cache
       # https://github.com/docker/setup-buildx-action
       - name: Set up Docker Buildx
-        uses: docker/setup-buildx-action@f95db51fddba0c2d1ec667646a06c2ce06100226 # v3.0.0
+        uses: docker/setup-buildx-action@v3
 
       # Login against a Docker registry except on PR
       # https://github.com/docker/login-action
       - name: Log into registry ${{ env.REGISTRY }}
-        if: github.event_name != 'pull_request'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        uses: docker/login-action@v3
         with:
           registry: ${{ env.REGISTRY }}
           username: ${{ secrets.DOCKER_USERNAME }}
@@ -55,7 +53,7 @@ jobs:
       # https://github.com/docker/metadata-action
       - name: Extract Docker metadata
         id: meta
-        uses: docker/metadata-action@96383f45573cb7f253c731d3b3ab81c87ef81934 # v5.0.0
+        uses: docker/metadata-action@v5
         with:
           images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
 
@@ -63,10 +61,10 @@ jobs:
       # https://github.com/docker/build-push-action
       - name: Build and push Docker image
         id: build-and-push
-        uses: docker/build-push-action@0565240e2d4ab88bba5387d719585280857ece09 # v5.0.0
+        uses: docker/build-push-action@v6
         with:
           context: .
-          push: ${{ github.event_name != 'pull_request' }}
+          push: true
           tags: ${{ steps.meta.outputs.tags }}
           labels: ${{ steps.meta.outputs.labels }}
           cache-from: type=gha
",add missing docs to docker metadata action,
54d6c9160c048d4283eec257ed1c52bee069c72a,python-publish.yml,"@@ -9,9 +9,8 @@
 name: Upload Python Package
 
 on:
-  push:
-    # Publish semver tags as releases.
-    tags: [ 'v*.*.*' ]
+  release:
+    types: [published]
 
 permissions:
   contents: read
@@ -34,4 +33,4 @@ jobs:
     - name: Build package
       run: python -m build
     - name: Publish package
-      uses: pypa/gh-action-pypi-publish@27b31702a0e7fc50959f5ad993c78deac1bdfc29
+      uses: pypa/gh-action-pypi-publish@release/v1
","add missing docs for -34,4",
54d6c9160c048d4283eec257ed1c52bee069c72a,Dockerfile,"@@ -2,11 +2,14 @@ FROM python:3.12
 
 WORKDIR /app
 
+COPY . .
+
 ENV PYTHONUNBUFFERED=1
 
-RUN apt-get update && apt-get install -y libgl1 \
-    && rm -rf /var/lib/apt/lists/*
+RUN apt-get update && apt-get install -y libgl1
+
+RUN pip install -r requirements.txt
 
-RUN pip install pdf2zh
+RUN pip install .
 
 CMD [""pdf2zh"", ""-i""]
\ No newline at end of file
",add missing pdf2zh to app/list,
54d6c9160c048d4283eec257ed1c52bee069c72a,__init__.py,"@@ -1,2 +1,2 @@
-__version__ = ""1.7.8""
+__version__ = ""1.7.9""
 __author__ = ""Byaidu""
",update version,
54d6c9160c048d4283eec257ed1c52bee069c72a,requirements.txt,"@@ -0,0 +1,15 @@
+charset-normalizer
+cryptography
+requests
+pymupdf
+tqdm
+tenacity
+doclayout-yolo
+numpy
+ollama
+deepl<1.19.1
+openai
+azure-ai-translation-text<=1.0.1
+gradio
+huggingface_hub
+torch
\ No newline at end of file
",add missing missing line,
54d6c9160c048d4283eec257ed1c52bee069c72a,setup.py,"@@ -1,11 +1,12 @@
-from pathlib import Path
 from pdf2zh import __version__, __author__
 from setuptools import setup
 
-root_dir = Path(__file__).parent
-with open(root_dir / ""README.md"", encoding='utf-8') as f:
+with open(""README.md"", encoding='utf-8') as f:
     readme = f.read()
 
+with open(""requirements.txt"", encoding='utf-8') as f:
+    requirements = f.readlines()
+
 setup(
     name=""pdf2zh"",
     long_description=readme,
@@ -17,23 +18,7 @@ setup(
     author_email=""byaidux@gmail.com"",
     url=""https://github.com/Byaidu/PDFMathTranslate"",
     packages=[""pdf2zh""],
-    install_requires=[
-        ""charset-normalizer"",
-        ""cryptography"",
-        ""requests"",
-        ""pymupdf"",
-        ""tqdm"",
-        ""tenacity"",
-        ""doclayout-yolo"",
-        ""numpy"",
-        ""ollama"",
-        ""deepl<1.19.1"",
-        ""openai"",
-        ""azure-ai-translation-text<=1.0.1"",
-        ""gradio"",
-        ""huggingface_hub"",
-        ""torch"",
-    ],
+    install_requires=requirements,
     classifiers=[
         ""Programming Language :: Python :: 3"",
         ""Operating System :: OS Independent"",
",add missing setup.py,
f025e87c5a30ef3c6467be1426e06c20a12ac1ea,banner.nocolor.png,"Binary files a/docs/images/banner.nocolor.png and /dev/null differ
",add missing binary file,
f025e87c5a30ef3c6467be1426e06c20a12ac1ea,setting-one.png,"Binary files a/docs/images/icon/setting-one.png and /dev/null differ
",fix missing file,
f025e87c5a30ef3c6467be1426e06c20a12ac1ea,gui.py,"@@ -237,12 +237,12 @@ with gr.Blocks(
         transition: background-color 0.2s ease-in;
     }
 
-    .progress-bar-wrap {
-    border-radius: 8px !important;
-    }
-    .progress-bar {
-    border-radius: 8px !important;
-    }
+.progress-bar-wrap {
+  border-radius: 8px !important;
+}
+.progress-bar {
+  border-radius: 8px !important;
+}
 
     # .input-file label {
     #     color: #165DFF !important;
@@ -257,7 +257,7 @@ with gr.Blocks(
     #     color: #165DFF !important;
     # }
     """""",
-) as demo1:
+) as demo:
     gr.Markdown(""# PDFMathTranslate"")
 
     with gr.Row():
@@ -280,7 +280,7 @@ with gr.Blocks(
             # lang_src = gr.Dropdown(
             #     label=""Source Language"",
             #     info=""Which translation service to use. Some require keys"",
-            #     choices=[""Google"", ""DeepL"", ""DeepLX"", ""Azure"", ""OpenAI"", ""Ollama""],
+            #     choices=[""Google"", ""DeepL"", ""DeepLX"", ""Ollama"", ""Azure""],
             #     value=""Google"",
             # )
             lang_to = gr.Dropdown(
@@ -403,297 +403,6 @@ with gr.Blocks(
     )
 
 
-class EnvSync:
-    """"""Two-way synchronization between a variable and its system environment counterpart.""""""
-
-    def __init__(self, env_name: str, default_value: str = """"):
-        self._name = env_name
-        self._value = os.environ.get(env_name, default_value)
-        # Initialize the environment variable if it doesn't exist
-        if env_name not in os.environ:
-            os.environ[env_name] = default_value
-
-    @property
-    def value(self) -> str:
-        """"""Get the current value, ensuring sync with system env.""""""
-        sys_value = os.environ.get(self._name)
-        if sys_value != self._value:
-            self._value = sys_value
-        return self._value
-
-    @value.setter
-    def value(self, new_value: str):
-        """"""Set the value and sync with system env.""""""
-        self._value = new_value
-        os.environ[self._name] = new_value
-
-    def __str__(self) -> str:
-        return self.value
-
-    def __bool__(self) -> bool:
-        return bool(self.value)
-
-
-# Global setup
-with gr.Blocks(
-    title=""PDFMathTranslate - PDF Translation with preserved formats"",
-    theme=gr.themes.Default(
-        primary_hue=custom_blue, spacing_size=""md"", radius_size=""lg""
-    ),
-    css=""""""
-    # .secondary-text {color: #999 !important;}
-    footer {visibility: hidden}
-    .env-warning {color: #dd5500 !important;}
-    .env-success {color: #559900 !important;}
-    .logo {border: transparent;}
-    .logo label {display: none;}
-    .logo .top-panel {display: none;}
-    .title {text-align: center;}
-    .title h1 {color: #999999 !important;}
-    .question  {text-align: center;}
-    .question h2 {color: #165DFF !important;}
-    .info-text {text-align: center; margin-top: -5px;}
-    .info-text p {color: #aaaaaa !important;}
-    """""",
-) as demo3:
-    gr.Markdown("" "", elem_classes=[""title""])
-    gr.Markdown("" "", elem_classes=[""title""])
-    gr.Markdown("" "", elem_classes=[""title""])
-    gr.Markdown("" "", elem_classes=[""title""])
-    gr.Image(""./docs/images/banner.nocolor.png"", elem_classes=[""logo""], width=400)
-    gr.Markdown(""# Configuration Guide<br/><br/>"", elem_classes=[""title""])
-    gr.Markdown(""## Use Google Translate?<br/>"", elem_classes=[""question""])
-    with gr.Row():
-        gr.Markdown("""")
-        use_google = gr.Button(
-            ""Yes"",
-            variant=""primary"",
-            elem_classes=[""secondary-text""],
-        )
-        use_other = gr.Button(
-            ""No"",
-            variant=""secondary"",
-            elem_classes=[""secondary-text""],
-        )
-        gr.Markdown("""")
-    with gr.Row():
-        gr.Markdown("""")
-        gr.Markdown(
-            ""Google Translate"",
-            elem_classes=[""info-text""],
-        )
-        gr.Markdown(
-            ""DeepL, OpenAI, and more"",
-            elem_classes=[""info-text""],
-        )
-        gr.Markdown("""")
-    # gr.Markdown(
-    #     """"""<span class='env-success'>- Properly configured.</span><br>
-    #     - GitHub: <a href=""https://github.com/Byaidu/PDFMathTranslate"">Byaidu/PDFMathTranslate</a><br>
-    #     - GUI by: <a href=""https://github.com/reycn"">Rongxin</a>""""""
-    # )
-
-with gr.Blocks(
-    title=""PDFMathTranslate - PDF Translation with preserved formats"",
-    theme=gr.themes.Default(
-        primary_hue=custom_blue, spacing_size=""md"", radius_size=""lg""
-    ),
-    css=""""""
-    # .secondary-text {color: #999 !important;}
-    footer {visibility: hidden}
-    .env-warning {color: #dd5500 !important;}
-    .env-success {color: #559900 !important;}
-    .logo {border: transparent;
-    height: 10vh;}
-    .logo label {display: none;}
-    .logo .top-panel {display: none;}
-    .title {text-align: center;
-    height: 5vh;}
-    .title h1 {color: #999999 !important;}
-    .question  {text-align: center;}
-    .question h2 {color: #165DFF !important;}
-    .info-text {text-align: center; margin-top: -5px;}
-    .info-text p {color: #aaaaaa !important;}
-
-    @keyframes pulse-background {
-        0% { background-color: #FFFFFF; }
-        25% { background-color: #FFFFFF; }
-        50% { background-color: #E8F3FF; }
-        75% { background-color: #FFFFFF; }
-        100% { background-color: #FFFFFF; }
-    }
-    
-    /* Add dashed border to input-file class */
-    .input-file {
-        border: 1.2px dashed #165DFF !important;
-        border-radius: 6px !important;
-        # background-color: #ffffff !important;
-        animation: pulse-background 2s ease-in-out;
-        transition: background-color 0.4s ease-out;
-        width: 80vw;
-        height: 60vh;
-        margin: 0 auto;
-    }
-
-    .input-file:hover {
-        border: 1.2px dashed #165DFF !important;
-        border-radius: 6px !important;
-        color: #165DFF !important;
-        background-color: #E8F3FF !important;
-        transition: background-color 0.2s ease-in;
-        box-shadow: 4px 4px 20px rgba(22, 93, 255, 0.1);
-    }
-
-
-    .input-file label {
-        color: #165DFF !important;
-        border: 1.2px dashed #165DFF !important;
-        border-left: none !important;
-        border-top: none !important;
-    }
-    .input-file .top-panel {
-        color: #165DFF !important;
-        border: 1.2px dashed #165DFF !important;
-        border-right: none !important;
-        border-top: none !important;
-    }
-    .input-file .filename {
-        color: #165DFF !important;
-        background-color: #FFFFFF !important;
-    }
-    .input-file .download {
-        color: #165DFF !important;
-        background-color: #FFFFFF !important;
-    }
-    .input-file .wrap {
-        color: #165DFF !important;
-    }
-    .input-file .or {
-        color: #165DFF !important;
-    }
-
-    .progress-bar-wrap {
-    border-radius: 8px !important;
-    }
-    .progress-bar {
-    border-radius: 8px !important;
-    }
-
-    .options-row {
-        align-items: center;
-        display: flex;
-    }
-    .options-row .wrap  {
-        align-items: center;
-        justify-content: center;
-        flex-wrap: wrap;
-        gap: 1rem;}
-
-    .options-row .form label  {
-        color: #999;}
-    .options-row .form   {
-        border: none !important;
-        align-items: center !important;}
-    .options-row [data-testid=""block-info""] {
-        display: none !important;}
-    .logo-row {
-        align-items: center;}
-    .title-row {
-        align-items: center;}
-    .details-row {
-        align-items: center;}
-    .hide-frame {
-        border: none !important;}
-    .hide-frame .top-panel {
-        display: none !important;}
-    .hide-frame label {
-        display: none !important;}
-    .options-icon {
-        height: 2em;
-        width: 2em;
-    }
-    .options-btn {
-        line-height: var(--line-md);
-        background-color: #FFFFFF;
-        border: 1.2px solid var(--checkbox-label-border-color) !important;
-        border-radius: 6px !important;
-        # color: var(--checkbox-label-border-color) !important;
-        color: #999;
-        transition: background-color 0.2s ease-in;
-    }
-    .options-btn:hover {
-        background-color: #fafafa;
-        # border: 1.2px solid  #fcfcfc !important;
-    }
-    """""",
-) as demo:
-    with gr.Row(elem_classes=[""logo-row""]):
-        gr.Image(""./docs/images/banner.nocolor.png"", elem_classes=[""logo""])
-    with gr.Row(elem_classes=[""title-row""]):
-        gr.Markdown(""# PDFMathTranslate"", elem_classes=[""title""])
-    with gr.Row(elem_classes=[""input-file-row""]):
-        gr.File(
-            label=""Upload PDF"",
-            file_count=""single"",
-            file_types=["".pdf""],
-            interactive=True,
-            elem_classes=[""input-file"", ""secondary-text""],
-        )
-    with gr.Row(elem_classes=[""options-row""]):
-        gr.Markdown("""")
-        # gr.Dropdown(
-        #     [""Google"", ""DeepL"", ""DeepLX"", ""Azure"", ""OpenAI"", ""Ollama""],
-        #     value=""Google"",
-        #     label=""Translation Service"",
-        #     interactive=True,
-        #     elem_classes=[""secondary-text""],
-        # )
-        # gr.Dropdown(
-        #     [
-        #         ""Chinese"",
-        #         ""English"",
-        #         ""French"",
-        #         ""German"",
-        #         ""Japanese"",
-        #         ""Korean"",
-        #         ""Russian"",
-        #         ""Spanish"",
-        #     ],
-        #     value=""Chinese"",
-        #     label=""To"",
-        #     interactive=True,
-        #     elem_classes=[""secondary-text""],
-        #     scale=2,
-        # )
-        gr.Radio(
-            [""All Pages"", ""First Page"", ""First 5 Pages""],
-            value=""All Pages"",
-            label=""Pages"",
-            interactive=True,
-            elem_classes=[""secondary-text""],
-            scale=2,
-        )
-        gr.Markdown("""")
-    with gr.Row(elem_classes=[""options-row""]):
-        gr.Markdown("""")
-        gr.Markdown("""")
-        # gr.Image(
-        #     ""./docs/images/icon/setting-one.png"",
-        #     elem_classes=[""hide-frame"", ""options-icon""],
-        #     scale=1,
-        # )
-        # gr.Markdown(""Advanced Settings"", elem_classes=[""secondary-text""])
-        gr.Button(
-            ""⚙️ Advanced Options"",
-            variant=""secondary"",
-            elem_classes=[""options-btn""],
-        )
-        gr.Markdown("""")
-        gr.Markdown("""")
-    # with gr.Row(elem_classes=[""details-row""]):
-    # gr.Markdown(""Technical details"", elem_classes=[""info-text""])
-
-
 def setup_gui(share=False):
     try:
         demo.launch(server_name=""0.0.0.0"", debug=True, inbrowser=True, share=share)
",add envsync example,
f025e87c5a30ef3c6467be1426e06c20a12ac1ea,translator.py,"@@ -11,10 +11,6 @@ import requests
 from azure.ai.translation.text import TextTranslationClient
 from azure.core.credentials import AzureKeyCredential
 
-import hmac
-import hashlib
-import time
-from datetime import datetime,UTC
 
 class BaseTranslator:
     def __init__(self, service, lang_out, lang_in, model):
@@ -62,96 +58,6 @@ class GoogleTranslator(BaseTranslator):
             result = html.unescape(re_result[0])
         return result
 
-class TencentTranslator(BaseTranslator):
-    def sign(self,key, msg):
-        return hmac.new(key, msg.encode(""utf-8""), hashlib.sha256).digest()
-
-    def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
-        super().__init__(service, lang_out, lang_in, model)
-        try:
-            server_url = (
-                ""tmt.tencentcloudapi.com""
-            )
-            self.secret_id = os.getenv(""Tencent_SECRET_ID"")
-            self.secret_key = os.getenv(""Tencent_SECRET_KEY"")
-            
-        except KeyError as e:
-            missing_var = e.args[0]
-            raise ValueError(
-                f""The environment variable '{missing_var}' is required but not set.""
-            ) from e
-
-        self.session = requests.Session()
-        self.base_link = f""{server_url}""
-
-    def translate(self, text):
-        text = text[:5000]
-        data={
-            ""SourceText"":text,
-            ""Source"":self.lang_in,
-            ""Target"":self.lang_out,
-            ""ProjectId"":0
-        }
-        payloadx = dumps(data)
-        hashed_request_payload = hashlib.sha256(payloadx.encode(""utf-8"")).hexdigest()
-        canonical_request = (""POST"" + ""\n"" +
-                            ""/"" + ""\n"" +
-                            """" + ""\n"" +
-                            ""content-type:application/json; charset=utf-8\nhost:tmt.tencentcloudapi.com\nx-tc-action:texttranslate\n"" + ""\n"" +
-                            ""content-type;host;x-tc-action"" + ""\n"" +
-                            hashed_request_payload)
-
-        timestamp = int(time.time())
-        date = datetime.fromtimestamp(timestamp, UTC).strftime(""%Y-%m-%d"")
-        credential_scope = date + ""/tmt/tc3_request""
-        hashed_canonical_request = hashlib.sha256(canonical_request.encode(""utf-8"")).hexdigest()
-        algorithm = ""TC3-HMAC-SHA256""
-        string_to_sign = (algorithm + ""\n"" +
-                        str(timestamp) + ""\n"" +
-                        credential_scope + ""\n"" +
-                        hashed_canonical_request)
-        secret_date = self.sign((""TC3"" + self.secret_key).encode(""utf-8""), date)
-        secret_service = self.sign(secret_date, ""tmt"")
-        secret_signing = self.sign(secret_service, ""tc3_request"")
-        signed_headers = ""content-type;host;x-tc-action""
-        signature = hmac.new(secret_signing, string_to_sign.encode(""utf-8""), hashlib.sha256).hexdigest()
-        authorization = (algorithm + "" "" +
-                 ""Credential="" + self.secret_id + ""/"" + credential_scope + "", "" +
-                 ""SignedHeaders="" + signed_headers + "", "" +
-                 ""Signature="" + signature)
-        self.headers = {
-            ""Authorization"": authorization,
-            ""Content-Type"": ""application/json; charset=utf-8"",
-            ""Host"": ""tmt.tencentcloudapi.com"",
-            ""X-TC-Action"": ""TextTranslate"",
-            ""X-TC-Region"":""ap-beijing"",
-            ""X-TC-Timestamp"": str(timestamp),
-            ""X-TC-Version"": ""2018-03-21""
-        }
-
-        response = self.session.post(
-            ""https://""+self.base_link,
-            json=data,
-            headers=self.headers,
-        )
-        # 1. Status code test
-        if response.status_code == 200:
-            result = loads(response.text)
-        else:
-            raise ValueError(""HTTP error: "" + str(response.status_code))
-        # 2. Result test
-        try:
-            result = result['Response']['TargetText']
-            return result
-        except KeyError:
-            result = """"
-            raise ValueError(""No valid key in Tencent's response"")
-        # 3. Result length check
-        if len(result) == 0:
-            raise ValueError(""Empty translation result"")
-        return result
 
 class DeepLXTranslator(BaseTranslator):
     def __init__(self, service, lang_out, lang_in, model):
@@ -172,11 +78,7 @@ class DeepLXTranslator(BaseTranslator):
             ) from e
 
         self.session = requests.Session()
-        server_url=server_url.rstrip('/')
-        if auth_key:
-            self.base_link = f""{server_url}/{auth_key}/translate""
-        else:
-            self.base_link = f""{server_url}/translate""
+        self.base_link = f""{server_url}/{auth_key}/translate""
         self.headers = {
             ""User-Agent"": ""Mozilla/4.0 (compatible;MSIE 6.0;Windows NT 5.1;SV1;.NET CLR 1.1.4322;.NET CLR 2.0.50727;.NET CLR 3.0.04506.30)""
         }
@@ -210,6 +112,7 @@ class DeepLXTranslator(BaseTranslator):
             raise ValueError(""Empty translation result"")
         return result
 
+
 class DeepLTranslator(BaseTranslator):
     def __init__(self, service, lang_out, lang_in, model):
         lang_out='ZH' if lang_out=='auto' else lang_out
@@ -315,4 +218,3 @@ class AzureTranslator(BaseTranslator):
 
         translated_text = response[0].translations[0].text
         return translated_text
-
",add tencentcloud api to the text translation client,
d7aec1b742a7be500d6a8b4d2fa45c921fae1c29,MANIFEST.in,"@@ -0,0 +1 @@
+include requirements.txt
\ No newline at end of file
",add missing newline,
5d19e1e63d4efc032a9da1cb8106886525766786,setup.py,"@@ -19,6 +19,7 @@ setup(
     url=""https://github.com/Byaidu/PDFMathTranslate"",
     packages=[""pdf2zh""],
     install_requires=requirements,
+    include_package_data=True,
     classifiers=[
         ""Programming Language :: Python :: 3"",
         ""Operating System :: OS Independent"",
",add missing setup.py file,
6afd4e553dd7eba816efc9ad3fa2eb1efc77d0ac,python-publish.yml,"@@ -14,6 +14,7 @@ on:
 
 permissions:
   contents: read
+  id-token: write
 
 jobs:
   deploy:
",add missing tag,
6afd4e553dd7eba816efc9ad3fa2eb1efc77d0ac,setup.py,"@@ -19,7 +19,6 @@ setup(
     url=""https://github.com/Byaidu/PDFMathTranslate"",
     packages=[""pdf2zh""],
     install_requires=requirements,
-    include_package_data=True,
     classifiers=[
         ""Programming Language :: Python :: 3"",
         ""Operating System :: OS Independent"",
",add missing setup.py file,
e550f8b0fa263d9abe70ae539b3027bc89cfcc4b,gui.py,"@@ -74,16 +74,16 @@ def pdf_preview(file):
 def upload_file(file, service, progress=gr.Progress()):
     """"""Handle file upload, validation, and initial preview.""""""
     if not file or not os.path.exists(file):
-        return None, None, gr.update(visible=False), gr.update(visible=False)
+        return None, None
 
     try:
         # Convert first page for preview
         preview_image = pdf_preview(file)
 
-        return file, preview_image, gr.update(visible=True), gr.update(visible=True)
+        return file, preview_image
     except Exception as e:
         print(f""Error converting PDF: {e}"")
-        return None, None, gr.update(visible=False), gr.update(visible=False)
+        return None, None
 
 
 def translate(
@@ -107,7 +107,7 @@ def translate(
     shutil.copyfile(file_path, file_en)
 
     selected_service = service_map.get(service, ""google"")
-    selected_page = page_map.get(page_range, [1])
+    selected_page = page_map.get(page_range, [0])
     lang_to = lang_map.get(lang, ""zh"")
     if selected_service == ""google"":
         lang_to = ""zh-CN"" if lang_to == ""zh"" else lang_to
@@ -222,7 +222,7 @@ with gr.Blocks(
     # }
     """""",
     head='''
-    <script src=""https://www.google.com/recaptcha/api.js"" async defer></script>
+    <script src=""https://www.google.com/recaptcha/api.js?render=explicit"" async defer></script>
     <script type=""text/javascript"">
         var onVerify = function(token) {
             el=document.getElementById('verify').getElementsByTagName('textarea')[0];
@@ -230,7 +230,7 @@ with gr.Blocks(
             el.dispatchEvent(new Event('input'));
         };
     </script>
-    ''' if flag_demo else None
+    ''' if flag_demo else """"
 ) as demo:
     gr.Markdown(""# [PDFMathTranslate @ Github](https://github.com/Byaidu/PDFMathTranslate)"")
 
@@ -336,11 +336,8 @@ with gr.Blocks(
                 label=""Download Translation (Dual)"", visible=False
             )
             recaptcha_response = gr.Textbox(label=""reCAPTCHA Response"", elem_id='verify', visible=False)
-            if flag_demo:
-                recaptcha_box=gr.HTML(f'<div class=""g-recaptcha"" data-sitekey=""{client_key}"" data-callback=""onVerify""></div>', visible=False)
-            else:
-                recaptcha_box=gr.HTML()
-            translate_btn = gr.Button(""Translate"", variant=""primary"", visible=False)
+            recaptcha_box=gr.HTML(f'<div id=""recaptcha-box""></div>')
+            translate_btn = gr.Button(""Translate"", variant=""primary"")
             tech_details_tog = gr.Markdown(
                 details_wrapper(envs_status),
                 elem_classes=[""secondary-text""],
@@ -355,7 +352,18 @@ with gr.Blocks(
     file_input.upload(
         upload_file,
         inputs=[file_input, service],
-        outputs=[file_input, preview, translate_btn, recaptcha_box],
+        outputs=[file_input, preview],
+        js=f""""""
+            (a,b)=>{{
+                try{{
+                    grecaptcha.render('recaptcha-box',{{
+                        'sitekey':'{client_key}',
+                        'callback':'onVerify'
+                    }});
+                }}catch(error){{}}
+                return [a];
+            }}
+            """""" if flag_demo else """"
     )
 
     translate_btn.click(
@@ -369,7 +377,7 @@ with gr.Blocks(
             output_file_dual,
             output_title,
         ],
-    )
+    ).then(lambda:None,js=""()=>{grecaptcha.reset()}"" if flag_demo else """")
 
 
 def setup_gui(share=False):
",add translation example,
f623fc53794dab3db349be293d4436daee12a68f,Dockerfile,"@@ -8,8 +8,6 @@ ENV PYTHONUNBUFFERED=1
 
 RUN apt-get update && apt-get install -y libgl1
 
-RUN pip install -r requirements.txt
-
 RUN pip install .
 
 CMD [""pdf2zh"", ""-i""]
\ No newline at end of file
",add missing --verbose option to pdf2zh,
f623fc53794dab3db349be293d4436daee12a68f,MANIFEST.in,"@@ -1 +0,0 @@
-include requirements.txt
\ No newline at end of file
",add missing newline,
51a363bc33343d2980e3ec7f6c8b6671fcbde4ef,gui.py,"@@ -228,7 +228,8 @@ with gr.Blocks(
     #     color: #165DFF !important;
     # }
     """""",
-    head='''
+    head=(
+        """"""
     <script src=""https://www.google.com/recaptcha/api.js?render=explicit"" async defer></script>
     <script type=""text/javascript"">
         var onVerify = function(token) {
@@ -237,7 +238,10 @@ with gr.Blocks(
             el.dispatchEvent(new Event('input'));
         };
     </script>
-    ''' if flag_demo else """"
+    """"""
+        if flag_demo
+        else """"
+    ),
 ) as demo:
     gr.Markdown(
         ""# [PDFMathTranslate @ Github](https://github.com/Byaidu/PDFMathTranslate)""
@@ -353,8 +357,10 @@ with gr.Blocks(
             output_file_dual = gr.File(
                 label=""Download Translation (Dual)"", visible=False
             )
-            recaptcha_response = gr.Textbox(label=""reCAPTCHA Response"", elem_id='verify', visible=False)
-            recaptcha_box=gr.HTML(f'<div id=""recaptcha-box""></div>')
+            recaptcha_response = gr.Textbox(
+                label=""reCAPTCHA Response"", elem_id=""verify"", visible=False
+            )
+            recaptcha_box = gr.HTML(f'<div id=""recaptcha-box""></div>')
             translate_btn = gr.Button(""Translate"", variant=""primary"")
             tech_details_tog = gr.Markdown(
                 details_wrapper(envs_status),
@@ -371,7 +377,8 @@ with gr.Blocks(
         upload_file,
         inputs=[file_input, service],
         outputs=[file_input, preview],
-        js=f""""""
+        js=(
+            f""""""
             (a,b)=>{{
                 try{{
                     grecaptcha.render('recaptcha-box',{{
@@ -381,7 +388,10 @@ with gr.Blocks(
                 }}catch(error){{}}
                 return [a];
             }}
-            """""" if flag_demo else """"
+            """"""
+            if flag_demo
+            else """"
+        ),
     )
 
     translate_btn.click(
@@ -395,7 +405,7 @@ with gr.Blocks(
             output_file_dual,
             output_title,
         ],
-    ).then(lambda:None,js=""()=>{grecaptcha.reset()}"" if flag_demo else """")
+    ).then(lambda: None, js=""()=>{grecaptcha.reset()}"" if flag_demo else """")
 
 
 def setup_gui(share=False):
",add example,
bd8177457d3be81ce8f6b74ffd977568ef4a6db0,gui.py,"@@ -360,7 +360,7 @@ with gr.Blocks(
             recaptcha_response = gr.Textbox(
                 label=""reCAPTCHA Response"", elem_id=""verify"", visible=False
             )
-            recaptcha_box = gr.HTML(f'<div id=""recaptcha-box""></div>')
+            recaptcha_box = gr.HTML('<div id=""recaptcha-box""></div>')
             translate_btn = gr.Button(""Translate"", variant=""primary"")
             tech_details_tog = gr.Markdown(
                 details_wrapper(envs_status),
",add button to show recaptcha dialog,
d5eed6c33d6f5e9c959ec30e60c76af870f1fe32,doclayout.py,"@@ -173,7 +173,8 @@ class OnnxModel(DocLayoutModel):
         specified in (img1_shape) to the shape of a different image (img0_shape).
 
         Args:
-            img1_shape (tuple): The shape of the image that the bounding boxes are for, in the format of (height, width).
+            img1_shape (tuple): The shape of the image that the bounding boxes are for,
+                in the format of (height, width).
             boxes (torch.Tensor): the bounding boxes of the objects in the image, in the format of (x1, y1, x2, y2)
             img0_shape (tuple): the shape of the target image, in the format of (height, width).
 
",add docstrings for onnxmodel,
d5eed6c33d6f5e9c959ec30e60c76af870f1fe32,pdf2zh.py,"@@ -14,7 +14,6 @@ from pathlib import Path
 from typing import TYPE_CHECKING, Any, Container, Iterable, List, Optional
 
 import pymupdf
-from pathlib import Path
 
 from pdf2zh import __version__
 from pdf2zh.pdfexceptions import PDFValueError
",add missing import,
5b31d52919101e50f08b39fc1d1fef5bbce40730,gui.py,"@@ -244,7 +244,7 @@ with gr.Blocks(
     ),
 ) as demo:
     gr.Markdown(
-        ""# [PDFMathTranslate @ Github](https://github.com/Byaidu/PDFMathTranslate)""
+        ""# [PDFMathTranslate @ GitHub](https://github.com/Byaidu/PDFMathTranslate)""
     )
 
     with gr.Row():
",add missing markdown section,
065bea74d2e849dfd680f544837ff3ac752fd9f5,gui.py,"@@ -183,20 +183,11 @@ with gr.Blocks(
     .env-warning {color: #dd5500 !important;}
     .env-success {color: #559900 !important;}
 
-    @keyframes pulse-background {
-        0% { background-color: #FFFFFF; }
-        25% { background-color: #FFFFFF; }
-        50% { background-color: #E8F3FF; }
-        75% { background-color: #FFFFFF; }
-        100% { background-color: #FFFFFF; }
-    }
-
     /* Add dashed border to input-file class */
     .input-file {
         border: 1.2px dashed #165DFF !important;
         border-radius: 6px !important;
         # background-color: #ffffff !important;
-        animation: pulse-background 2s ease-in-out;
         transition: background-color 0.4s ease-out;
     }
 
",add missing styles,
3394aee69f670ec34e80d34fc31cc5c317f45e9d,converter.py,"@@ -281,7 +281,7 @@ class PDFLayoutAnalyzer(PDFTextDevice):
             graphicstate,
         )
         self.cur_item.add(item)
-        item.cid = cid  # hack
+        item.cid = cid  # hack 插入原字符编码
         return item.adv
 
     def handle_undefined_char(self, font: PDFFont, cid: int) -> str:
@@ -404,342 +404,304 @@ class TextConverter(PDFConverter[AnyIO]):
         else:
             cast(TextIO, self.outfp).write(text)
 
+    # fmt: off
     def receive_layout(self, ltpage: LTPage):
-        def render(item: LTItem) -> None:
-            xt = None  # 上一个字符
-            sstk = []  # 段落文字栈
-            vstk = []  # 公式符号组
-            vlstk = []  # 公式线条组
-            vfix = 0  # 公式纵向偏移
-            vbkt = 0  # 段落公式括号计数
-            pstk = []  # 段落属性栈
-            lstk = []  # 全局线条栈
-            var = []  # 公式符号组栈
-            varl = []  # 公式线条组栈
-            varf = []  # 公式纵向偏移栈
-            vlen = []  # 公式宽度栈
-            xt_cls = -1  # 上一个字符所属段落
-            vmax = ltpage.width / 4  # 行内公式最大宽度
-            ops = """"  # 渲染结果
-
-            def vflag(font, char):  # 匹配公式（和角标）字体
-                if re.match(r""\(cid:"", char):
+        xt = None   # 上一个字符
+        sstk = []   # 段落文字栈
+        vstk = []   # 公式符号组
+        vlstk = []  # 公式线条组
+        vfix = 0    # 公式纵向偏移
+        vbkt = 0    # 段落公式括号计数
+        pstk = []   # 段落属性栈
+        lstk = []   # 全局线条栈
+        var = []    # 公式符号组栈
+        varl = []   # 公式线条组栈
+        varf = []   # 公式纵向偏移栈
+        vlen = []   # 公式宽度栈
+        xt_cls = -1 # 上一个字符所属段落
+        vmax = ltpage.width / 4 # 行内公式最大宽度
+        ops = """"    # 渲染结果
+
+        def vflag(font, char):  # 匹配公式（和角标）字体
+            if re.match(r""\(cid:"", char):
+                return True
+            # 基于字体名规则的判定
+            if self.vfont:
+                if re.match(self.vfont, font):
                     return True
-                if self.vfont:
-                    if re.match(self.vfont, font):
-                        return True
-                else:
-                    if re.match(
-                        r""(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)"",
-                        font,
-                    ):
-                        return True
-                if self.vchar:
-                    if re.match(self.vchar, char):
-                        return True
-                else:
-                    if (
-                        char
-                        and char != "" ""
-                        and (
-                            unicodedata.category(char[0])
-                            in [""Lm"", ""Mn"", ""Sk"", ""Sm"", ""Zl"", ""Zp"", ""Zs""]
-                            or ord(char[0]) in range(0x370, 0x400)
-                        )
-                    ):  # 文字修饰符、数学符号、分隔符号、希腊字母
-                        return True
-                return False
-
-            ptr = 0
-            item = list(item)
-            while ptr < len(item):  # 识别文字和公式
-                child = item[ptr]
-                if isinstance(child, LTChar):
-                    cur_v = False  # 公式
-                    fontname = child.fontname.split(""+"")[-1]
-                    layout = self.layout[ltpage.pageid]
-                    h, w = (
-                        layout.shape
-                    )  # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
-                    cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(
-                        int(child.y0), 0, h - 1
+            else:
+                if re.match(                                            # latex 字体
+                    r""(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)"",
+                    font,
+                ):
+                    return True
+            # 基于字符集规则的判定
+            if self.vchar:
+                if re.match(self.vchar, char):
+                    return True
+            else:
+                if (
+                    char
+                    and char != "" ""                                     # 非空格
+                    and (
+                        unicodedata.category(char[0])
+                        in [""Lm"", ""Mn"", ""Sk"", ""Sm"", ""Zl"", ""Zp"", ""Zs""]   # 文字修饰符、数学符号、分隔符号
+                        or ord(char[0]) in range(0x370, 0x400)          # 希腊字母
                     )
-                    cls = layout[cy, cx]
-                    # if log.isEnabledFor(logging.DEBUG):
-                    # ops+=f'ET [] 0 d 0 J 0.1 w {child.x0:f}
-                    # {child.y0:f} {child.x1-child.x0:f} {child.y1-child.y0:f} re S Q BT '
-                    if (
-                        cls == 0
-                        or (cls == xt_cls and child.size < pstk[-1][4] * 0.79)
-                        or vflag(fontname, child.get_text())
-                        or (child.matrix[0] == 0 and child.matrix[3] == 0)
-                    ):  # 有 0.76 的角标和 0.799 的大写，这里用 0.79 取中
+                ):
+                    return True
+            return False
+
+        ############################################################
+        # A. 原文档解析
+        ptr = 0
+        item = list(ltpage)
+        while ptr < len(item):
+            child = item[ptr]
+            if isinstance(child, LTChar):
+                cur_v = False
+                fontname = child.fontname.split(""+"")[-1]
+                layout = self.layout[ltpage.pageid]
+                # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
+                h, w = layout.shape
+                # 读取当前字符在 layout 中的类别
+                cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(int(child.y0), 0, h - 1)
+                cls = layout[cy, cx]
+                if (                                                                                        # 判定当前字符是否属于公式
+                    cls == 0                                                                                # 1. 类别为保留区域
+                    or (cls == xt_cls and len(sstk[-1].strip()) > 1 and child.size < pstk[-1][4] * 0.79)    # 2. 角标字体，有 0.76 的角标和 0.799 的大写，这里用 0.79 取中，同时考虑首字母放大的情况
+                    or vflag(fontname, child.get_text())                                                    # 3. 公式字体
+                    or (child.matrix[0] == 0 and child.matrix[3] == 0)                                      # 4. 垂直字体
+                ):
+                    cur_v = True
+                # 判定括号组是否属于公式
+                if not cur_v:
+                    if vstk and child.get_text() == ""("":
                         cur_v = True
-                    if not cur_v:  # 判定括号组是否属于公式
-                        if vstk and child.get_text() == ""("":
-                            cur_v = True
-                            vbkt += 1
-                        if vbkt and child.get_text() == "")"":
-                            cur_v = True
-                            vbkt -= 1
-                    if (
-                        not cur_v
-                        or cls != xt_cls
-                        or (abs(child.x0 - xt.x0) > vmax and cls != 0)
-                    ):  # 公式结束、段落边界、公式换行
-                        if vstk:  # 公式出栈
-                            sstk[-1] += f""$v{len(var)}$""
-                            if (
-                                not cur_v
-                                and cls == xt_cls
-                                and child.x0 > max([vch.x0 for vch in vstk])
-                            ):  # and child.y1>vstk[0].y0: # 段落内公式转文字，行内公式修正
-                                vfix = vstk[0].y0 - child.y0
-                            var.append(vstk)
-                            varl.append(vlstk)
-                            varf.append(vfix)
-                            vstk = []
-                            vlstk = []
-                            vfix = 0
-                    if not vstk:  # 非公式或是公式开头
-                        if cls == xt_cls:  # 同一段落
-                            if child.x0 > xt.x1 + 1:  # 行内空格
-                                sstk[-1] += "" ""
-                            elif child.x1 < xt.x0:  # 换行空格
-                                sstk[-1] += "" ""
-                                pstk[-1][6] = True  # 标记原文段落存在换行
-                        else:
-                            sstk.append("""")
-                            pstk.append(
-                                [
-                                    child.y0,
-                                    child.x0,
-                                    child.x0,
-                                    child.x0,
-                                    child.size,
-                                    child.font,
-                                    False,
-                                ]
-                            )
-                    if not cur_v:  # 文字入栈
-                        if (
-                            child.size > pstk[-1][4] / 0.79
-                            or vflag(pstk[-1][5].fontname.split(""+"")[-1], """")
-                            or re.match(
-                                r""(.*Medi|.*Bold)"",
-                                pstk[-1][5].fontname.split(""+"")[-1],
-                                re.IGNORECASE,
-                            )
-                        ):  # 小字体、公式或粗体开头，后续接文字，需要校正字体
-                            pstk[-1][0] -= child.size - pstk[-1][4]
-                            pstk[-1][4] = child.size
-                            pstk[-1][5] = child.font
-                        sstk[-1] += child.get_text()
-                    else:  # 公式入栈
-                        if (
-                            not vstk and cls == xt_cls and child.x0 > xt.x0
-                        ):  # and child.y1>xt.y0: # 段落内文字转公式，行内公式修正
-                            vfix = child.y0 - xt.y0
-                        vstk.append(child)
-                    # 更新段落边界，段落内换行之后可能是公式开头
-                    pstk[-1][2] = min(pstk[-1][2], child.x0)
-                    pstk[-1][3] = max(pstk[-1][3], child.x1)
-                    xt = child
-                    xt_cls = cls
-                elif isinstance(child, LTFigure):  # 图表
-                    pass
-                elif isinstance(child, LTLine):  # 线条
-                    layout = self.layout[ltpage.pageid]
-                    h, w = (
-                        layout.shape
-                    )  # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
-                    cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(
-                        int(child.y0), 0, h - 1
-                    )
-                    cls = layout[cy, cx]
-                    if vstk and cls == xt_cls:  # 公式线条
-                        vlstk.append(child)
-                    else:  # 全局线条
-                        lstk.append(child)
-                else:
-                    # print(child)
-                    pass
-                ptr += 1
-            # 处理结尾
-            if vstk:  # 公式出栈
-                sstk[-1] += f""$v{len(var)}$""
-                var.append(vstk)
-                varl.append(vlstk)
-                varf.append(vfix)
-            log.debug(""\n==========[VSTACK]==========\n"")
-            for id, v in enumerate(var):  # 计算公式宽度
-                l = max([vch.x1 for vch in v]) - v[0].x0  # noqa: E741
-                log.debug(
-                    f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}'  # noqa: E501
+                        vbkt += 1
+                    if vbkt and child.get_text() == "")"":
+                        cur_v = True
+                        vbkt -= 1
+                if (                                                        # 判定当前公式是否结束
+                    not cur_v                                               # 1. 当前字符不属于公式
+                    or cls != xt_cls                                        # 2. 当前字符与前一个字符不属于同一段落
+                    or (abs(child.x0 - xt.x0) > vmax and cls != 0)          # 3. 段落内换行，可能是一长串斜体的段落，也可能是段内分式换行，这里设个阈值进行区分
+                ):
+                    if vstk:
+                        if (                                                # 根据公式右侧的文字修正公式的纵向偏移
+                            not cur_v                                       # 1. 当前字符不属于公式
+                            and cls == xt_cls                               # 2. 当前字符与前一个字符属于同一段落
+                            and child.x0 > max([vch.x0 for vch in vstk])    # 3. 当前字符在公式右侧
+                        ):
+                            vfix = vstk[0].y0 - child.y0
+                        sstk[-1] += f""$v{len(var)}$""
+                        var.append(vstk)
+                        varl.append(vlstk)
+                        varf.append(vfix)
+                        vstk = []
+                        vlstk = []
+                        vfix = 0
+                # 当前字符不属于公式或当前字符是公式的第一个字符
+                if not vstk:
+                    if cls == xt_cls:               # 当前字符与前一个字符属于同一段落
+                        if child.x0 > xt.x1 + 1:    # 添加行内空格
+                            sstk[-1] += "" ""
+                        elif child.x1 < xt.x0:      # 添加换行空格并标记原文段落存在换行
+                            sstk[-1] += "" ""
+                            pstk[-1][6] = True
+                    else:                           # 根据当前字符构建一个新的段落
+                        sstk.append("""")
+                        pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False,])
+                if not cur_v:                                               # 文字入栈
+                    if (                                                    # 根据当前字符修正段落属性
+                        child.size > pstk[-1][4] / 0.79                     # 1. 当前字符显著比段落字体大
+                        or len(sstk[-1].strip()) == 1                       # 2. 当前字符为段落第二个文字（考虑首字母放大的情况）
+                        or vflag(pstk[-1][5].fontname.split(""+"")[-1], """")   # 3. 段落字体为公式字体
+                        or re.match(                                        # 4. 段落字体为粗体
+                            r""(.*Medi|.*Bold)"",
+                            pstk[-1][5].fontname.split(""+"")[-1],
+                            re.IGNORECASE,
+                        )
+                    ):
+                        pstk[-1][0] -= child.size - pstk[-1][4]             # hack 这个段落纵向位置的修正有问题，不过先凑合用吧
+                        pstk[-1][4] = child.size
+                        pstk[-1][5] = child.font
+                    sstk[-1] += child.get_text()
+                else:                                                       # 公式入栈
+                    if (                                                    # 根据公式右侧的文字修正公式的纵向偏移
+                        not vstk                                            # 1. 当前字符是公式的第一个字符
+                        and cls == xt_cls                                   # 2. 当前字符与前一个字符属于同一段落
+                        and child.x0 > xt.x0                                # 3. 当前字符在前一个字符右侧
+                    ):
+                        vfix = child.y0 - xt.y0
+                    vstk.append(child)
+                # 更新段落边界，因为段落内换行之后可能是公式开头，所以要在外边处理
+                pstk[-1][2] = min(pstk[-1][2], child.x0)
+                pstk[-1][3] = max(pstk[-1][3], child.x1)
+                # 更新上一个字符
+                xt = child
+                xt_cls = cls
+            elif isinstance(child, LTFigure):   # 图表
+                pass
+            elif isinstance(child, LTLine):     # 线条
+                layout = self.layout[ltpage.pageid]
+                # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
+                h, w = layout.shape
+                # 读取当前线条在 layout 中的类别
+                cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(int(child.y0), 0, h - 1)
+                cls = layout[cy, cx]
+                if vstk and cls == xt_cls:      # 公式线条
+                    vlstk.append(child)
+                else:                           # 全局线条
+                    lstk.append(child)
+            else:
+                pass
+            ptr += 1
+        # 处理结尾
+        if vstk:    # 公式出栈
+            sstk[-1] += f""$v{len(var)}$""
+            var.append(vstk)
+            varl.append(vlstk)
+            varf.append(vfix)
+        log.debug(""\n==========[VSTACK]==========\n"")
+        for id, v in enumerate(var):  # 计算公式宽度
+            l = max([vch.x1 for vch in v]) - v[0].x0  # noqa: E741
+            log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
+            vlen.append(l)
+
+        ############################################################
+        # B. 段落翻译
+        log.debug(""\n==========[SSTACK]==========\n"")
+        hash_key = cache.deterministic_hash(""PDFMathTranslate"")
+        cache.create_cache(hash_key)
+        @retry(wait=wait_fixed(1))
+        def worker(s):  # 多线程翻译
+            try:
+                hash_key_paragraph = cache.deterministic_hash(
+                    (s, str(self.translator))
                 )
-                vlen.append(l)
-            log.debug(""\n==========[SSTACK]==========\n"")
-            hash_key = cache.deterministic_hash(""PDFMathTranslate"")
-            cache.create_cache(hash_key)
-
-            @retry(wait=wait_fixed(1))
-            def worker(s):  # 多线程翻译
-                try:
-                    hash_key_paragraph = cache.deterministic_hash(
-                        (s, str(self.translator))
-                    )
-                    new = cache.load_paragraph(hash_key, hash_key_paragraph)  # 查询缓存
-                    if new is None:
-                        new = self.translator.translate(s)
-                        new = remove_control_characters(new)
-                        cache.write_paragraph(hash_key, hash_key_paragraph, new)
-                    return new
-                except BaseException as e:
-                    if log.isEnabledFor(logging.DEBUG):
-                        log.exception(e)
-                    else:
-                        log.exception(e, exc_info=False)
-                    raise e
-
-            with concurrent.futures.ThreadPoolExecutor(
-                max_workers=self.thread
-            ) as executor:
-                news = list(executor.map(worker, sstk))
-
-            def raw_string(fcur, cstk):  # 编码字符串
-                if isinstance(self.fontmap[fcur], PDFCIDFont):  # 判断编码长度
-                    return """".join([""%04x"" % ord(c) for c in cstk])
+                new = cache.load_paragraph(hash_key, hash_key_paragraph)  # 查询缓存
+                if new is None:
+                    new = self.translator.translate(s)
+                    new = remove_control_characters(new)
+                    cache.write_paragraph(hash_key, hash_key_paragraph, new)
+                return new
+            except BaseException as e:
+                if log.isEnabledFor(logging.DEBUG):
+                    log.exception(e)
                 else:
-                    return """".join([""%02x"" % ord(c) for c in cstk])
-
-            _x, _y = 0, 0
-            for id, new in enumerate(news):  # 排版文字和公式
-                tx = x = pstk[id][1]
-                y = pstk[id][0]
-                lt = pstk[id][2]
-                rt = pstk[id][3]
-                ptr = 0
-                size = pstk[id][4]
-                font = pstk[id][5]
-                lb = pstk[id][6]  # 段落属性
-                cstk = """"  # 单行文字栈
-                fcur = fcur_ = None  # 单行字体
-                log.debug(
-                    f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}""
-                )
-                while True:
-                    if ptr == len(new):  # 到达段落结尾
-                        if cstk:
-                            ops += f""/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur, cstk)}>] TJ ""
-                        break
-                    vy_regex = re.match(
-                        r""\$?\s*v([\d\s]+)\$"", new[ptr:], re.IGNORECASE
-                    )  # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
-                    mod = False  # 当前公式是否为文字修饰符
-                    if vy_regex:  # 加载公式
-                        ptr += len(vy_regex.group(0))
-                        try:
-                            vid = int(vy_regex.group(1).replace("" "", """"))
-                            adv = vlen[vid]
-                        except Exception:
-                            continue  # 翻译器可能会自动补个越界的公式标记
-                        if len(var[vid]) == 1 and unicodedata.category(
-                            var[vid][0].get_text()[0]
-                        ) in [
-                            ""Lm"",
-                            ""Mn"",
-                            ""Sk"",
-                        ]:  # 文字修饰符
-                            mod = True
-                    else:  # 加载文字
-                        ch = new[ptr]
-                        # if font.char_width(ord(ch)):
-                        fcur_ = None
-                        # 原字体编码容易出问题，这里直接放弃掉
-                        # try:
-                        #     if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
-                        #         fcur_=self.fontid[font] # 原字体
-                        # except:
-                        #     pass
-                        try:
-                            if (
-                                fcur_ is None
-                                and self.fontmap[""tiro""].to_unichr(ord(ch)) == ch
-                            ):
-                                fcur_ = ""tiro""  # 默认英文字体
-                        except Exception:
-                            pass
-                        if fcur_ is None:
-                            fcur_ = ""china-ss""  # 默认中文字体
-                        # print(self.fontid[font],fcur_,ch,font.char_width(ord(ch)))
-                        adv = self.fontmap[fcur_].char_width(ord(ch)) * size
-                        ptr += 1
-                    if (
-                        fcur_ != fcur or vy_regex or x + adv > rt + 0.1 * size
-                    ):  # 输出文字缓冲区：1.字体更新 2.插入公式 3.到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
-                        if cstk:
-                            ops += f""/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur, cstk)}>] TJ ""
-                            cstk = """"
-                    if lb and x + adv > rt + 0.1 * size:  # 到达右边界且原文段落存在换行
-                        x = lt
-                        lang_space = {
-                            ""zh-CN"": 1.4,
-                            ""zh-TW"": 1.4,
-                            ""ja"": 1.1,
-                            ""ko"": 1.2,
-                            ""en"": 1.2,
-                        }  # CJK
-                        y -= size * lang_space.get(
-                            self.translator.lang_out, 1.1
-                        )  # 小语种大多适配 1.1
-                    if vy_regex:  # 插入公式
-                        fix = 0
-                        if fcur is not None:  # 段落内公式修正纵向偏移
-                            fix = varf[vid]
-                        for vch in var[vid]:  # 排版公式字符
-                            vc = chr(vch.cid)
-                            ops += f""/{self.fontid[vch.font]} {vch.size:f} Tf 1 0 0 1 {x + vch.x0 - var[vid][0].x0:f} {fix + y + vch.y0 - var[vid][0].y0:f} Tm [<{raw_string(self.fontid[vch.font], vc)}>] TJ ""  # noqa: E501
-                            if log.isEnabledFor(logging.DEBUG):
-                                lstk.append(
-                                    LTLine(
-                                        0.1,
-                                        (_x, _y),
-                                        (
-                                            x + vch.x0 - var[vid][0].x0,
-                                            fix + y + vch.y0 - var[vid][0].y0,
-                                        ),
-                                    )
-                                )
-                                _x, _y = (
-                                    x + vch.x0 - var[vid][0].x0,
-                                    fix + y + vch.y0 - var[vid][0].y0,
-                                )
-                        for l in varl[vid]:  # 排版公式线条 # noqa: E741
-                            if l.linewidth < 5:  # hack
-                                ops += f""ET q 1 0 0 1 {l.pts[0][0] + x - var[vid][0].x0:f} {l.pts[0][1] + fix + y - var[vid][0].y0:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
-                    else:  # 插入文字缓冲区
-                        if not cstk:  # 单行开头
-                            tx = x
-                            if x == lt and ch == "" "":  # 消除段落换行空格
-                                adv = 0
-                            else:
-                                cstk += ch
+                    log.exception(e, exc_info=False)
+                raise e
+        with concurrent.futures.ThreadPoolExecutor(
+            max_workers=self.thread
+        ) as executor:
+            news = list(executor.map(worker, sstk))
+
+        ############################################################
+        # C. 新文档排版
+        def raw_string(fcur, cstk):  # 编码字符串
+            if isinstance(self.fontmap[fcur], PDFCIDFont):  # 判断编码长度
+                return """".join([""%04x"" % ord(c) for c in cstk])
+            else:
+                return """".join([""%02x"" % ord(c) for c in cstk])
+        _x, _y = 0, 0
+        for id, new in enumerate(news):
+            tx = x = pstk[id][1]    # 段落初始横坐标
+            y = pstk[id][0]         # 段落上边界
+            lt = pstk[id][2]        # 段落左边界
+            rt = pstk[id][3]        # 段落右边界
+            size = pstk[id][4]      # 段落字体大小
+            font = pstk[id][5]      # 段落字体
+            lb = pstk[id][6]        # 段落属性
+            cstk = """"               # 当前文字栈
+            fcur = fcur_ = None     # 当前字体
+            ptr = 0
+            log.debug(f""< {y} {x} {lt} {rt} {size} {font.fontname} {lb} > {sstk[id]} | {new}"")
+            while True:
+                if ptr == len(new):  # 到达段落结尾
+                    if cstk:
+                        ops += f""/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur, cstk)}>] TJ ""
+                    break
+                vy_regex = re.match(
+                    r""\$?\s*v([\d\s]+)\$"", new[ptr:], re.IGNORECASE
+                )  # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
+                mod = False  # 当前公式是否为文字修饰符
+                if vy_regex:  # 加载公式
+                    ptr += len(vy_regex.group(0))
+                    try:
+                        vid = int(vy_regex.group(1).replace("" "", """"))
+                        adv = vlen[vid]
+                    except Exception:
+                        continue  # 翻译器可能会自动补个越界的公式标记
+                    if len(var[vid]) == 1 and unicodedata.category(
+                        var[vid][0].get_text()[0]
+                    ) in [""Lm"",""Mn"",""Sk"",]:  # 文字修饰符
+                        mod = True
+                else:  # 加载文字
+                    ch = new[ptr]
+                    # if font.char_width(ord(ch)):
+                    fcur_ = None
+                    # 原字体编码容易出问题，这里直接放弃掉
+                    # try:
+                    #     if font.widths.get(ord(ch)) and font.to_unichr(ord(ch))==ch:
+                    #         fcur_=self.fontid[font] # 原字体
+                    # except:
+                    #     pass
+                    try:
+                        if fcur_ is None and self.fontmap[""tiro""].to_unichr(ord(ch)) == ch:
+                            fcur_ = ""tiro""  # 默认英文字体
+                    except Exception:
+                        pass
+                    if fcur_ is None:
+                        fcur_ = ""china-ss""  # 默认中文字体
+                    # print(self.fontid[font],fcur_,ch,font.char_width(ord(ch)))
+                    adv = self.fontmap[fcur_].char_width(ord(ch)) * size
+                    ptr += 1
+                if (                                # 输出文字缓冲区
+                    fcur_ != fcur                   # 1. 字体更新
+                    or vy_regex                     # 2. 插入公式
+                    or x + adv > rt + 0.1 * size    # 3. 到达右边界（可能一整行都被符号化，这里需要考虑浮点误差）
+                ):
+                    if cstk:
+                        ops += f""/{fcur} {size:f} Tf 1 0 0 1 {tx:f} {y:f} Tm [<{raw_string(fcur, cstk)}>] TJ ""
+                        cstk = """"
+                if lb and x + adv > rt + 0.1 * size:  # 到达右边界且原文段落存在换行
+                    x = lt
+                    lang_space = {""zh-CN"": 1.4,""zh-TW"": 1.4,""ja"": 1.1,""ko"": 1.2,""en"": 1.2}  # CJK
+                    y -= size * lang_space.get(self.translator.lang_out, 1.1)  # 小语种大多适配 1.1
+                if vy_regex:  # 插入公式
+                    fix = 0
+                    if fcur is not None:  # 段落内公式修正纵向偏移
+                        fix = varf[vid]
+                    for vch in var[vid]:  # 排版公式字符
+                        vc = chr(vch.cid)
+                        ops += f""/{self.fontid[vch.font]} {vch.size:f} Tf 1 0 0 1 {x + vch.x0 - var[vid][0].x0:f} {fix + y + vch.y0 - var[vid][0].y0:f} Tm [<{raw_string(self.fontid[vch.font], vc)}>] TJ ""  # noqa: E501
+                        if log.isEnabledFor(logging.DEBUG):
+                            lstk.append(LTLine(0.1,(_x, _y),(x + vch.x0 - var[vid][0].x0,fix + y + vch.y0 - var[vid][0].y0,)))
+                            _x, _y = x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0
+                    for l in varl[vid]:  # 排版公式线条 # noqa: E741
+                        if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
+                            ops += f""ET q 1 0 0 1 {l.pts[0][0] + x - var[vid][0].x0:f} {l.pts[0][1] + fix + y - var[vid][0].y0:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
+                else:  # 插入文字缓冲区
+                    if not cstk:  # 单行开头
+                        tx = x
+                        if x == lt and ch == "" "":  # 消除段落换行空格
+                            adv = 0
                         else:
                             cstk += ch
-                    if mod:  # 文字修饰符
-                        adv = 0
-                    fcur = fcur_
-                    x += adv
-                    if log.isEnabledFor(logging.DEBUG):
-                        lstk.append(LTLine(0.1, (_x, _y), (x, y)))
-                        _x, _y = x, y
-            for l in lstk:  # 排版全局线条 # noqa: E741
-                if l.linewidth < 5:  # hack
-                    ops += f""ET q 1 0 0 1 {l.pts[0][0]:f} {l.pts[0][1]:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
-            ops = f""BT {ops}ET ""
-            return ops
-
-        ops = render(ltpage)
+                    else:
+                        cstk += ch
+                if mod:  # 文字修饰符
+                    adv = 0
+                fcur = fcur_
+                x += adv
+                if log.isEnabledFor(logging.DEBUG):
+                    lstk.append(LTLine(0.1, (_x, _y), (x, y)))
+                    _x, _y = x, y
+        for l in lstk:  # 排版全局线条 # noqa: E741
+            if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
+                ops += f""ET q 1 0 0 1 {l.pts[0][0]:f} {l.pts[0][1]:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
+        ops = f""BT {ops}ET ""
         return ops
 
     # Some dummy functions to save memory/CPU when all that is wanted
",add support for textdev,
3394aee69f670ec34e80d34fc31cc5c317f45e9d,high_level.py,"@@ -205,7 +205,7 @@ def extract_text_to_fp(
             # print(page.number,page_layout)
             page.rotate = (page.rotate + rotation) % 360
             # 新建一个 xref 存放新指令流
-            page.page_xref = doc_en.get_new_xref()  # hack
+            page.page_xref = doc_en.get_new_xref()  # hack 插入页面的新 xref
             doc_en.update_object(page.page_xref, ""<<>>"")
             doc_en.update_stream(page.page_xref, b"""")
             doc_en[page.pageno].set_contents(page.page_xref)
",update extract_text_to_fp,
3394aee69f670ec34e80d34fc31cc5c317f45e9d,pdf2zh.py,"@@ -8,7 +8,6 @@ from __future__ import annotations
 import argparse
 import logging
 import os
-import subprocess
 import sys
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, Container, Iterable, List, Optional
@@ -93,45 +92,7 @@ def extract_text(
     for file in files:
         filename = os.path.splitext(os.path.basename(file))[0]
 
-        def convert_to_pdfa(input_pdf_path, output_pdfa_path):
-            """"""
-            Converts a PDF to PDF/A format using Ghostscript.
-            Args:
-                input_pdf_path (str): Path to the input PDF file.
-                output_pdfa_path (str): Path where the PDF/A file will be saved.
-            """"""
-            try:
-                # Ghostscript command for conversion
-                command = [
-                    ""gs"",
-                    ""-dPDFA"",
-                    ""-dBATCH"",
-                    ""-dNOPAUSE"",
-                    ""-dNOOUTERSAVE"",
-                    ""-sDEVICE=pdfwrite"",
-                    ""-sOutputFile="" + output_pdfa_path,
-                    ""-dPDFACompatibilityPolicy=1"",
-                    input_pdf_path,
-                ]
-
-                # Run the command
-                subprocess.run(command, check=True)
-                print(
-                    f""Successfully converted {input_pdf_path} to PDF/A at {output_pdfa_path}""
-                )
-            except subprocess.CalledProcessError as e:
-                print(f""Error during conversion: {e}"")
-            except FileNotFoundError:
-                print(""Ghostscript is not installed or not found in the PATH."")
-
-        try:
-            file_pdfa = f""{str(file)}-pdfa.pdf""
-            convert_to_pdfa(file, file_pdfa)
-            doc_en = pymupdf.open(file_pdfa)
-        except Exception as e:
-            print(f""Error converting PDF: {e}"")
-            doc_en = pymupdf.open(file)
-
+        doc_en = pymupdf.open(file)
         page_count = doc_en.page_count
         font_list = [""china-ss"", ""tiro""]
         font_id = {}
","add support for ghostscript in -93,45",
1b7f405970cb9bcd856ab1bb4c92f68dd221e79a,python-build.yml,"@@ -25,7 +25,7 @@ jobs:
     - name: Check code format
       run: |
         black --check --diff --color pdf2zh/*.py
-        flake8
+        flake8 --ignore E203,E261,E501,W503,E741
 
     - name: Build package
       run: python -m build
",add missing build tag to list of build jobs,
1b7f405970cb9bcd856ab1bb4c92f68dd221e79a,.pre-commit-config.yaml,"@@ -10,5 +10,5 @@ repos:
       language: python
     - id: flake8
       name: flake8
-      entry: flake8
+      entry: flake8 --ignore E203,E261,E501,W503,E741
       language: python
",add missing line,
1b7f405970cb9bcd856ab1bb4c92f68dd221e79a,converter.py,"@@ -511,7 +511,7 @@ class TextConverter(PDFConverter[AnyIO]):
                             pstk[-1][6] = True
                     else:                           # 根据当前字符构建一个新的段落
                         sstk.append("""")
-                        pstk.append([child.y0,child.x0,child.x0,child.x0,child.size,child.font,False,])
+                        pstk.append([child.y0, child.x0, child.x0, child.x0, child.size, child.font, False])
                 if not cur_v:                                               # 文字入栈
                     if (                                                    # 根据当前字符修正段落属性
                         child.size > pstk[-1][4] / 0.79                     # 1. 当前字符显著比段落字体大
@@ -565,7 +565,7 @@ class TextConverter(PDFConverter[AnyIO]):
             varf.append(vfix)
         log.debug(""\n==========[VSTACK]==========\n"")
         for id, v in enumerate(var):  # 计算公式宽度
-            l = max([vch.x1 for vch in v]) - v[0].x0  # noqa: E741
+            l = max([vch.x1 for vch in v]) - v[0].x0
             log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
             vlen.append(l)
 
@@ -574,6 +574,7 @@ class TextConverter(PDFConverter[AnyIO]):
         log.debug(""\n==========[SSTACK]==========\n"")
         hash_key = cache.deterministic_hash(""PDFMathTranslate"")
         cache.create_cache(hash_key)
+
         @retry(wait=wait_fixed(1))
         def worker(s):  # 多线程翻译
             try:
@@ -604,6 +605,7 @@ class TextConverter(PDFConverter[AnyIO]):
                 return """".join([""%04x"" % ord(c) for c in cstk])
             else:
                 return """".join([""%02x"" % ord(c) for c in cstk])
+
         _x, _y = 0, 0
         for id, new in enumerate(news):
             tx = x = pstk[id][1]    # 段落初始横坐标
@@ -633,9 +635,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         adv = vlen[vid]
                     except Exception:
                         continue  # 翻译器可能会自动补个越界的公式标记
-                    if len(var[vid]) == 1 and unicodedata.category(
-                        var[vid][0].get_text()[0]
-                    ) in [""Lm"",""Mn"",""Sk"",]:  # 文字修饰符
+                    if len(var[vid]) == 1 and unicodedata.category(var[vid][0].get_text()[0]) in [""Lm"", ""Mn"", ""Sk""]:  # 文字修饰符
                         mod = True
                 else:  # 加载文字
                     ch = new[ptr]
@@ -667,7 +667,7 @@ class TextConverter(PDFConverter[AnyIO]):
                         cstk = """"
                 if lb and x + adv > rt + 0.1 * size:  # 到达右边界且原文段落存在换行
                     x = lt
-                    lang_space = {""zh-CN"": 1.4,""zh-TW"": 1.4,""ja"": 1.1,""ko"": 1.2,""en"": 1.2}  # CJK
+                    lang_space = {""zh-CN"": 1.4, ""zh-TW"": 1.4, ""ja"": 1.1, ""ko"": 1.2, ""en"": 1.2}  # CJK
                     y -= size * lang_space.get(self.translator.lang_out, 1.1)  # 小语种大多适配 1.1
                 if vy_regex:  # 插入公式
                     fix = 0
@@ -675,13 +675,13 @@ class TextConverter(PDFConverter[AnyIO]):
                         fix = varf[vid]
                     for vch in var[vid]:  # 排版公式字符
                         vc = chr(vch.cid)
-                        ops += f""/{self.fontid[vch.font]} {vch.size:f} Tf 1 0 0 1 {x + vch.x0 - var[vid][0].x0:f} {fix + y + vch.y0 - var[vid][0].y0:f} Tm [<{raw_string(self.fontid[vch.font], vc)}>] TJ ""  # noqa: E501
+                        ops += f""/{self.fontid[vch.font]} {vch.size:f} Tf 1 0 0 1 {x + vch.x0 - var[vid][0].x0:f} {fix + y + vch.y0 - var[vid][0].y0:f} Tm [<{raw_string(self.fontid[vch.font], vc)}>] TJ ""
                         if log.isEnabledFor(logging.DEBUG):
-                            lstk.append(LTLine(0.1,(_x, _y),(x + vch.x0 - var[vid][0].x0,fix + y + vch.y0 - var[vid][0].y0,)))
+                            lstk.append(LTLine(0.1, (_x, _y), (x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0)))
                             _x, _y = x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0
-                    for l in varl[vid]:  # 排版公式线条 # noqa: E741
+                    for l in varl[vid]:  # 排版公式线条
                         if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
-                            ops += f""ET q 1 0 0 1 {l.pts[0][0] + x - var[vid][0].x0:f} {l.pts[0][1] + fix + y - var[vid][0].y0:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
+                            ops += f""ET q 1 0 0 1 {l.pts[0][0] + x - var[vid][0].x0:f} {l.pts[0][1] + fix + y - var[vid][0].y0:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""
                 else:  # 插入文字缓冲区
                     if not cstk:  # 单行开头
                         tx = x
@@ -698,9 +698,9 @@ class TextConverter(PDFConverter[AnyIO]):
                 if log.isEnabledFor(logging.DEBUG):
                     lstk.append(LTLine(0.1, (_x, _y), (x, y)))
                     _x, _y = x, y
-        for l in lstk:  # 排版全局线条 # noqa: E741
+        for l in lstk:  # 排版全局线条
             if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
-                ops += f""ET q 1 0 0 1 {l.pts[0][0]:f} {l.pts[0][1]:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""  # noqa: E501
+                ops += f""ET q 1 0 0 1 {l.pts[0][0]:f} {l.pts[0][1]:f} cm [] 0 d 0 J {l.linewidth:f} w 0 0 m {l.pts[1][0] - l.pts[0][0]:f} {l.pts[1][1] - l.pts[0][1]:f} l S Q BT ""
         ops = f""BT {ops}ET ""
         return ops
 
",add support for 当前字符显著比段落字体大,
33aa762bd581a9c58ca9e02e86848cd3183ba0a0,README.md,"@@ -39,7 +39,6 @@ Feel free to provide feedback in [GitHub Issues](https://github.com/Byaidu/PDFMa
 
 - [Nov. 23 2024] [ONNX](https://github.com/onnx/onnx) support to reduce dependency sizes *(by [@Wybxc](https://github.com/Wybxc))*  
 - [Nov. 23 2024] 🌟 [Public Service](#demo)  online! *(by [@Byaidu](https://github.com/Byaidu))*  
-- [Nov. 23 2024] Non-PDF/A documents are now supported *(by [@reycn](https://github.com/reycn))*  
 - [Nov. 23 2024] Firewall for preventing web bots *(by [@Byaidu](https://github.com/Byaidu))*  
 - [Nov. 22 2024] GUI now supports Italian, and has been improved *(by [@Byaidu](https://github.com/Byaidu), [@reycn](https://github.com/reycn))*  
 - [Nov. 22 2024] You can now share your deployed service to others *(by [@Zxis233](https://github.com/Zxis233))*  
",add more examples to the docs,
33aa762bd581a9c58ca9e02e86848cd3183ba0a0,README_zh-CN.md,"@@ -39,7 +39,6 @@
 
 - [Nov. 24 2024] 为降低依赖大小，提供 [ONNX](https://github.com/onnx/onnx) 支持 *(by [@Wybxc](https://github.com/Wybxc))*  
 - [Nov. 23 2024] 🌟 [免费公共服务](#demo) 上线! *(by [@Byaidu](https://github.com/Byaidu))*  
-- [Nov. 23 2024] 非 PDF/A 文档也能正常翻译了 *(by [@reycn](https://github.com/reycn))*  
 - [Nov. 23 2024] 防止网页爬虫的防火墙 *(by [@Byaidu](https://github.com/Byaidu))*  
 - [Nov. 22 2024] 图形用户界面现已支持意大利语，并获得了一些更新 *(by [@Byaidu](https://github.com/Byaidu), [@reycn](https://github.com/reycn))*  
 - [Nov. 22 2024] 现在你可以将自己部署的服务分享给朋友了 *(by [@Zxis233](https://github.com/Zxis233))*  
",add examples,
33aa762bd581a9c58ca9e02e86848cd3183ba0a0,gui.py,"@@ -400,8 +400,6 @@ with gr.Blocks(
 
 
 def setup_gui(share=False):
-    import doclayout_yolo  # cache # noqa: F401
-
     if flag_demo:
         demo.launch(server_name=""0.0.0.0"", max_file_size=""5mb"", inbrowser=True)
     else:
",add flag_demo to setup_gui,
68f7026999a96678cb7d99a77b78cd80fc3de328,pyproject.toml,"@@ -1,6 +1,6 @@
 [project]
 name = ""pdf2zh""
-version = ""1.7.9""
+version = ""1.8.0""
 description = ""Latex PDF Translator""
 authors = [{ name = ""Byaidu"", email = ""byaidux@gmail.com"" }]
 license = ""AGPL-3.0""
",add missing version in missing file,
b099f0a70daf95e8167413fcecd55f0eadee1f25,converter.py,"@@ -528,10 +528,10 @@ class TextConverter(PDFConverter[AnyIO]):
                         pstk[-1][5] = child.font
                     sstk[-1] += child.get_text()
                 else:                                                       # 公式入栈
-                    if (                                                    # 根据公式右侧的文字修正公式的纵向偏移
+                    if (                                                    # 根据公式左侧的文字修正公式的纵向偏移
                         not vstk                                            # 1. 当前字符是公式的第一个字符
                         and cls == xt_cls                                   # 2. 当前字符与前一个字符属于同一段落
-                        and child.x0 > xt.x0                                # 3. 当前字符在前一个字符右侧
+                        and child.x0 > xt.x0                                # 3. 前一个字符在公式左侧
                     ):
                         vfix = child.y0 - xt.y0
                     vstk.append(child)
",add support for 公式左侧的文字修正公式纵向偏移,
c144e14b526d92c88e8e0b412eab00d35a7690f1,translator.py,"@@ -173,7 +173,6 @@ class DeepLXTranslator(BaseTranslator):
             self.base_link = f""{server_url}/{auth_key}/translate""
         else:
             self.base_link = f""{server_url}/translate""
-        self.base_link = f""{server_url}/{auth_key}/translate""
         self.headers = {
             ""User-Agent"": ""Mozilla/4.0 (compatible;MSIE 6.0;Windows NT 5.1;SV1;.NET CLR 1.1.4322;.NET CLR 2.0.50727;.NET CLR 3.0.04506.30)""  # noqa: E501
         }
",add missing headers,
94f4bda439379f69621b9c903b59e468cb1a4d10,Dockerfile,"@@ -4,6 +4,8 @@ WORKDIR /app
 
 COPY . .
 
+EXPOSE 7860
+
 ENV PYTHONUNBUFFERED=1
 
 RUN apt-get update && apt-get install -y libgl1
",add missing env variable,
94f4bda439379f69621b9c903b59e468cb1a4d10,Dockerfile.Demo,"@@ -4,6 +4,8 @@ WORKDIR /app
 
 COPY . .
 
+EXPOSE 7860
+
 ENV PYTHONUNBUFFERED=1
 
 RUN apt-get update && apt-get install -y libgl1
",add missing env variable,
772b0130fdbad3939d265be2fad63c02b1aa49cc,pdf2zh.py,"@@ -97,7 +97,7 @@ def extract_text(
     model = DocLayoutModel.load_available()
 
     for file in files:
-        if file.startswith(""http://"") or file.startswith(""https://""):
+        if file is str and (file.startswith(""http://"") or file.startswith(""https://"")):
             print(""Online files detected, downloading..."")
             try:
                 r = requests.get(file, allow_redirects=True)
",add download script,
f2b1fb8ba6501e41b8f619049da67e1ffd1fba9a,translator.py,"@@ -121,7 +121,7 @@ class TencentTranslator(BaseTranslator):
             + ""\n""
             + hashed_canonical_request
         )
-        secret_date = self.sign((""TC3"" + self.secret_key).encode(""utf-8""), date)
+        secret_date = self.sign((""TC3"" + str(self.secret_key)).encode(""utf-8""), date)
         secret_service = self.sign(secret_date, ""tmt"")
         secret_signing = self.sign(secret_service, ""tc3_request"")
         signed_headers = ""content-type;host;x-tc-action""
@@ -132,7 +132,7 @@ class TencentTranslator(BaseTranslator):
             algorithm
             + "" ""
             + ""Credential=""
-            + self.secret_id
+            + str(self.secret_id)
             + ""/""
             + credential_scope
             + "", ""
@@ -194,7 +194,7 @@ class DeepLXTranslator(BaseTranslator):
             ) from e
 
         self.session = requests.Session()
-        server_url = server_url.rstrip(""/"")
+        server_url = str(server_url).rstrip(""/"")
         if auth_key:
             self.base_link = f""{server_url}/{auth_key}/translate""
         else:
",add more info to the tencent translator,
f560f1bc0e3b144cacbfecfbd9b210c50385eaf7,问题反馈.md,"@@ -10,7 +10,7 @@ assignees: ''
 ## 问题描述
 请对问题进行描述，并提供日志或截图
 请确认 issues 中没有相同问题且完整阅读 wiki
-**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed/unable to connect to proxy）
+**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed/unable to connect to proxy/LocalEntryNotFoundError）
 
 ## 测试文档
 > [!IMPORTANT]
",add missing comments,
e4d714699a0b6fcdd589506d4c4088a170fd2f23,README.md,"@@ -281,6 +281,8 @@ pdf2zh example.pdf -t 1
 
 - [ ] Support multiple language with [Noto Font](https://fonts.google.com/noto), [Ubuntu Font](https://design.ubuntu.com/font)
 
+- [ ] Retry except KeyboardInterrupt
+
 <h2 id=""acknowledgement"">Acknowledgements</h2>
 
 - Document merging: [PyMuPDF](https://github.com/pymupdf/PyMuPDF)
",add a link to the example page,
e4d714699a0b6fcdd589506d4c4088a170fd2f23,converter.py,"@@ -1,5 +1,7 @@
+from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
 from pdfminer.pdffont import PDFCIDFont
 from pdfminer.converter import PDFConverter
+from pdfminer.pdffont import PDFUnicodeNotDefined
 from pdfminer.layout import (
     LTChar,
     LTFigure,
@@ -27,7 +29,58 @@ from pdf2zh.translator import (
 log = logging.getLogger(__name__)
 
 
-class TranslateConverter(PDFConverter):
+class PDFConverterEx(PDFConverter):
+    def __init__(
+        self,
+        rsrcmgr: PDFResourceManager,
+        outfp,
+        codec: str = ""utf-8"",
+        pageno: int = 1,
+        laparams=None,
+    ) -> None:
+        PDFConverter.__init__(self, rsrcmgr, outfp, codec, pageno, laparams)
+
+    def end_page(self, page):
+        # self.pageno += 1
+        return self.receive_layout(self.cur_item)
+
+    def render_char(
+        self,
+        matrix,
+        font,
+        fontsize: float,
+        scaling: float,
+        rise: float,
+        cid: int,
+        ncs,
+        graphicstate: PDFGraphicState,
+    ) -> float:
+        try:
+            text = font.to_unichr(cid)
+            assert isinstance(text, str), str(type(text))
+        except PDFUnicodeNotDefined:
+            text = self.handle_undefined_char(font, cid)
+        textwidth = font.char_width(cid)
+        textdisp = font.char_disp(cid)
+        item = LTChar(
+            matrix,
+            font,
+            fontsize,
+            scaling,
+            rise,
+            text,
+            textwidth,
+            textdisp,
+            ncs,
+            graphicstate,
+        )
+        self.cur_item.add(item)
+        item.cid = cid  # hack 插入原字符编码
+        item.font = font  # hack 插入原字符字体
+        return item.adv
+
+
+class TranslateConverter(PDFConverterEx):
     def __init__(
         self,
         rsrcmgr,
@@ -133,6 +186,7 @@ class TranslateConverter(PDFConverter):
             if isinstance(child, LTChar):
                 cur_v = False
                 fontname = child.fontname.split(""+"")[-1]
+                ltpage.pageid = 0 # hack DEBUG ONLY
                 layout = self.layout[ltpage.pageid]
                 # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
                 h, w = layout.shape
@@ -256,7 +310,6 @@ class TranslateConverter(PDFConverter):
                 new = cache.load_paragraph(hash_key, hash_key_paragraph)  # 查询缓存
                 if new is None:
                     new = self.translator.translate(s)
-                    new = remove_control_characters(new)
                     cache.write_paragraph(hash_key, hash_key_paragraph, new)
                 return new
             except BaseException as e:
",add support for unicode in ltchar,
e4d714699a0b6fcdd589506d4c4088a170fd2f23,high_level.py,"@@ -66,7 +66,7 @@ def extract_text_to_fp(
         for page in progress:
             if callback:
                 callback(progress)
-            page.pageno = 1  # hack
+            page.pageno = 0  # hack DEBUG ONLY
             pix = doc_en[page.pageno].get_pixmap()
             image = np.fromstring(pix.samples, np.uint8).reshape(
                 pix.height, pix.width, 3
",update extract_text_to_fp.py,
f864a8052cd97c422afb00713efcae94cc0c5f42,converter.py,"@@ -92,7 +92,7 @@ class TranslateConverter(PDFConverterEx):
         lang_out: str = """",
         service: str = """",
     ) -> None:
-        super().__init__(rsrcmgr, None, ""utf-8"", 1, None)
+        super().__init__(rsrcmgr, None, ""utf-8"", 1, None)  # hack DEBUG ONLY
         self.vfont = vfont
         self.vchar = vchar
         self.thread = thread
",add missing debug flag,
f864a8052cd97c422afb00713efcae94cc0c5f42,high_level.py,"@@ -1,9 +1,7 @@
 """"""Functions that can be used for the most common use-cases for pdf2zh.six""""""
 
 import logging
-import sys
-from io import StringIO
-from typing import Any, BinaryIO, Container, Iterator, Optional, cast
+from typing import BinaryIO
 import numpy as np
 import tqdm
 from pymupdf import Document
",add missing import,
f864a8052cd97c422afb00713efcae94cc0c5f42,pdf2zh.py,"@@ -9,7 +9,8 @@ import argparse
 import os
 import sys
 from pathlib import Path
-from typing import TYPE_CHECKING, Any, Container, Iterable, List, Optional
+from typing import Any, Container, Iterable, List, Optional
+from pdfminer.pdfexceptions import PDFValueError
 
 import pymupdf
 import requests
@@ -28,15 +29,6 @@ def check_files(files: List[str]) -> List[str]:
     return missing_files
 
 
-def float_or_disabled(x: str) -> Optional[float]:
-    if x.lower().strip() == ""disabled"":
-        return None
-    try:
-        return float(x)
-    except ValueError:
-        raise argparse.ArgumentTypeError(f""invalid float value: {x}"")
-
-
 def extract_text(
     files: Iterable[str] = [],
     pages: Optional[Container[int]] = None,
@@ -51,14 +43,13 @@ def extract_text(
     callback: object = None,
     output: str = """",
     **kwargs: Any,
-) -> AnyIO:
+):
     import pdf2zh.high_level
     from pdf2zh.doclayout import DocLayoutModel
 
     if not files:
         raise PDFValueError(""Must provide files to work upon!"")
 
-    outfp: AnyIO = sys.stdout
     model = DocLayoutModel.load_available()
 
     for file in files:
@@ -271,4 +262,3 @@ def main(args: Optional[List[str]] = None) -> int:
 
 if __name__ == ""__main__"":
     sys.exit(main())
-    sys.exit(main())
",add docutils script for missing files,
f864a8052cd97c422afb00713efcae94cc0c5f42,pdfinterp.py,"@@ -1,49 +1,39 @@
 import logging
-import re
-from io import BytesIO
-from typing import Dict, List, Mapping, Optional, Sequence, Tuple, Union, cast
+from typing import Any, Dict, Optional, Sequence, Tuple, cast
 import numpy as np
 
 from pdfminer import settings
-from pdfminer.cmapdb import CMap, CMapBase, CMapDB
 from pdfminer.pdfcolor import PREDEFINED_COLORSPACE, PDFColorSpace
-from pdfminer.pdfdevice import PDFDevice, PDFTextSeq
-from pdfminer.pdffont import (
-    PDFCIDFont,
-    PDFFont,
-    PDFFontError,
-    PDFTrueTypeFont,
-    PDFType1Font,
-    PDFType3Font,
+from pdfminer.pdfdevice import PDFDevice
+from pdfminer.pdfinterp import (
+    PDFPageInterpreter,
+    PDFResourceManager,
+    PDFContentParser,
+    PDFInterpreterError,
+    Color,
+    PDFStackT,
+    LITERAL_FORM,
+    LITERAL_IMAGE,
 )
+from pdfminer.pdffont import PDFFont
 from pdfminer.pdfpage import PDFPage
 from pdfminer.pdftypes import (
-    LITERALS_ASCII85_DECODE,
     PDFObjRef,
-    PDFStream,
     dict_value,
     list_value,
     resolve1,
     stream_value,
 )
-from pdfminer.psparser import PSEOF
+from pdfminer.psexceptions import PSEOF
 from pdfminer.psparser import (
-    KWD,
-    LIT,
     PSKeyword,
-    PSLiteral,
-    PSStackParser,
-    PSStackType,
     keyword_name,
     literal_name,
 )
 from pdfminer.utils import (
     MATRIX_IDENTITY,
     Matrix,
-    PathSegment,
-    Point,
     Rect,
-    choplist,
     mult_matrix,
     apply_matrix_pt,
 )
@@ -51,312 +41,14 @@ from pdfminer.utils import (
 log = logging.getLogger(__name__)
 
 
-class PDFInterpreterError(Exception):
-    pass
+def safe_float(o: Any) -> Optional[float]:
+    try:
+        return float(o)
+    except (TypeError, ValueError):
+        return None
 
 
-LITERAL_PDF = LIT(""PDF"")
-LITERAL_TEXT = LIT(""Text"")
-LITERAL_FONT = LIT(""Font"")
-LITERAL_FORM = LIT(""Form"")
-LITERAL_IMAGE = LIT(""Image"")
-
-
-class PDFTextState:
-    matrix: Matrix
-    linematrix: Point
-
-    def __init__(self) -> None:
-        self.font: Optional[PDFFont] = None
-        self.fontsize: float = 0
-        self.charspace: float = 0
-        self.wordspace: float = 0
-        self.scaling: float = 100
-        self.leading: float = 0
-        self.render: int = 0
-        self.rise: float = 0
-        self.reset()
-        # self.matrix is set
-        # self.linematrix is set
-
-    def __repr__(self) -> str:
-        return (
-            ""<PDFTextState: font=%r, fontsize=%r, charspace=%r, ""
-            ""wordspace=%r, scaling=%r, leading=%r, render=%r, rise=%r, ""
-            ""matrix=%r, linematrix=%r>""
-            % (
-                self.font,
-                self.fontsize,
-                self.charspace,
-                self.wordspace,
-                self.scaling,
-                self.leading,
-                self.render,
-                self.rise,
-                self.matrix,
-                self.linematrix,
-            )
-        )
-
-    def copy(self) -> ""PDFTextState"":
-        obj = PDFTextState()
-        obj.font = self.font
-        obj.fontsize = self.fontsize
-        obj.charspace = self.charspace
-        obj.wordspace = self.wordspace
-        obj.scaling = self.scaling
-        obj.leading = self.leading
-        obj.render = self.render
-        obj.rise = self.rise
-        obj.matrix = self.matrix
-        obj.linematrix = self.linematrix
-        return obj
-
-    def reset(self) -> None:
-        self.matrix = MATRIX_IDENTITY
-        self.linematrix = (0, 0)
-
-
-Color = Union[
-    float,  # Greyscale
-    Tuple[float, float, float],  # R, G, B
-    Tuple[float, float, float, float],  # C, M, Y, K
-]
-
-
-class PDFGraphicState:
-    def __init__(self) -> None:
-        self.linewidth: float = 0
-        self.linecap: Optional[object] = None
-        self.linejoin: Optional[object] = None
-        self.miterlimit: Optional[object] = None
-        self.dash: Optional[Tuple[object, object]] = None
-        self.intent: Optional[object] = None
-        self.flatness: Optional[object] = None
-
-        # stroking color
-        self.scolor: Optional[Color] = None
-
-        # non stroking color
-        self.ncolor: Optional[Color] = None
-
-    def copy(self) -> ""PDFGraphicState"":
-        obj = PDFGraphicState()
-        obj.linewidth = self.linewidth
-        obj.linecap = self.linecap
-        obj.linejoin = self.linejoin
-        obj.miterlimit = self.miterlimit
-        obj.dash = self.dash
-        obj.intent = self.intent
-        obj.flatness = self.flatness
-        obj.scolor = self.scolor
-        obj.ncolor = self.ncolor
-        return obj
-
-    def __repr__(self) -> str:
-        return (
-            ""<PDFGraphicState: linewidth=%r, linecap=%r, linejoin=%r, ""
-            "" miterlimit=%r, dash=%r, intent=%r, flatness=%r, ""
-            "" stroking color=%r, non stroking color=%r>""
-            % (
-                self.linewidth,
-                self.linecap,
-                self.linejoin,
-                self.miterlimit,
-                self.dash,
-                self.intent,
-                self.flatness,
-                self.scolor,
-                self.ncolor,
-            )
-        )
-
-
-class PDFResourceManager:
-    """"""Repository of shared resources.
-
-    ResourceManager facilitates reuse of shared resources
-    such as fonts and images so that large objects are not
-    allocated multiple times.
-    """"""
-
-    def __init__(self, caching: bool = True) -> None:
-        self.caching = caching
-        self._cached_fonts: Dict[object, PDFFont] = {}
-
-    def get_procset(self, procs: Sequence[object]) -> None:
-        for proc in procs:
-            if proc is LITERAL_PDF or proc is LITERAL_TEXT:
-                pass
-            else:
-                pass
-
-    def get_cmap(self, cmapname: str, strict: bool = False) -> CMapBase:
-        try:
-            return CMapDB.get_cmap(cmapname)
-        except CMapDB.CMapNotFound:
-            if strict:
-                raise
-            return CMap()
-
-    def get_font(self, objid: object, spec: Mapping[str, object]) -> PDFFont:
-        if objid and objid in self._cached_fonts:
-            font = self._cached_fonts[objid]
-        else:
-            # log.debug(""get_font: create: objid=%r, spec=%r"", objid, spec)
-            if settings.STRICT:
-                if spec[""Type""] is not LITERAL_FONT:
-                    raise PDFFontError(""Type is not /Font"")
-            # Create a Font object.
-            if ""Subtype"" in spec:
-                subtype = literal_name(spec[""Subtype""])
-            else:
-                if settings.STRICT:
-                    raise PDFFontError(""Font Subtype is not specified."")
-                subtype = ""Type1""
-            if subtype in (""Type1"", ""MMType1""):
-                # Type1 Font
-                font = PDFType1Font(self, spec)
-            elif subtype == ""TrueType"":
-                # TrueType Font
-                font = PDFTrueTypeFont(self, spec)
-            elif subtype == ""Type3"":
-                # Type3 Font
-                font = PDFType3Font(self, spec)
-            elif subtype in (""CIDFontType0"", ""CIDFontType2""):
-                # CID Font
-                font = PDFCIDFont(self, spec)
-            elif subtype == ""Type0"":
-                # Type0 Font
-                dfonts = list_value(spec[""DescendantFonts""])
-                assert dfonts
-                subspec = dict_value(dfonts[0]).copy()
-                for k in (""Encoding"", ""ToUnicode""):
-                    if k in spec:
-                        subspec[k] = resolve1(spec[k])
-                font = self.get_font(None, subspec)
-            else:
-                if settings.STRICT:
-                    raise PDFFontError(""Invalid Font spec: %r"" % spec)
-                font = PDFType1Font(self, spec)  # this is so wrong!
-            if objid and self.caching:
-                self._cached_fonts[objid] = font
-        return font
-
-
-class PDFContentParser(PSStackParser[Union[PSKeyword, PDFStream]]):
-    def __init__(self, streams: Sequence[object]) -> None:
-        self.streams = streams
-        self.istream = 0
-        # PSStackParser.__init__(fp=None) is safe only because we've overloaded
-        # all the methods that would attempt to access self.fp without first
-        # calling self.fillfp().
-        PSStackParser.__init__(self, None)  # type: ignore[arg-type]
-
-    def fillfp(self) -> None:
-        if not self.fp:
-            if self.istream < len(self.streams):
-                strm = stream_value(self.streams[self.istream])
-                self.istream += 1
-            else:
-                raise PSEOF(""Unexpected EOF, file truncated?"")
-            self.fp = BytesIO(strm.get_data())
-            # if log.isEnabledFor(logging.DEBUG):
-            #     log.debug(f'STREAM DATA {strm.get_data()}')
-
-    def seek(self, pos: int) -> None:
-        self.fillfp()
-        PSStackParser.seek(self, pos)
-
-    def fillbuf(self) -> None:
-        if self.charpos < len(self.buf):
-            return
-        while 1:
-            self.fillfp()
-            self.bufpos = self.fp.tell()
-            self.buf = self.fp.read(self.BUFSIZ)
-            if self.buf:
-                break
-            self.fp = None  # type: ignore[assignment]
-        self.charpos = 0
-
-    def get_inline_data(self, pos: int, target: bytes = b""EI"") -> Tuple[int, bytes]:
-        self.seek(pos)
-        i = 0
-        data = b""""
-        while i <= len(target):
-            self.fillbuf()
-            if i:
-                ci = self.buf[self.charpos]
-                c = bytes((ci,))
-                data += c
-                self.charpos += 1
-                if (
-                    len(target) <= i
-                    and c.isspace()
-                    or i < len(target)
-                    and c == (bytes((target[i],)))
-                ):
-                    i += 1
-                else:
-                    i = 0
-            else:
-                try:
-                    j = self.buf.index(target[0], self.charpos)
-                    data += self.buf[self.charpos : j + 1]
-                    self.charpos = j + 1
-                    i = 1
-                except ValueError:
-                    data += self.buf[self.charpos :]
-                    self.charpos = len(self.buf)
-        data = data[: -(len(target) + 1)]  # strip the last part
-        data = re.sub(rb""(\x0d\x0a|[\x0d\x0a])$"", b"""", data)
-        return (pos, data)
-
-    def flush(self) -> None:
-        self.add_results(*self.popall())
-
-    KEYWORD_BI = KWD(b""BI"")
-    KEYWORD_ID = KWD(b""ID"")
-    KEYWORD_EI = KWD(b""EI"")
-
-    def do_keyword(self, pos: int, token: PSKeyword) -> None:
-        if token is self.KEYWORD_BI:
-            # inline image within a content stream
-            self.start_type(pos, ""inline"")
-        elif token is self.KEYWORD_ID:
-            try:
-                (_, objs) = self.end_type(""inline"")
-                if len(objs) % 2 != 0:
-                    error_msg = f""Invalid dictionary construct: {objs!r}""
-                    raise PSTypeError(error_msg)
-                d = {literal_name(k): resolve1(v) for (k, v) in choplist(2, objs)}
-                eos = b""EI""
-                filter = d.get(""F"", None)
-                if filter is not None:
-                    if isinstance(filter, PSLiteral):
-                        filter = [filter]
-                    if filter[0] in LITERALS_ASCII85_DECODE:
-                        eos = b""~>""
-                (pos, data) = self.get_inline_data(pos + len(b""ID ""), target=eos)
-                if eos != b""EI"":  # it may be necessary for decoding
-                    data += eos
-                obj = PDFStream(d, data)
-                self.push((pos, obj))
-                if eos == b""EI"":  # otherwise it is still in the stream
-                    self.push((pos, self.KEYWORD_EI))
-            except PSTypeError:
-                if settings.STRICT:
-                    raise
-        else:
-            self.push((pos, token))
-
-
-PDFStackT = PSStackType[PDFStream]
-""""""Types that may appear on the PDF argument stack.""""""
-
-
-class PDFPageInterpreterEx:
+class PDFPageInterpreterEx(PDFPageInterpreter):
     """"""Processor for the content of a PDF page
 
     Reference: PDF Reference, Appendix A, Operator Summary
@@ -369,7 +61,7 @@ class PDFPageInterpreterEx:
         self.device = device
         self.obj_patch = obj_patch
 
-    def dup(self) -> ""PDFPageInterpreter"":
+    def dup(self) -> ""PDFPageInterpreterEx"":
         return self.__class__(self.rsrcmgr, self.device, self.obj_patch)
 
     def init_resources(self, resources: Dict[object, object]) -> None:
@@ -403,6 +95,7 @@ class PDFPageInterpreterEx:
                         objid = spec.objid
                     spec = dict_value(spec)
                     self.fontmap[fontid] = self.rsrcmgr.get_font(objid, spec)
+                    self.fontmap[fontid].descent = 0  # hack fix
                     self.fontid[self.fontmap[fontid]] = fontid
             elif k == ""ColorSpace"":
                 for csid, spec in dict_value(v).items():
@@ -415,155 +108,6 @@ class PDFPageInterpreterEx:
                 for xobjid, xobjstrm in dict_value(v).items():
                     self.xobjmap[xobjid] = xobjstrm
 
-    def init_state(self, ctm: Matrix) -> None:
-        """"""Initialize the text and graphic states for rendering a page.""""""
-        # gstack: stack for graphical states.
-        self.gstack: List[Tuple[Matrix, PDFTextState, PDFGraphicState]] = []
-        self.ctm = ctm
-        self.device.set_ctm(self.ctm)
-        self.textstate = PDFTextState()
-        self.graphicstate = PDFGraphicState()
-        self.curpath: List[PathSegment] = []
-        # argstack: stack for command arguments.
-        self.argstack: List[PDFStackT] = []
-        # set some global states.
-        self.scs: Optional[PDFColorSpace] = None
-        self.ncs: Optional[PDFColorSpace] = None
-        if self.csmap:
-            self.scs = self.ncs = next(iter(self.csmap.values()))
-
-    def push(self, obj: PDFStackT) -> None:
-        self.argstack.append(obj)
-
-    def pop(self, n: int) -> List[PDFStackT]:
-        if n == 0:
-            return []
-        x = self.argstack[-n:]
-        self.argstack = self.argstack[:-n]
-        return x
-
-    def get_current_state(self) -> Tuple[Matrix, PDFTextState, PDFGraphicState]:
-        return (self.ctm, self.textstate.copy(), self.graphicstate.copy())
-
-    def set_current_state(
-        self,
-        state: Tuple[Matrix, PDFTextState, PDFGraphicState],
-    ) -> None:
-        (self.ctm, self.textstate, self.graphicstate) = state
-        self.device.set_ctm(self.ctm)
-
-    def do_q(self) -> None:
-        """"""Save graphics state""""""
-        self.gstack.append(self.get_current_state())
-
-    def do_Q(self) -> None:
-        """"""Restore graphics state""""""
-        if self.gstack:
-            self.set_current_state(self.gstack.pop())
-
-    def do_cm(
-        self,
-        a1: PDFStackT,
-        b1: PDFStackT,
-        c1: PDFStackT,
-        d1: PDFStackT,
-        e1: PDFStackT,
-        f1: PDFStackT,
-    ) -> None:
-        """"""Concatenate matrix to current transformation matrix""""""
-        self.ctm = mult_matrix(cast(Matrix, (a1, b1, c1, d1, e1, f1)), self.ctm)
-        self.device.set_ctm(self.ctm)
-
-    def do_w(self, linewidth: PDFStackT) -> None:
-        """"""Set line width""""""
-        self.graphicstate.linewidth = cast(float, linewidth)
-
-    def do_J(self, linecap: PDFStackT) -> None:
-        """"""Set line cap style""""""
-        self.graphicstate.linecap = linecap
-
-    def do_j(self, linejoin: PDFStackT) -> None:
-        """"""Set line join style""""""
-        self.graphicstate.linejoin = linejoin
-
-    def do_M(self, miterlimit: PDFStackT) -> None:
-        """"""Set miter limit""""""
-        self.graphicstate.miterlimit = miterlimit
-
-    def do_d(self, dash: PDFStackT, phase: PDFStackT) -> None:
-        """"""Set line dash pattern""""""
-        self.graphicstate.dash = (dash, phase)
-
-    def do_ri(self, intent: PDFStackT) -> None:
-        """"""Set color rendering intent""""""
-        self.graphicstate.intent = intent
-
-    def do_i(self, flatness: PDFStackT) -> None:
-        """"""Set flatness tolerance""""""
-        self.graphicstate.flatness = flatness
-
-    def do_gs(self, name: PDFStackT) -> None:
-        """"""Set parameters from graphics state parameter dictionary""""""
-        # TODO
-
-    def do_m(self, x: PDFStackT, y: PDFStackT) -> None:
-        """"""Begin new subpath""""""
-        self.curpath.append((""m"", cast(float, x), cast(float, y)))
-
-    def do_l(self, x: PDFStackT, y: PDFStackT) -> None:
-        """"""Append straight line segment to path""""""
-        self.curpath.append((""l"", cast(float, x), cast(float, y)))
-
-    def do_c(
-        self,
-        x1: PDFStackT,
-        y1: PDFStackT,
-        x2: PDFStackT,
-        y2: PDFStackT,
-        x3: PDFStackT,
-        y3: PDFStackT,
-    ) -> None:
-        """"""Append curved segment to path (three control points)""""""
-        self.curpath.append(
-            (
-                ""c"",
-                cast(float, x1),
-                cast(float, y1),
-                cast(float, x2),
-                cast(float, y2),
-                cast(float, x3),
-                cast(float, y3),
-            ),
-        )
-
-    def do_v(self, x2: PDFStackT, y2: PDFStackT, x3: PDFStackT, y3: PDFStackT) -> None:
-        """"""Append curved segment to path (initial point replicated)""""""
-        self.curpath.append(
-            (""v"", cast(float, x2), cast(float, y2), cast(float, x3), cast(float, y3)),
-        )
-
-    def do_y(self, x1: PDFStackT, y1: PDFStackT, x3: PDFStackT, y3: PDFStackT) -> None:
-        """"""Append curved segment to path (final point replicated)""""""
-        self.curpath.append(
-            (""y"", cast(float, x1), cast(float, y1), cast(float, x3), cast(float, y3)),
-        )
-
-    def do_h(self) -> None:
-        """"""Close subpath""""""
-        self.curpath.append((""h"",))
-
-    def do_re(self, x: PDFStackT, y: PDFStackT, w: PDFStackT, h: PDFStackT) -> None:
-        """"""Append rectangle to path""""""
-        x = cast(float, x)
-        y = cast(float, y)
-        w = cast(float, w)
-        h = cast(float, h)
-        self.curpath.append((""m"", x, y))
-        self.curpath.append((""l"", x + w, y))
-        self.curpath.append((""l"", x + w, y + h))
-        self.curpath.append((""l"", x, y + h))
-        self.curpath.append((""h"",))
-
     def do_S(self) -> None:
         """"""Stroke path""""""
 
@@ -588,11 +132,6 @@ class PDFPageInterpreterEx:
         else:
             self.curpath = []
 
-    def do_s(self) -> None:
-        """"""Close and stroke path""""""
-        self.do_h()
-        self.do_S()
-
     def do_f(self) -> None:
         """"""Fill path using nonzero winding number rule""""""
         # self.device.paint_path(self.graphicstate, False, True, False, self.curpath)
@@ -616,85 +155,6 @@ class PDFPageInterpreterEx:
         # self.device.paint_path(self.graphicstate, True, True, True, self.curpath)
         self.curpath = []
 
-    def do_b(self) -> None:
-        """"""Close, fill, and stroke path using nonzero winding number rule""""""
-        self.do_h()
-        self.do_B()
-
-    def do_b_a(self) -> None:
-        """"""Close, fill, and stroke path using even-odd rule""""""
-        self.do_h()
-        self.do_B_a()
-
-    def do_n(self) -> None:
-        """"""End path without filling or stroking""""""
-        self.curpath = []
-
-    def do_W(self) -> None:
-        """"""Set clipping path using nonzero winding number rule""""""
-
-    def do_W_a(self) -> None:
-        """"""Set clipping path using even-odd rule""""""
-
-    def do_CS(self, name: PDFStackT) -> None:
-        """"""Set color space for stroking operations
-
-        Introduced in PDF 1.1
-        """"""
-        try:
-            self.scs = self.csmap[literal_name(name)]
-        except KeyError:
-            if settings.STRICT:
-                raise PDFInterpreterError(""Undefined ColorSpace: %r"" % name)
-
-    def do_cs(self, name: PDFStackT) -> None:
-        """"""Set color space for nonstroking operations""""""
-        try:
-            self.ncs = self.csmap[literal_name(name)]
-        except KeyError:
-            if settings.STRICT:
-                raise PDFInterpreterError(""Undefined ColorSpace: %r"" % name)
-
-    def do_G(self, gray: PDFStackT) -> None:
-        """"""Set gray level for stroking operations""""""
-        self.graphicstate.scolor = cast(float, gray)
-        self.scs = self.csmap[""DeviceGray""]
-
-    def do_g(self, gray: PDFStackT) -> None:
-        """"""Set gray level for nonstroking operations""""""
-        self.graphicstate.ncolor = cast(float, gray)
-        self.ncs = self.csmap[""DeviceGray""]
-
-    def do_RG(self, r: PDFStackT, g: PDFStackT, b: PDFStackT) -> None:
-        """"""Set RGB color for stroking operations""""""
-        self.graphicstate.scolor = (cast(float, r), cast(float, g), cast(float, b))
-        self.scs = self.csmap[""DeviceRGB""]
-
-    def do_rg(self, r: PDFStackT, g: PDFStackT, b: PDFStackT) -> None:
-        """"""Set RGB color for nonstroking operations""""""
-        self.graphicstate.ncolor = (cast(float, r), cast(float, g), cast(float, b))
-        self.ncs = self.csmap[""DeviceRGB""]
-
-    def do_K(self, c: PDFStackT, m: PDFStackT, y: PDFStackT, k: PDFStackT) -> None:
-        """"""Set CMYK color for stroking operations""""""
-        self.graphicstate.scolor = (
-            cast(float, c),
-            cast(float, m),
-            cast(float, y),
-            cast(float, k),
-        )
-        self.scs = self.csmap[""DeviceCMYK""]
-
-    def do_k(self, c: PDFStackT, m: PDFStackT, y: PDFStackT, k: PDFStackT) -> None:
-        """"""Set CMYK color for nonstroking operations""""""
-        self.graphicstate.ncolor = (
-            cast(float, c),
-            cast(float, m),
-            cast(float, y),
-            cast(float, k),
-        )
-        self.ncs = self.csmap[""DeviceCMYK""]
-
     def do_SCN(self) -> None:
         """"""Set color for stroking operations.""""""
         if self.scs:
@@ -727,220 +187,6 @@ class PDFPageInterpreterEx:
         """"""Set color for nonstroking operations""""""
         return self.do_scn()
 
-    def do_sh(self, name: object) -> None:
-        """"""Paint area defined by shading pattern""""""
-
-    def do_BT(self) -> None:
-        """"""Begin text object
-
-        Initializing the text matrix, Tm, and the text line matrix, Tlm, to
-        the identity matrix. Text objects cannot be nested; a second BT cannot
-        appear before an ET.
-        """"""
-        self.textstate.reset()
-
-    def do_ET(self) -> None:
-        """"""End a text object""""""
-
-    def do_BX(self) -> None:
-        """"""Begin compatibility section""""""
-
-    def do_EX(self) -> None:
-        """"""End compatibility section""""""
-
-    def do_MP(self, tag: PDFStackT) -> None:
-        """"""Define marked-content point""""""
-        self.device.do_tag(cast(PSLiteral, tag))
-
-    def do_DP(self, tag: PDFStackT, props: PDFStackT) -> None:
-        """"""Define marked-content point with property list""""""
-        self.device.do_tag(cast(PSLiteral, tag), props)
-
-    def do_BMC(self, tag: PDFStackT) -> None:
-        """"""Begin marked-content sequence""""""
-        self.device.begin_tag(cast(PSLiteral, tag))
-
-    def do_BDC(self, tag: PDFStackT, props: PDFStackT) -> None:
-        """"""Begin marked-content sequence with property list""""""
-        self.device.begin_tag(cast(PSLiteral, tag), props)
-
-    def do_EMC(self) -> None:
-        """"""End marked-content sequence""""""
-        self.device.end_tag()
-
-    def do_Tc(self, space: PDFStackT) -> None:
-        """"""Set character spacing.
-
-        Character spacing is used by the Tj, TJ, and ' operators.
-
-        :param space: a number expressed in unscaled text space units.
-        """"""
-        self.textstate.charspace = cast(float, space)
-
-    def do_Tw(self, space: PDFStackT) -> None:
-        """"""Set the word spacing.
-
-        Word spacing is used by the Tj, TJ, and ' operators.
-
-        :param space: a number expressed in unscaled text space units
-        """"""
-        self.textstate.wordspace = cast(float, space)
-
-    def do_Tz(self, scale: PDFStackT) -> None:
-        """"""Set the horizontal scaling.
-
-        :param scale: is a number specifying the percentage of the normal width
-        """"""
-        self.textstate.scaling = cast(float, scale)
-
-    def do_TL(self, leading: PDFStackT) -> None:
-        """"""Set the text leading.
-
-        Text leading is used only by the T*, ', and "" operators.
-
-        :param leading: a number expressed in unscaled text space units
-        """"""
-        self.textstate.leading = -cast(float, leading)
-
-    def do_Tf(self, fontid: PDFStackT, fontsize: PDFStackT) -> None:
-        """"""Set the text font
-
-        :param fontid: the name of a font resource in the Font subdictionary
-            of the current resource dictionary
-        :param fontsize: size is a number representing a scale factor.
-        """"""
-        try:
-            self.textstate.font = self.fontmap[literal_name(fontid)]
-        except KeyError:
-            if settings.STRICT:
-                raise PDFInterpreterError(""Undefined Font id: %r"" % fontid)
-            self.textstate.font = self.rsrcmgr.get_font(None, {})
-        self.textstate.fontsize = cast(float, fontsize)
-
-    def do_Tr(self, render: PDFStackT) -> None:
-        """"""Set the text rendering mode""""""
-        self.textstate.render = cast(int, render)
-
-    def do_Ts(self, rise: PDFStackT) -> None:
-        """"""Set the text rise
-
-        :param rise: a number expressed in unscaled text space units
-        """"""
-        self.textstate.rise = cast(float, rise)
-
-    def do_Td(self, tx: PDFStackT, ty: PDFStackT) -> None:
-        """"""Move to the start of the next line
-
-        Offset from the start of the current line by (tx , ty).
-        """"""
-        tx_ = cast(float, tx)
-        ty_ = cast(float, ty)
-        if tx_ is not None and ty_ is not None:
-            (a, b, c, d, e, f) = self.textstate.matrix
-            e_new = tx_ * a + ty_ * c + e
-            f_new = tx_ * b + ty_ * d + f
-            self.textstate.matrix = (a, b, c, d, e_new, f_new)
-
-        self.textstate.linematrix = (0, 0)
-
-    def do_TD(self, tx: PDFStackT, ty: PDFStackT) -> None:
-        """"""Move to the start of the next line.
-
-        offset from the start of the current line by (tx , ty). As a side effect, this
-        operator sets the leading parameter in the text state.
-        """"""
-        tx_ = safe_float(tx)
-        ty_ = safe_float(ty)
-
-        if tx_ is not None and ty_ is not None:
-            (a, b, c, d, e, f) = self.textstate.matrix
-            e_new = tx_ * a + ty_ * c + e
-            f_new = tx_ * b + ty_ * d + f
-            self.textstate.matrix = (a, b, c, d, e_new, f_new)
-
-        elif settings.STRICT:
-            raise PDFValueError(""Invalid offset ({tx}, {ty}) for TD"")
-
-        if ty_ is not None:
-            self.textstate.leading = ty_
-
-        self.textstate.linematrix = (0, 0)
-
-    def do_Tm(
-        self,
-        a: PDFStackT,
-        b: PDFStackT,
-        c: PDFStackT,
-        d: PDFStackT,
-        e: PDFStackT,
-        f: PDFStackT,
-    ) -> None:
-        """"""Set text matrix and text line matrix""""""
-        self.textstate.matrix = cast(Matrix, (a, b, c, d, e, f))
-        self.textstate.linematrix = (0, 0)
-
-    def do_T_a(self) -> None:
-        """"""Move to start of next text line""""""
-        (a, b, c, d, e, f) = self.textstate.matrix
-        self.textstate.matrix = (
-            a,
-            b,
-            c,
-            d,
-            self.textstate.leading * c + e,
-            self.textstate.leading * d + f,
-        )
-        self.textstate.linematrix = (0, 0)
-
-    def do_TJ(self, seq: PDFStackT) -> None:
-        """"""Show text, allowing individual glyph positioning""""""
-        if self.textstate.font is None:
-            if settings.STRICT:
-                raise PDFInterpreterError(""No font specified!"")
-            return
-        assert self.ncs is not None
-        self.device.render_string(
-            self.textstate,
-            cast(PDFTextSeq, seq),
-            self.ncs,
-            self.graphicstate.copy(),
-        )
-
-    def do_Tj(self, s: PDFStackT) -> None:
-        """"""Show text""""""
-        self.do_TJ([s])
-
-    def do__q(self, s: PDFStackT) -> None:
-        """"""Move to next line and show text
-
-        The ' (single quote) operator.
-        """"""
-        self.do_T_a()
-        self.do_TJ([s])
-
-    def do__w(self, aw: PDFStackT, ac: PDFStackT, s: PDFStackT) -> None:
-        """"""Set word and character spacing, move to next line, and show text
-
-        The "" (double quote) operator.
-        """"""
-        self.do_Tw(aw)
-        self.do_Tc(ac)
-        self.do_TJ([s])
-
-    def do_BI(self) -> None:
-        """"""Begin inline image object""""""
-
-    def do_ID(self) -> None:
-        """"""Begin inline image data""""""
-
-    def do_EI(self, obj: PDFStackT) -> None:
-        """"""End inline image object""""""
-        if isinstance(obj, PDFStream) and ""W"" in obj and ""H"" in obj:
-            iobjid = str(id(obj))
-            self.device.begin_figure(iobjid, (0, 0, 1, 1), MATRIX_IDENTITY)
-            self.device.render_image(iobjid, obj)
-            self.device.end_figure(iobjid)
-
     def do_Do(self, xobjid_arg: PDFStackT) -> None:
         """"""Invoke named XObject""""""
         xobjid = literal_name(xobjid_arg)
",add missing missing imports,
78fb0ba32668abb3487491c538c28266c6739c63,converter.py,"@@ -2,6 +2,7 @@ from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
 from pdfminer.pdffont import PDFCIDFont
 from pdfminer.converter import PDFConverter
 from pdfminer.pdffont import PDFUnicodeNotDefined
+from pdfminer.utils import apply_matrix_pt, mult_matrix
 from pdfminer.layout import (
     LTChar,
     LTFigure,
@@ -33,17 +34,31 @@ class PDFConverterEx(PDFConverter):
     def __init__(
         self,
         rsrcmgr: PDFResourceManager,
-        outfp,
-        codec: str = ""utf-8"",
-        pageno: int = 1,
-        laparams=None,
     ) -> None:
-        PDFConverter.__init__(self, rsrcmgr, outfp, codec, pageno, laparams)
+        PDFConverter.__init__(self, rsrcmgr, None, ""utf-8"", 1, None)
+
+    def begin_page(self, page, ctm) -> None:
+        (x0, y0, x1, y1) = page.cropbox
+        (x0, y0) = apply_matrix_pt(ctm, (x0, y0))
+        (x1, y1) = apply_matrix_pt(ctm, (x1, y1))
+        mediabox = (0, 0, abs(x0 - x1), abs(y0 - y1))
+        self.cur_item = LTPage(page.pageno, mediabox)
 
     def end_page(self, page):
-        # self.pageno += 1
         return self.receive_layout(self.cur_item)
 
+    def begin_figure(self, name, bbox, matrix) -> None:
+        self._stack.append(self.cur_item)
+        self.cur_item = LTFigure(name, bbox, mult_matrix(matrix, self.ctm))
+        self.cur_item.pageid = self._stack[-1].pageid
+    
+    def end_figure(self, _: str) -> None:
+        fig = self.cur_item
+        assert isinstance(self.cur_item, LTFigure), str(type(self.cur_item))
+        self.cur_item = self._stack.pop()
+        self.cur_item.add(fig)
+        return self.receive_layout(fig)
+
     def render_char(
         self,
         matrix,
@@ -92,7 +107,7 @@ class TranslateConverter(PDFConverterEx):
         lang_out: str = """",
         service: str = """",
     ) -> None:
-        super().__init__(rsrcmgr, None, ""utf-8"", 1, None)  # hack DEBUG ONLY
+        super().__init__(rsrcmgr)
         self.vfont = vfont
         self.vchar = vchar
         self.thread = thread
@@ -186,7 +201,6 @@ class TranslateConverter(PDFConverterEx):
             if isinstance(child, LTChar):
                 cur_v = False
                 fontname = child.fontname.split(""+"")[-1]
-                ltpage.pageid = 0 # hack DEBUG ONLY
                 layout = self.layout[ltpage.pageid]
                 # ltpage.height 可能是 fig 里面的高度，这里统一用 layout.shape
                 h, w = layout.shape
",add support for multmatrix in pdfminer,
78fb0ba32668abb3487491c538c28266c6739c63,high_level.py,"@@ -6,8 +6,10 @@ import numpy as np
 import tqdm
 from pymupdf import Document
 from pdfminer.pdfpage import PDFPage
-from pdf2zh.converter import TranslateConverter
 from pdfminer.pdfinterp import PDFResourceManager
+from pdfminer.pdfdocument import PDFDocument
+from pdfminer.pdfparser import PDFParser
+from pdf2zh.converter import TranslateConverter
 from pdf2zh.pdfinterp import PDFPageInterpreterEx
 
 
@@ -57,14 +59,19 @@ def extract_text_to_fp(
         total_pages = len(pages)
     else:
         total_pages = page_count
+
+    parser = PDFParser(inf)
+    doc = PDFDocument(parser, password=password)
     with tqdm.tqdm(
-        PDFPage.get_pages(inf, pages, password=password),
+        enumerate(PDFPage.create_pages(doc)),
         total=total_pages,
     ) as progress:
-        for page in progress:
+        for pageno, page in progress:
+            if pages and (not pageno in pages):
+                continue
             if callback:
                 callback(progress)
-            page.pageno = 0  # hack DEBUG ONLY
+            page.pageno = pageno
             pix = doc_en[page.pageno].get_pixmap()
             image = np.fromstring(pix.samples, np.uint8).reshape(
                 pix.height, pix.width, 3
","add support for -57,14+59,19",
78fb0ba32668abb3487491c538c28266c6739c63,pdfinterp.py,"@@ -95,7 +95,7 @@ class PDFPageInterpreterEx(PDFPageInterpreter):
                         objid = spec.objid
                     spec = dict_value(spec)
                     self.fontmap[fontid] = self.rsrcmgr.get_font(objid, spec)
-                    self.fontmap[fontid].descent = 0  # hack fix
+                    self.fontmap[fontid].descent = 0  # hack fix descent
                     self.fontid[self.fontmap[fontid]] = fontid
             elif k == ""ColorSpace"":
                 for csid, spec in dict_value(v).items():
",fix descent in fontinterpreter,
3f8e4e03c7bed85548d7b5d1e60fd4e7b6b96eae,docker-publish.yml,"@@ -64,6 +64,7 @@ jobs:
         id: build-and-push
         uses: docker/build-push-action@v6
         with:
+          platforms: linux/amd64,linux/arm64
           context: .
           push: true
           tags: ${{ steps.meta.outputs.tags }}
",add missing tag to build-and-push,
5aa5bf1b7f868a14f4e068a1b49932adf7782c67,converter.py,"@@ -374,7 +374,7 @@ class TranslateConverter(PDFConverterEx):
                         adv = vlen[vid]
                     except Exception:
                         continue  # 翻译器可能会自动补个越界的公式标记
-                    if len(var[vid]) == 1 and unicodedata.category(var[vid][0].get_text()[0]) in [""Lm"", ""Mn"", ""Sk""]:  # 文字修饰符
+                    if len(var[vid]) == 1 and var[vid][0].get_text() and unicodedata.category(var[vid][0].get_text()[0]) in [""Lm"", ""Mn"", ""Sk""]:  # 文字修饰符
                         mod = True
                 else:  # 加载文字
                     ch = new[ptr]
",add support for 不公式标记,
23c1041db47a1411621cf71c518a8e7b37452781,converter.py,"@@ -178,7 +178,7 @@ class TranslateConverter(PDFConverterEx):
                     return True
             else:
                 if re.match(                                            # latex 字体
-                    r""(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|.*Mono|.*Code|.*Ital|.*Sym)"",
+                    r""(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
                     font,
                 ):
                     return True
@@ -366,7 +366,7 @@ class TranslateConverter(PDFConverterEx):
                 vy_regex = re.match(
                     r""\$?\s*v([\d\s]+)\$"", new[ptr:], re.IGNORECASE
                 )  # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
-                mod = False  # 当前公式是否为文字修饰符
+                mod = 0  # 文字修饰符
                 if vy_regex:  # 加载公式
                     ptr += len(vy_regex.group(0))
                     try:
@@ -374,8 +374,8 @@ class TranslateConverter(PDFConverterEx):
                         adv = vlen[vid]
                     except Exception:
                         continue  # 翻译器可能会自动补个越界的公式标记
-                    if len(var[vid]) == 1 and var[vid][0].get_text() and unicodedata.category(var[vid][0].get_text()[0]) in [""Lm"", ""Mn"", ""Sk""]:  # 文字修饰符
-                        mod = True
+                    if var[vid][-1].get_text() and unicodedata.category(var[vid][-1].get_text()[0]) in [""Lm"", ""Mn"", ""Sk""]:  # 文字修饰符
+                        mod = var[vid][-1].width
                 else:  # 加载文字
                     ch = new[ptr]
                     fcur_ = None
@@ -429,8 +429,7 @@ class TranslateConverter(PDFConverterEx):
                             cstk += ch
                     else:
                         cstk += ch
-                if mod:  # 文字修饰符
-                    adv = 0
+                adv -= mod # 文字修饰符
                 fcur = fcur_
                 x += adv
                 if log.isEnabledFor(logging.DEBUG):
","add support for -366,7,7,8,9,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,15,14,15,16,15,16,17,15,16,17,15,16,17,15,",
1f10284f07cb4ac40d3f319aa2d6ba947607a96d,converter.py,"@@ -178,7 +178,7 @@ class TranslateConverter(PDFConverterEx):
                     return True
             else:
                 if re.match(                                            # latex 字体
-                    r""(CM[^R]|MS|XY|MT|BL|RM|EU|LA|RS|LINE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
+                    r""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
                     font,
                 ):
                     return True
",add missing regex,
9d4474b85359c1d841fd4656f015475e35b33a51,gui.py,"@@ -41,7 +41,7 @@ flag_demo = False
 if os.environ.get(""PDF2ZH_DEMO""):
     flag_demo = True
     service_map = {
-        ""Google"": ""google"",
+        ""Google"": (""google"", None, None),
     }
     page_map = {
         ""First"": [0],
@@ -115,12 +115,12 @@ def translate(
     file_dual = output / f""{filename}-dual.pdf""
     shutil.copyfile(file_path, file_en)
 
-    selected_service = service_map.get(service, ""google"")[0]
+    selected_service = service_map[service][0]
     if service_map[service][1]:
         os.environ.setdefault(service_map[service][1], apikey)
-    selected_page = page_map.get(page_range, [0])
-    lang_from = lang_map.get(lang_from, ""en"")
-    lang_to = lang_map.get(lang_to, ""zh"")
+    selected_page = page_map[page_range]
+    lang_from = lang_map[lang_from]
+    lang_to = lang_map[lang_to]
     if selected_service == ""google"":
         lang_from = ""zh-CN"" if lang_from == ""zh"" else lang_from
         lang_to = ""zh-CN"" if lang_to == ""zh"" else lang_to
","add support for -n,n,d,e,t,d,e-t,e-t,e-t",
b7832ae08c652119ceff074b78567eeeeab8f00c,gui.py,"@@ -91,7 +91,7 @@ def upload_file(file, service, progress=gr.Progress()):
 def download_with_limit(url, save_path, size_limit):
     chunk_size = 1024
     total_size = 0
-    with requests.get(url, stream=True) as response:
+    with requests.get(url, stream=True, timeout=10) as response:
         response.raise_for_status()
         content = response.headers.get(""Content-Disposition"")
         try:
",add download_with_limit,
2604748fb70bfc20e6f43b9d9bab337e554b0f5e,converter.py,"@@ -170,7 +170,7 @@ class TranslateConverter(PDFConverterEx):
         # 全局
         lstk: list[LTLine] = []         # 全局线条栈
         xt: LTChar = None               # 上一个字符
-        xt_cls: int = -1                # 上一个字符所属段落
+        xt_cls: int = -1                # 上一个字符所属段落，保证无论第一个字符属于哪个类别都可以触发新段落
         vmax: float = ltpage.width / 4  # 行内公式最大宽度
         ops: str = """"                   # 渲染结果
 
@@ -216,6 +216,10 @@ class TranslateConverter(PDFConverterEx):
                 # 读取当前字符在 layout 中的类别
                 cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(int(child.y0), 0, h - 1)
                 cls = layout[cy, cx]
+                # 锚定文档中 bullet 的位置
+                if child.get_text() == ""•"":
+                    cls = 0
+                # 判定当前字符是否属于公式
                 if (                                                                                        # 判定当前字符是否属于公式
                     cls == 0                                                                                # 1. 类别为保留区域
                     or (cls == xt_cls and len(sstk[-1].strip()) > 1 and child.size < pstk[-1].size * 0.79)  # 2. 角标字体，有 0.76 的角标和 0.799 的大写，这里用 0.79 取中，同时考虑首字母放大的情况
",add support for bulleting in translate converter,
f631a5014df569de7ce599a0a3e90ba4c04461f6,converter.py,"@@ -19,6 +19,7 @@ from pdf2zh import cache
 from pdf2zh.translator import (
     BaseTranslator,
     GoogleTranslator,
+    BingTranslator,
     DeepLTranslator,
     DeepLXTranslator,
     OllamaTranslator,
@@ -138,7 +139,7 @@ class TranslateConverter(PDFConverterEx):
         param = service.split("":"", 1)
         service_name = param[0]
         service_model = param[1] if len(param) > 1 else None
-        for translator in [GoogleTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, OpenAITranslator, AzureTranslator, TencentTranslator]:
+        for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, OpenAITranslator, AzureTranslator, TencentTranslator]:
             if service_name == translator.name:
                 self.translator = translator(service, lang_out, lang_in, service_model)
         if not self.translator:
@@ -320,6 +321,8 @@ class TranslateConverter(PDFConverterEx):
 
         @retry(wait=wait_fixed(1))
         def worker(s: str):  # 多线程翻译
+            if re.match(r""^\$v\d+\$$"", s):  # 公式不翻译
+                return s
             try:
                 hash_key_paragraph = cache.deterministic_hash(
                     (s, str(self.translator))
",add support for old translations,
f631a5014df569de7ce599a0a3e90ba4c04461f6,gui.py,"@@ -6,6 +6,7 @@ from pdf2zh.pdf2zh import extract_text
 from pdf2zh.translator import (
     BaseTranslator,
     GoogleTranslator,
+    BingTranslator,
     DeepLTranslator,
     DeepLXTranslator,
     OllamaTranslator,
@@ -25,6 +26,7 @@ import cgi
 # five value, padding with None
 service_map: dict[str, BaseTranslator] = {
     ""Google"": GoogleTranslator,
+    ""Bing"": BingTranslator,
     ""DeepL"": DeepLTranslator,
     ""DeepLX"": DeepLXTranslator,
     ""Ollama"": OllamaTranslator,
",add missing imports,
f631a5014df569de7ce599a0a3e90ba4c04461f6,translator.py,"@@ -85,33 +85,31 @@ class BingTranslator(BaseTranslator):
     name = ""bing""
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
+        lang_out = ""zh-Hans"" if lang_out == ""auto"" else lang_out
         lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         self.session = requests.Session()
-        self.endpoint = ""https://www.bing.com/ttranslatev3?isVertical=1""
+        self.endpoint = ""https://www.bing.com/ttranslatev3""
+        self.headers = {
+            ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"",  # noqa: E501
+        }
 
     def fineSID(self):
         resp = self.session.get(""https://www.bing.com/translator"")
-        result = re.findall(
+        ig = re.findall(r""\""ig\"":\""(.*?)\"""", resp.text)[0]
+        iid = re.findall(r""data-iid=\""(.*?)\"""", resp.text)[-1]
+        key, token = re.findall(
             r""params_AbusePreventionHelper\s=\s\[(.*?),\""(.*?)\"","", resp.text
         )[0]
-        return result
+        return ig, iid, key, token
 
     def translate(self, text):
-        sid = self.fineSID()
+        ig, iid, key, token = self.fineSID()
         resp = self.session.post(
-            self.endpoint,
-            data={
-                ""fromLang"": self.lang_in,
-                ""text"": text,
-                ""to"": self.lang_out,
-                ""tryFetchingGenderDebiasedTranslations"": True,
-                ""token"": sid[1],
-                ""key"": sid[0],
-            },
+            f""{self.endpoint}?IG={ig}&IID={iid}"",
+            data={""fromLang"": self.lang_in, ""to"": self.lang_out, ""text"": text, ""token"": token, ""key"": key},
+            headers=self.headers,
         )
-        print(resp.json())
         return resp.json()[0][""translations""][0][""text""]
 
 
",add support for bing 2.0.0,
6981951ef5eebadd02a6e49527e07e03ee9a0d00,converter.py,"@@ -414,8 +414,8 @@ class TranslateConverter(PDFConverterEx):
                         cstk = """"
                 if brk and x + adv > x1 + 0.1 * size:  # 到达右边界且原文段落存在换行
                     x = x0
-                    lang_space = {""zh-CN"": 1.4, ""zh-TW"": 1.4, ""ja"": 1.1, ""ko"": 1.2, ""en"": 1.2, ""ar"": 1.0, ""ru"": 0.8, ""uk"": 0.8, ""ta"": 0.8}
-                    y -= size * lang_space.get(self.translator.lang_out, 1.1)  # 小语种大多适配 1.1
+                    lang_space = {""zh-cn"": 1.4, ""zh-tw"": 1.4, ""zh-hans"": 1.4, ""zh-hant"": 1.4, ""zh"": 1.4, ""ja"": 1.1, ""ko"": 1.2, ""en"": 1.2, ""ar"": 1.0, ""ru"": 0.8, ""uk"": 0.8, ""ta"": 0.8}
+                    y -= size * lang_space.get(self.translator.lang_out.lower(), 1.1)  # 小语种大多适配 1.1
                 if vy_regex:  # 插入公式
                     fix = 0
                     if fcur is not None:  # 段落内公式修正纵向偏移
",add fix for translate,
6981951ef5eebadd02a6e49527e07e03ee9a0d00,pdf2zh.py,"@@ -27,8 +27,11 @@ logging.basicConfig()
 model = DocLayoutModel.load_available()
 
 resfont_map = {
-    ""zh-CN"": ""china-ss"",
-    ""zh-TW"": ""china-ts"",
+    ""zh-cn"": ""china-ss"",
+    ""zh-tw"": ""china-ts"",
+    ""zh-hans"": ""china-ss"",
+    ""zh-hant"": ""china-ts"",
+    ""zh"": ""china-ss"",
     ""ja"": ""japan-s"",
     ""ko"": ""korea-s"",
 }
@@ -49,11 +52,11 @@ noto_list = [
     ""mr"",  # Marathi
     ""ru"",  # Russian
     ""sr"",  # Serbian
-    # ""zh-CN"",# Chinese (PRC)
+    # ""zh-cn"",# SC
     ""ta"",  # Tamil
     ""te"",  # Telugu
     ""th"",  # Thai
-    # ""zh-TW"",# Chinese (Taiwan)
+    # ""zh-tw"",# TC
     ""ur"",  # Urdu
     ""uk"",  # Ukrainian
 ]
@@ -114,10 +117,10 @@ def extract_text(
 
         font_list = [(""tiro"", None)]
         noto = None
-        if lang_out in resfont_map:  # CJK
-            resfont = resfont_map[lang_out]
+        if lang_out.lower() in resfont_map:  # CJK
+            resfont = resfont_map[lang_out.lower()]
             font_list.append((resfont, None))
-        elif lang_out in noto_list:  # noto
+        elif lang_out.lower() in noto_list:  # noto
             resfont = ""noto""
             ttf_path = os.path.join(tempfile.gettempdir(), ""GoNotoKurrent-Regular.ttf"")
             if not os.path.exists(ttf_path):
@@ -128,7 +131,7 @@ def extract_text(
                 )
             font_list.append((""noto"", ttf_path))
             noto = pymupdf.Font(""noto"", ttf_path)
-        else:  # auto
+        else:  # fallback
             resfont = ""china-ss""
             font_list.append((""china-ss"", None))
 
@@ -240,14 +243,14 @@ def create_parser() -> argparse.ArgumentParser:
         ""--lang-in"",
         ""-li"",
         type=str,
-        default=""auto"",
+        default=""en"",
         help=""The code of source language."",
     )
     parse_params.add_argument(
         ""--lang-out"",
         ""-lo"",
         type=str,
-        default=""auto"",
+        default=""zh"",
         help=""The code of target language."",
     )
     parse_params.add_argument(
",add more examples to gonotokurrent,
6981951ef5eebadd02a6e49527e07e03ee9a0d00,translator.py,"@@ -25,11 +25,9 @@ class BaseTranslator:
     envs = {}
     lang_map = {}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
-        lang_out = self.lang_map.get(lang_out, lang_out)
-        lang_in = self.lang_map.get(lang_in, lang_in)
+    def __init__(self, service, lang_out: str, lang_in: str, model):
+        lang_out = self.lang_map.get(lang_out.lower(), lang_out)
+        lang_in = self.lang_map.get(lang_in.lower(), lang_in)
         self.service = service
         self.lang_out = lang_out
         self.lang_in = lang_in
@@ -59,8 +57,6 @@ class GoogleTranslator(BaseTranslator):
     lang_map = {""zh"": ""zh-CN""}
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh-CN"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         self.session = requests.Session()
         self.endpoint = ""http://translate.google.com/m""
@@ -92,8 +88,6 @@ class BingTranslator(BaseTranslator):
     lang_map = {""zh"": ""zh-Hans""}
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh-Hans"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         self.session = requests.Session()
         self.endpoint = ""https://www.bing.com/ttranslatev3""
@@ -136,8 +130,6 @@ class TencentTranslator(BaseTranslator):
     }
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         cred = credential.DefaultCredentialProvider().get_credential()
         self.client = TmtClient(cred, ""ap-beijing"")
@@ -162,8 +154,6 @@ class DeepLTranslator(BaseTranslator):
     lang_map = {""zh"": ""zh-Hans""}
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         self.session = requests.Session()
         server_url = os.getenv(""DEEPL_SERVER_URL"")
@@ -186,8 +176,6 @@ class DeepLXTranslator(BaseTranslator):
     lang_map = {""zh"": ""zh-Hans""}
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         self.endpoint = os.getenv(""DEEPLX_ENDPOINT"")
         self.session = requests.Session()
@@ -213,8 +201,6 @@ class OllamaTranslator(BaseTranslator):
     }
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh-CN"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         if not model:
             model = os.getenv(""OLLAMA_MODEL"", self.envs[""OLLAMA_MODEL""])
         super().__init__(service, lang_out, lang_in, model)
@@ -240,8 +226,6 @@ class OpenAITranslator(BaseTranslator):
     }
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh-CN"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         if not model:
             model = os.getenv(""OPENAI_MODEL"", self.envs[""OPENAI_MODEL""])
         super().__init__(service, lang_out, lang_in, model)
@@ -267,8 +251,6 @@ class AzureTranslator(BaseTranslator):
     lang_map = {""zh"": ""zh-Hans""}
 
     def __init__(self, service, lang_out, lang_in, model):
-        lang_out = ""zh-Hans"" if lang_out == ""auto"" else lang_out
-        lang_in = ""en"" if lang_in == ""auto"" else lang_in
         super().__init__(service, lang_out, lang_in, model)
         endpoint = os.environ[""AZURE_ENDPOINT""]
         api_key = os.environ[""AZURE_APIKEY""]
",add docs for google and bing translator,
8245904afdd81d2a1d50a82d8031f31aca75b3f4,gui.py,"@@ -154,7 +154,7 @@ def translate(
     lang_to = lang_map[lang_to]
 
     for i, env in enumerate(translator.envs.items()):
-        os.putenv(env[0], envs[i])
+        os.environ[env[0]]=envs[i]
 
     print(f""Files before translation: {os.listdir(output)}"")
 
",update output dir,
c886982bcc077b9dffcf4bd317d122a91c459765,setup.bat,"@@ -5,13 +5,13 @@ set PYTHON_URL=https://www.python.org/ftp/python/3.12.7/python-3.12.7-embed-amd6
 set PIP_URL=https://bootstrap.pypa.io/get-pip.py
 set HF_ENDPOINT=https://hf-mirror.com
 
-if not exist pdf2zh/python.exe (
+if not exist pdf2zh_dist/python.exe (
     powershell -Command ""& {Invoke-WebRequest -Uri !PYTHON_URL! -OutFile python.zip}""
-    powershell -Command ""& {Expand-Archive -Path python.zip -DestinationPath pdf2zh -Force}""
+    powershell -Command ""& {Expand-Archive -Path python.zip -DestinationPath pdf2zh_dist -Force}""
     del python.zip
-    echo import site >> pdf2zh/python312._pth
+    echo import site >> pdf2zh_dist/python312._pth
 )
-cd pdf2zh
+cd pdf2zh_dist
 
 if not exist Scripts/pip.exe (
     powershell -Command ""& {Invoke-WebRequest -Uri !PIP_URL! -OutFile get-pip.py}""
",add missing script,
8bc01370494d243cde501ea1f2865cf582538ac0,converter.py,"@@ -178,7 +178,7 @@ class TranslateConverter(PDFConverterEx):
                     return True
             else:
                 if re.match(                                            # latex 字体
-                    r""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
+                    r""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
                     font,
                 ):
                     return True
",add check for licence in translate converter,
e9386aa667ba0737352429dfe054de18e69ebebb,converter.py,"@@ -231,7 +231,11 @@ class TranslateConverter(PDFConverterEx):
                 if (                                                        # 判定当前公式是否结束
                     not cur_v                                               # 1. 当前字符不属于公式
                     or cls != xt_cls                                        # 2. 当前字符与前一个字符不属于同一段落
-                    or (abs(child.x0 - xt.x0) > vmax and cls != 0)          # 3. 段落内换行，可能是一长串斜体的段落，也可能是段内分式换行，这里设个阈值进行区分
+                    # or (abs(child.x0 - xt.x0) > vmax and cls != 0)        # 3. 段落内换行，可能是一长串斜体的段落，也可能是段内分式换行，这里设个阈值进行区分
+                    # 禁止纯公式（代码）段落换行，直到文字开始再重开文字段落，保证只存在两种情况
+                    # A. 纯公式（代码）段落（锚定绝对位置）sstk[-1]=="""" -> sstk[-1]==""$v*$""
+                    # B. 文字开头段落（排版相对位置）sstk[-1]!=""""
+                    or (sstk[-1] != """" and abs(child.x0 - xt.x0) > vmax)    # 因为 cls==xt_cls==0 一定有 sstk[-1]==""""，所以这里不需要再判定 cls!=0
                 ):
                     if vstk:
                         if (                                                # 根据公式右侧的文字修正公式的纵向偏移
@@ -240,6 +244,8 @@ class TranslateConverter(PDFConverterEx):
                             and child.x0 > max([vch.x0 for vch in vstk])    # 3. 当前字符在公式右侧
                         ):
                             vfix = vstk[0].y0 - child.y0
+                        if sstk[-1] == """":
+                            xt_cls = -1 # 禁止纯公式段落（sstk[-1]==""$v*$""）的后续连接，但是要考虑新字符和后续字符的连接，所以这里修改的是上个字符的类别
                         sstk[-1] += f""$v{len(var)}$""
                         var.append(vstk)
                         varl.append(vlstk)
@@ -263,7 +269,7 @@ class TranslateConverter(PDFConverterEx):
                         child.size > pstk[-1].size / 0.79                   # 1. 当前字符显著比段落字体大
                         or len(sstk[-1].strip()) == 1                       # 2. 当前字符为段落第二个文字（考虑首字母放大的情况）
                     ):
-                        pstk[-1].y -= child.size - pstk[-1].size             # hack 这个段落纵向位置的修正有问题，不过先凑合用吧
+                        pstk[-1].y -= child.size - pstk[-1].size            # 修正段落初始纵坐标，假设两个不同大小字符的上边界对齐
                         pstk[-1].size = child.size
                     sstk[-1] += child.get_text()
                 else:                                                       # 公式入栈
",add support for 公式是否公式是否公式是否公式是否公式是否公式是否公式是否公式是吧�,
efe48bfa40e6837545fe85e73661d3b9b618fb97,high_level.py,"@@ -48,13 +48,11 @@ def extract_text_to_fp(
 
     parser = PDFParser(inf)
     doc = PDFDocument(parser, password=password)
-    with tqdm.tqdm(
-        enumerate(PDFPage.create_pages(doc)),
-        total=total_pages,
-    ) as progress:
-        for pageno, page in progress:
+    with tqdm.tqdm(total=total_pages) as progress:
+        for pageno, page in enumerate(PDFPage.create_pages(doc)):
             if pages and (pageno not in pages):
                 continue
+            progress.update()
             if callback:
                 callback(progress)
             page.pageno = pageno
",add progress bar for extract_text_to_fp,
d6f96334b1fb16d5d20f475d24fd521974edd0ea,converter.py,"@@ -144,7 +144,7 @@ class TranslateConverter(PDFConverterEx):
         for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, AzureOpenAITranslator,
                            OpenAITranslator, ZhipuTranslator, SiliconTranslator, AzureTranslator, TencentTranslator]:
             if service_name == translator.name:
-                self.translator = translator(service, lang_out, lang_in, service_model)
+                self.translator = translator(lang_out, lang_in, service_model)
         if not self.translator:
             raise ValueError(""Unsupported translation service"")
 
",fix translator name,
d6f96334b1fb16d5d20f475d24fd521974edd0ea,pdf2zh.py,"@@ -142,6 +142,7 @@ def main(args: Optional[List[str]] = None) -> int:
 
     if parsed_args.interactive:
         from pdf2zh.gui import setup_gui
+
         setup_gui(parsed_args.share)
         return 0
 
",add example for --interactive,
d6f96334b1fb16d5d20f475d24fd521974edd0ea,translator.py,"@@ -25,10 +25,9 @@ class BaseTranslator:
     envs = {}
     lang_map = {}
 
-    def __init__(self, service, lang_out: str, lang_in: str, model):
+    def __init__(self, lang_out: str, lang_in: str, model):
         lang_out = self.lang_map.get(lang_out.lower(), lang_out)
         lang_in = self.lang_map.get(lang_in.lower(), lang_in)
-        self.service = service
         self.lang_out = lang_out
         self.lang_in = lang_in
         self.model = model
@@ -49,15 +48,15 @@ class BaseTranslator:
         ]
 
     def __str__(self):
-        return f""{self.service} {self.lang_out} {self.lang_in}""
+        return f""{self.name} {self.lang_out} {self.lang_in} {self.model}""
 
 
 class GoogleTranslator(BaseTranslator):
     name = ""google""
     lang_map = {""zh"": ""zh-CN""}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         self.session = requests.Session()
         self.endpoint = ""http://translate.google.com/m""
         self.headers = {
@@ -87,8 +86,8 @@ class BingTranslator(BaseTranslator):
     name = ""bing""
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         self.session = requests.Session()
         self.endpoint = ""https://www.bing.com/ttranslatev3""
         self.headers = {
@@ -130,8 +129,8 @@ class DeepLTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         self.session = requests.Session()
         server_url = os.getenv(""DEEPL_SERVER_URL"", self.envs[""DEEPL_SERVER_URL""])
         auth_key = os.getenv(""DEEPL_AUTH_KEY"")
@@ -152,8 +151,8 @@ class DeepLXTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         self.endpoint = os.getenv(""DEEPLX_ENDPOINT"", self.envs[""DEEPLX_ENDPOINT""])
         self.session = requests.Session()
 
@@ -177,10 +176,10 @@ class OllamaTranslator(BaseTranslator):
         ""OLLAMA_MODEL"": ""gemma2"",
     }
 
-    def __init__(self, service, lang_out, lang_in, model):
+    def __init__(self, lang_out, lang_in, model):
         if not model:
             model = os.getenv(""OLLAMA_MODEL"", self.envs[""OLLAMA_MODEL""])
-        super().__init__(service, lang_out, lang_in, model)
+        super().__init__(lang_out, lang_in, model)
         self.options = {""temperature"": 0}  # 随机采样可能会打断公式标记
         self.client = ollama.Client()
 
@@ -202,10 +201,10 @@ class OpenAITranslator(BaseTranslator):
         ""OPENAI_MODEL"": ""gpt-4o-mini"",
     }
 
-    def __init__(self, service, lang_out, lang_in, model, base_url=None, api_key=None):
+    def __init__(self, lang_out, lang_in, model, base_url=None, api_key=None):
         if not model:
             model = os.getenv(""OPENAI_MODEL"", self.envs[""OPENAI_MODEL""])
-        super().__init__(service, lang_out, lang_in, model)
+        super().__init__(lang_out, lang_in, model)
         self.options = {""temperature"": 0}  # 随机采样可能会打断公式标记
         self.client = openai.OpenAI(base_url=base_url, api_key=api_key)
 
@@ -226,14 +225,14 @@ class AzureOpenAITranslator(BaseTranslator):
         ""AZURE_OPENAI_MODEL"": ""gpt-4o-mini"",
     }
 
-    def __init__(self, service, lang_out, lang_in, model, base_url=None, api_key=None):
+    def __init__(self, lang_out, lang_in, model, base_url=None, api_key=None):
         base_url = os.getenv(
             ""AZURE_OPENAI_BASE_URL"", self.envs[""AZURE_OPENAI_BASE_URL""]
         )
         api_version = os.getenv(""AZURE_OPENAI_API_VERSION"", ""2024-06-01"")
         if not model:
             model = os.getenv(""AZURE_OPENAI_MODEL"", self.envs[""AZURE_OPENAI_MODEL""])
-        super().__init__(service, lang_out, lang_in, model)
+        super().__init__(lang_out, lang_in, model)
         self.options = {""temperature"": 0}
         self.client = openai.AzureOpenAI(
             azure_endpoint=base_url,
@@ -259,14 +258,12 @@ class ZhipuTranslator(OpenAITranslator):
         ""ZHIPU_MODEL"": ""glm-4-flash"",
     }
 
-    def __init__(self, service, lang_out, lang_in, model):
+    def __init__(self, lang_out, lang_in, model):
         base_url = ""https://open.bigmodel.cn/api/paas/v4""
         api_key = os.getenv(""ZHIPU_API_KEY"")
         if not model:
             model = os.getenv(""ZHIPU_MODEL"", self.envs[""ZHIPU_MODEL""])
-        super().__init__(
-            service, lang_out, lang_in, model, base_url=base_url, api_key=api_key
-        )
+        super().__init__(lang_out, lang_in, model, base_url=base_url, api_key=api_key)
 
 
 class SiliconTranslator(OpenAITranslator):
@@ -277,14 +274,12 @@ class SiliconTranslator(OpenAITranslator):
         ""SILICON_MODEL"": ""Qwen/Qwen2.5-7B-Instruct"",
     }
 
-    def __init__(self, service, lang_out, lang_in, model):
+    def __init__(self, lang_out, lang_in, model):
         base_url = ""https://api.siliconflow.cn/v1""
         api_key = os.getenv(""SILICON_API_KEY"")
         if not model:
             model = os.getenv(""SILICON_MODEL"", self.envs[""SILICON_MODEL""])
-        super().__init__(
-            service, lang_out, lang_in, model, base_url=base_url, api_key=api_key
-        )
+        super().__init__(lang_out, lang_in, model, base_url=base_url, api_key=api_key)
 
 
 class AzureTranslator(BaseTranslator):
@@ -296,8 +291,8 @@ class AzureTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         endpoint = os.getenv(""AZURE_ENDPOINT"", self.envs[""AZURE_ENDPOINT""])
         api_key = os.getenv(""AZURE_API_KEY"")
         credential = AzureKeyCredential(api_key)
@@ -326,8 +321,8 @@ class TencentTranslator(BaseTranslator):
         ""TENCENTCLOUD_SECRET_KEY"": None,
     }
 
-    def __init__(self, service, lang_out, lang_in, model):
-        super().__init__(service, lang_out, lang_in, model)
+    def __init__(self, lang_out, lang_in, model):
+        super().__init__(lang_out, lang_in, model)
         cred = credential.DefaultCredentialProvider().get_credential()
         self.client = TmtClient(cred, ""ap-beijing"")
         self.req = TextTranslateRequest()
",add missing docstrings,
9cb812e29cf10aff36d9820b6d52ea9260437470,gui.py,"@@ -164,7 +164,7 @@ def translate_file(
         progress(t.n / t.total, desc=""Translating..."")
 
     param = {
-        ""files"": [file_raw],
+        ""files"": [str(file_raw)],
         ""pages"": selected_page,
         ""lang_in"": lang_from,
         ""lang_out"": lang_to,
",add missing param to translate_file,
afe7c53eaf75ac9f096cf9408142d7e754a7594e,gui.py,"@@ -20,8 +20,6 @@ from pdf2zh.translator import (
 
 import gradio as gr
 from gradio_pdf import PDF
-import numpy as np
-import pymupdf
 import tqdm
 import requests
 import cgi
@@ -79,19 +77,6 @@ def verify_recaptcha(response):
     return result.get(""success"")
 
 
-def pdf_preview(file):
-    doc = pymupdf.open(file)
-    page = doc[0]
-    pix = page.get_pixmap()
-    image = np.frombuffer(pix.samples, np.uint8).reshape(pix.height, pix.width, 3)
-    return image
-
-
-def upload_file(file, service, progress=gr.Progress()):
-    preview_image = pdf_preview(file)
-    return file, file
-
-
 def download_with_limit(url, save_path, size_limit):
     chunk_size = 1024
     total_size = 0
@@ -181,11 +166,6 @@ def translate_file(
     if not file_mono.exists() or not file_dual.exists():
         raise gr.Error(""No output"")
 
-    try:
-        translated_preview = pdf_preview(str(file_mono))
-    except Exception:
-        raise gr.Error(""No preview"")
-
     progress(1.0, desc=""Translation complete!"")
 
     return (
@@ -335,7 +315,9 @@ with gr.Blocks(
                 )
 
             output_title = gr.Markdown(""## Translated"", visible=False)
-            output_file = gr.File(label=""Download Translation"", visible=False)
+            output_file_mono = gr.File(
+                label=""Download Translation (Mono)"", visible=False
+            )
             output_file_dual = gr.File(
                 label=""Download Translation (Dual)"", visible=False
             )
@@ -385,9 +367,9 @@ with gr.Blocks(
 
     # Event handlers
     file_input.upload(
-        upload_file,
-        inputs=[file_input, service],
-        outputs=[file_input, preview],
+        lambda x: x,
+        inputs=file_input,
+        outputs=preview,
         js=(
             f""""""
             (a,b)=>{{
@@ -419,10 +401,10 @@ with gr.Blocks(
             *envs,
         ],
         outputs=[
-            output_file,
+            output_file_mono,
             preview,
             output_file_dual,
-            output_file,
+            output_file_mono,
             output_file_dual,
             output_title,
         ],
","add example for the -335, 7 +367, 9 translations",
afe7c53eaf75ac9f096cf9408142d7e754a7594e,pyproject.toml,"@@ -27,6 +27,7 @@ dependencies = [
     ""opencv-python-headless"",
     ""tencentcloud-sdk-python"",
     ""pdfminer.six>=20240706"",
+    ""gradio_pdf"",
 ]
 
 [project.optional-dependencies]
",add missing dependency,
b63ff573fcec4be3c9f0fc678942b2868eebec63,converter.py,"@@ -235,7 +235,7 @@ class TranslateConverter(PDFConverterEx):
                     or cls != xt_cls                                        # 2. 当前字符与前一个字符不属于同一段落
                     # or (abs(child.x0 - xt.x0) > vmax and cls != 0)        # 3. 段落内换行，可能是一长串斜体的段落，也可能是段内分式换行，这里设个阈值进行区分
                     # 禁止纯公式（代码）段落换行，直到文字开始再重开文字段落，保证只存在两种情况
-                    # A. 纯公式（代码）段落（锚定绝对位置）sstk[-1]=="""" -> sstk[-1]==""$v*$""
+                    # A. 纯公式（代码）段落（锚定绝对位置）sstk[-1]=="""" -> sstk[-1]==""{v*}""
                     # B. 文字开头段落（排版相对位置）sstk[-1]!=""""
                     or (sstk[-1] != """" and abs(child.x0 - xt.x0) > vmax)    # 因为 cls==xt_cls==0 一定有 sstk[-1]==""""，所以这里不需要再判定 cls!=0
                 ):
@@ -247,8 +247,8 @@ class TranslateConverter(PDFConverterEx):
                         ):
                             vfix = vstk[0].y0 - child.y0
                         if sstk[-1] == """":
-                            xt_cls = -1 # 禁止纯公式段落（sstk[-1]==""$v*$""）的后续连接，但是要考虑新字符和后续字符的连接，所以这里修改的是上个字符的类别
-                        sstk[-1] += f""$v{len(var)}$""
+                            xt_cls = -1 # 禁止纯公式段落（sstk[-1]==""{v*}""）的后续连接，但是要考虑新字符和后续字符的连接，所以这里修改的是上个字符的类别
+                        sstk[-1] += f""{{v{len(var)}}}""
                         var.append(vstk)
                         varl.append(vlstk)
                         varf.append(vfix)
@@ -305,14 +305,14 @@ class TranslateConverter(PDFConverterEx):
                 pass
         # 处理结尾
         if vstk:    # 公式出栈
-            sstk[-1] += f""$v{len(var)}$""
+            sstk[-1] += f""{{v{len(var)}}}""
             var.append(vstk)
             varl.append(vlstk)
             varf.append(vfix)
         log.debug(""\n==========[VSTACK]==========\n"")
         for id, v in enumerate(var):  # 计算公式宽度
             l = max([vch.x1 for vch in v]) - v[0].x0
-            log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > $v{id}$ = {"""".join([ch.get_text() for ch in v])}')
+            log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > v{id} = {"""".join([ch.get_text() for ch in v])}')
             vlen.append(l)
 
         ############################################################
@@ -323,7 +323,7 @@ class TranslateConverter(PDFConverterEx):
 
         @retry(wait=wait_fixed(1))
         def worker(s: str):  # 多线程翻译
-            if not s.strip() or re.match(r""^\$v\d+\$$"", s):  # 空白和公式不翻译
+            if not s.strip() or re.match(r""^\{v\d+\}$"", s):  # 空白和公式不翻译
                 return s
             try:
                 hash_key_paragraph = cache.deterministic_hash(
@@ -371,8 +371,8 @@ class TranslateConverter(PDFConverterEx):
             log.debug(f""< {y} {x} {x0} {x1} {size} {brk} > {sstk[id]} | {new}"")
             while ptr < len(new):
                 vy_regex = re.match(
-                    r""\$?\s*v([\d\s]+)\$"", new[ptr:], re.IGNORECASE
-                )  # 匹配 $vn$ 公式标记，前面的 $ 有的时候会被丢掉
+                    r""\{\s*v([\d\s]+)\}"", new[ptr:], re.IGNORECASE
+                )  # 匹配 {vn} 公式标记
                 mod = 0  # 文字修饰符
                 if vy_regex:  # 加载公式
                     ptr += len(vy_regex.group(0))
",add support for 两种情况,
b63ff573fcec4be3c9f0fc678942b2868eebec63,translator.py,"@@ -43,7 +43,7 @@ class BaseTranslator:
             },
             {
                 ""role"": ""user"",
-                ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation $v*$ unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",  # noqa: E501
+                ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",  # noqa: E501
             },
         ]
 
",add missing role tag in basetranslator,
c6c0b4fa8ff780c4d197f5feb9fc7e71e0a58218,README.md,"@@ -241,7 +241,7 @@ pdf2zh example.pdf -t 1
 from pdf2zh import translate, translate_stream
 
 params = {""lang_in"": ""en"", ""lang_out"": ""zh"", ""service"": ""google"", ""thread"": 4}
-doc_mono, doc_dual = translate(files=[""example.pdf""], **params)
+file_mono, file_dual = translate(files=[""example.pdf""], **params)[0]
 with open(""example.pdf"", ""rb"") as f:
     stream_mono, stream_dual = translate_stream(stream=f.read(), **params)
 ```
",update example.py,
c6c0b4fa8ff780c4d197f5feb9fc7e71e0a58218,README_zh-CN.md,"@@ -241,7 +241,7 @@ pdf2zh example.pdf -t 1
 from pdf2zh import translate, translate_stream
 
 params = {""lang_in"": ""en"", ""lang_out"": ""zh"", ""service"": ""google"", ""thread"": 4}
-doc_mono, doc_dual = translate(files=[""example.pdf""], **params)
+file_mono, file_dual = translate(files=[""example.pdf""], **params)[0]
 with open(""example.pdf"", ""rb"") as f:
     stream_mono, stream_dual = translate_stream(stream=f.read(), **params)
 ```
",update example.py,
c6c0b4fa8ff780c4d197f5feb9fc7e71e0a58218,high_level.py,"@@ -250,6 +250,8 @@ def translate(
             print(f""  {file}"", file=sys.stderr)
         raise PDFValueError(""Some files do not exist."")
 
+    result_files = []
+
     for file in files:
         if file is str and (file.startswith(""http://"") or file.startswith(""https://"")):
             print(""Online files detected, downloading..."")
@@ -280,5 +282,6 @@ def translate(
         doc_dual = open(file_dual, ""wb"")
         doc_mono.write(s_mono)
         doc_dual.write(s_dual)
+        result_files.append((str(file_mono), str(file_dual)))
 
-    return str(file_mono), str(file_dual)
+    return result_files
",add download script,
ae471cb6b492c83ec88d83e5c71a0d539132e860,README.md,"@@ -1,8 +1,6 @@
 <div align=""center"">
 
-<p>
 English | [简体中文](README_zh-CN.md) | [日本語](README_ja-JP.md)
-</p>
 
 <img src=""./docs/images/banner.png"" width=""320px""  alt=""PDF2ZH""/>  
 
",add missing link to doc,
ae471cb6b492c83ec88d83e5c71a0d539132e860,README_ja-JP.md,"@@ -1,8 +1,6 @@
 <div align=""center"">
 
-<p>
 [English](README.md) | [简体中文](README_zh-CN.md) | 日本語
-</p>
 
 <img src=""./docs/images/banner.png"" width=""320px""  alt=""PDF2ZH""/>  
 
",add missing link to the last commit,
ae471cb6b492c83ec88d83e5c71a0d539132e860,README_zh-CN.md,"@@ -1,8 +1,6 @@
 <div align=""center"">
 
-<p>
 [English](README.md) | 简体中文 | [日本語](README_ja-JP.md)
-</p>
 
 <img src=""./docs/images/banner.png"" width=""320px""  alt=""PDF2ZH""/>  
 
",add missing link to the last commit,
d617c16c40297fe84a46eda00cc1f14bccca78c7,translator.py,"@@ -89,26 +89,27 @@ class BingTranslator(BaseTranslator):
     def __init__(self, lang_in, lang_out, model):
         super().__init__(lang_in, lang_out, model)
         self.session = requests.Session()
-        self.endpoint = ""https://www.bing.com/ttranslatev3""
+        self.endpoint = ""https://www.bing.com/translator""
         self.headers = {
             ""User-Agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0"",  # noqa: E501
         }
 
     def fineSID(self):
-        response = self.session.get(""https://www.bing.com/translator"")
+        response = self.session.get(self.endpoint)
         response.raise_for_status()
+        url = response.url[:-10]
         ig = re.findall(r""\""ig\"":\""(.*?)\"""", response.text)[0]
         iid = re.findall(r""data-iid=\""(.*?)\"""", response.text)[-1]
         key, token = re.findall(
             r""params_AbusePreventionHelper\s=\s\[(.*?),\""(.*?)\"","", response.text
         )[0]
-        return ig, iid, key, token
+        return url, ig, iid, key, token
 
     def translate(self, text):
         text = text[:1000]  # bing translate max length
-        ig, iid, key, token = self.fineSID()
+        url, ig, iid, key, token = self.fineSID()
         response = self.session.post(
-            f""{self.endpoint}?IG={ig}&IID={iid}"",
+            f""{url}ttranslatev3?IG={ig}&IID={iid}"",
             data={
                 ""fromLang"": self.lang_in,
                 ""to"": self.lang_out,
",add bing translator,
2e84cda6ca827427976c715698bbc03314531be6,README.md,"@@ -196,7 +196,7 @@ The table below outlines the required [environment variables](https://chatgpt.co
 |-|-|-|-|-|
 |**Google (Default)**|`google`|None|N/A|None|
 |**Bing**|`bing`|None|N/A|None|
-|**DeepL**|`deepl`|`DEEPL_SERVER_URL`,`DEEPL_AUTH_KEY`|`https://api.deepl.com`, `[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
 |**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
 |**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
 |**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
",add missing env table,
2e84cda6ca827427976c715698bbc03314531be6,README_ja-JP.md,"@@ -196,7 +196,7 @@ pdf2zh example.pdf -li en -lo ja
 |-|-|-|-|-|
 |**Google (Default)**|`google`|None|N/A|None|
 |**Bing**|`bing`|None|N/A|None|
-|**DeepL**|`deepl`|`DEEPL_SERVER_URL`,`DEEPL_AUTH_KEY`|`https://api.deepl.com`, `[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
 |**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
 |**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
 |**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
",add missing doc blocks,
2e84cda6ca827427976c715698bbc03314531be6,README_zh-CN.md,"@@ -196,7 +196,7 @@ pdf2zh example.pdf -li en -lo ja
 |-|-|-|-|-|
 |**Google (Default)**|`google`|None|N/A|None|
 |**Bing**|`bing`|None|N/A|None|
-|**DeepL**|`deepl`|`DEEPL_SERVER_URL`,`DEEPL_AUTH_KEY`|`https://api.deepl.com`, `[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
 |**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
 |**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
 |**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
",add missing doc blocks,
2e84cda6ca827427976c715698bbc03314531be6,translator.py,"@@ -127,16 +127,14 @@ class DeepLTranslator(BaseTranslator):
     # https://github.com/DeepLcom/deepl-python
     name = ""deepl""
     envs = {
-        ""DEEPL_SERVER_URL"": ""https://api.deepl.com"",
         ""DEEPL_AUTH_KEY"": None,
     }
     lang_map = {""zh"": ""zh-Hans""}
 
     def __init__(self, lang_in, lang_out, model):
         super().__init__(lang_in, lang_out, model)
-        server_url = os.getenv(""DEEPL_SERVER_URL"", self.envs[""DEEPL_SERVER_URL""])
         auth_key = os.getenv(""DEEPL_AUTH_KEY"")
-        self.client = deepl.Translator(auth_key, server_url=server_url)
+        self.client = deepl.Translator(auth_key)
 
     def translate(self, text):
         response = self.client.translate_text(
",add deepl translator,
6952684e8bf4219c6e2d0d87215312042be98b9e,translator.py,"@@ -282,7 +282,7 @@ class ZhipuTranslator(OpenAITranslator):
                 == ""1301""
             ):
                 return """"
-            print(""openai api error."")
+            raise ValueError(""openai api error."")
         return response.choices[0].message.content.strip()
 
 
",update zhipu.py,
0b7a789f5f741372bf42ed6b9c82ae6e36eb224e,gui.py,"@@ -105,6 +105,7 @@ def download_with_limit(url, save_path, size_limit):
                 file.write(chunk)
     return save_path / filename
 
+
 def stop_translate_file(state):
     session_id = state[""session_id""]
     if session_id is None:
@@ -112,6 +113,7 @@ def stop_translate_file(state):
     if session_id in cancellation_event_map:
         cancellation_event_map[session_id].set()
 
+
 def translate_file(
     file_type,
     file_input,
@@ -182,7 +184,7 @@ def translate_file(
     print(param)
     try:
         translate(**param)
-    except CancelledError as e:
+    except CancelledError:
         del cancellation_event_map[session_id]
         raise gr.Error(""Translation cancelled"")
     print(f""Files after translation: {os.listdir(output)}"")
",add missing comments,
0b7a789f5f741372bf42ed6b9c82ae6e36eb224e,high_level.py,"@@ -1,4 +1,5 @@
 """"""Functions that can be used for the most common use-cases for pdf2zh.six""""""
+
 import asyncio
 from asyncio import CancelledError
 from typing import BinaryIO
@@ -85,7 +86,7 @@ def translate_patch(
     resfont: str = """",
     noto: Font = None,
     callback: object = None,
-    cancellation_event : asyncio.Event = None,
+    cancellation_event: asyncio.Event = None,
     **kwarg: Any,
 ) -> None:
     rsrcmgr = PDFResourceManager()
",add docstrings for pdf2zh.six,
0b7a789f5f741372bf42ed6b9c82ae6e36eb224e,translator.py,"@@ -274,13 +274,13 @@ class ZhipuTranslator(OpenAITranslator):
                 **self.options,
                 messages=self.prompt(text),
             )
-        except openai.APIError:
+        except openai.BadRequestError as e:
             if (
                 json.loads(response.choices[0].message.content.strip())[""error""][""code""]
                 == ""1301""
             ):
-                return """"
-            raise ValueError(""openai api error."")
+                return ""IRREPARABLE TRANSLATION ERROR""
+            raise e
         return response.choices[0].message.content.strip()
 
 
@@ -368,6 +368,8 @@ class TencentTranslator(BaseTranslator):
         self.req.SourceText = text
         resp: TextTranslateResponse = self.client.TextTranslate(self.req)
         return resp.TargetText
+
+
 class AnythingLLMTranslator(BaseTranslator):
     name = ""anythingllm""
     envs = {
@@ -393,18 +395,21 @@ class AnythingLLMTranslator(BaseTranslator):
             ""sessionId"": ""translation_expert"",
         }
 
-        response = requests.post(self.api_url, headers=self.headers, data=json.dumps(payload))
+        response = requests.post(
+            self.api_url, headers=self.headers, data=json.dumps(payload)
+        )
         response.raise_for_status()
         data = response.json()
 
         if ""textResponse"" in data:
             return data[""textResponse""].strip()
 
+
 class DifyTranslator(BaseTranslator):
     name = ""dify""
     envs = {
         ""DIFY_API_URL"": None,  # 填写实际 Dify API 地址
-        ""DIFY_API_KEY"": ""api_key""  # 替换为实际 API 密钥
+        ""DIFY_API_KEY"": ""api_key"",  # 替换为实际 API 密钥
     }
 
     def __init__(self, lang_out, lang_in, model):
@@ -415,27 +420,25 @@ class DifyTranslator(BaseTranslator):
     def translate(self, text):
         headers = {
             ""Authorization"": f""Bearer {self.api_key}"",
-            ""Content-Type"": ""application/json""
+            ""Content-Type"": ""application/json"",
         }
 
         payload = {
             ""inputs"": {
                 ""lang_out"": self.lang_out,
                 ""lang_in"": self.lang_in,
-                ""text"": text
+                ""text"": text,
             },
             ""response_mode"": ""blocking"",
-            ""user"": ""translator-service""
+            ""user"": ""translator-service"",
         }
 
         # 向 Dify 服务器发送请求
         response = requests.post(
-            self.api_url,
-            headers=headers,
-            data=json.dumps(payload)
+            self.api_url, headers=headers, data=json.dumps(payload)
         )
         response.raise_for_status()
         response_data = response.json()
 
         # 解析响应
-        return response_data.get('data', {}).get('outputs', {}).get('text', [])
+        return response_data.get(""data"", {}).get(""outputs"", {}).get(""text"", [])
",add more translator classes,
d2d36bda0cf567511df375c0dff716b36a223a8c,converter.py,"@@ -173,8 +173,8 @@ class TranslateConverter(PDFConverterEx):
         ops: str = """"                   # 渲染结果
 
         def vflag(font: str, char: str):    # 匹配公式（和角标）字体
-            if isinstance(font, bytes):     # hack 嵌入的 china-ss 会变成 b'Song'
-                font = font.decode()
+            if isinstance(font, bytes):     # 不一定能 decode，直接转 str
+                font = str(font)
             font = font.split(""+"")[-1]      # 字体名截断
             if re.match(r""\(cid:"", char):
                 return True
",add support for china-ss,
198e4fd1054385b012fed5ad7ed175311d2d9ad8,README_zh-CN.md,"@@ -193,7 +193,7 @@ pdf2zh example.pdf -li en -lo ja
 下表列出了每个翻译服务所需的 [环境变量](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4)，在使用相应服务之前，请确保已设置这些变量
 
 | **Translator**       | **Service**    |**Environment Variables**|**Default Values**| **Notes**                                                                                                                                                                                                 |
-|----------------------|----------------|-|-|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
+|-|-|-|-|-|
 | **Google (Default)** | `google`       |None|N/A| None                                                                                                                                                                                                      |
 | **Bing**             | `bing`         |None|N/A| None                                                                                                                                                                                                      |
 | **DeepL**            | `deepl`        |`DEEPL_AUTH_KEY`|`[Your Key]`| See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)                                                                                                             |
@@ -202,7 +202,7 @@ pdf2zh example.pdf -li en -lo ja
 | **OpenAI**           | `openai`       |`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`| See [OpenAI](https://platform.openai.com/docs/overview)                                                                                                                                                   |
 | **AzureOpenAI**      | `azure-openai` |`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`| See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python) |
 | **Zhipu**            | `zhipu`        |`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`| See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)                                                                                                                                 |
-| **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)                                                                                                                            |
+| **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
 | **Silicon**          | `silicon`      |`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`| See [SiliconCloud](https://docs.siliconflow.cn/quickstart)                                                                                                                                                |
 | **Gemini**           | `gemini`       |`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`| See [Gemini](https://ai.google.dev/gemini-api/docs/openai)                                                                                                                                                |
 | **Azure**            | `azure`        |`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`| See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)                                                                                                                 |
",add missing examples,
d92aa77900305a23527232f3f432969c14de6205,README_zh-CN.md,"@@ -192,23 +192,23 @@ pdf2zh example.pdf -li en -lo ja
 
 下表列出了每个翻译服务所需的 [环境变量](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4)，在使用相应服务之前，请确保已设置这些变量
 
-| **Translator**       | **Service**    |**Environment Variables**|**Default Values**| **Notes**                                                                                                                                                                                                 |
+|**Translator**|**Service**|**Environment Variables**|**Default Values**|**Notes**|
 |-|-|-|-|-|
-| **Google (Default)** | `google`       |None|N/A| None                                                                                                                                                                                                      |
-| **Bing**             | `bing`         |None|N/A| None                                                                                                                                                                                                      |
-| **DeepL**            | `deepl`        |`DEEPL_AUTH_KEY`|`[Your Key]`| See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)                                                                                                             |
-| **DeepLX**           | `deeplx`       |`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`| See [DeepLX](https://github.com/OwO-Network/DeepLX)                                                                                                                                                       |
-| **Ollama**           | `ollama`       |`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`| See [Ollama](https://github.com/ollama/ollama)                                                                                                                                                            |
-| **OpenAI**           | `openai`       |`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`| See [OpenAI](https://platform.openai.com/docs/overview)                                                                                                                                                   |
-| **AzureOpenAI**      | `azure-openai` |`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`| See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python) |
-| **Zhipu**            | `zhipu`        |`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`| See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)                                                                                                                                 |
+|**Google (Default)**|`google`|None|N/A|None|
+|**Bing**|`bing`|None|N/A|None|
+|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
+|**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
+|**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
+|**AzureOpenAI**|`azure-openai`|`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
+|**Zhipu**|`zhipu`|`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
 | **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
-| **Silicon**          | `silicon`      |`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`| See [SiliconCloud](https://docs.siliconflow.cn/quickstart)                                                                                                                                                |
-| **Gemini**           | `gemini`       |`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`| See [Gemini](https://ai.google.dev/gemini-api/docs/openai)                                                                                                                                                |
-| **Azure**            | `azure`        |`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`| See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)                                                                                                                 |
-| **Tencent**          | `tencent`      |`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`| See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)                                                                                                                            |
-| **Dify**             | `dify`         |`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`| See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.                                                                 |
-| **AnythingLLM**      | `anythingllm`  |`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`| See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)                                                                                                                                         |
+|**Silicon**|`silicon`|`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
+|**Gemini**|`gemini`|`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
+|**Azure**|`azure`|`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
+|**Tencent**|`tencent`|`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`|See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)|
+|**Dify**|`dify`|`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`|See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.|
+|**AnythingLLM**|`anythingllm`|`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`|See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)|
 
 使用 `-s service` 或 `-s service:model` 指定翻译服务:
 
",add examples to the 2zh example,
872e2dafec69ecd24ebbe3ce9462482b1a555376,pdfinterp.py,"@@ -229,7 +229,11 @@ class PDFPageInterpreterEx(PDFPageInterpreter):
                 self.device.fontmap = interpreter.fontmap
                 ops_new = self.device.end_figure(xobjid)
                 ctm_inv = np.linalg.inv(np.array(ctm[:4]).reshape(2, 2))
-                pos_inv = -np.mat(ctm[4:]) * ctm_inv
+                np_version = np.__version__
+                if np_version.split(""."")[0] >= ""2"":
+                    pos_inv = -np.asmatrix(ctm[4:]) * ctm_inv
+                else:
+                    pos_inv = -np.mat(ctm[4:]) * ctm_inv
                 a, b, c, d = ctm_inv.reshape(4).tolist()
                 e, f = pos_inv.tolist()[0]
                 self.obj_patch[self.xobjmap[xobjid].objid] = (
",add support for np.asmatrix in pdfpageinterpreter,
ca39f01f03cbb31ac7ef5aac946ae5cfaa2d6872,gui.py,"@@ -290,7 +290,7 @@ with gr.Blocks(
             service = gr.Dropdown(
                 label=""Service"",
                 choices=service_map.keys(),
-                value=""Google"",
+                value=""ModelScope"",
             )
             envs = []
             for i in range(3):
",add missing dropdowns,
0c69753898bf826907efa7baec640bbf5e724024,gui.py,"@@ -296,7 +296,7 @@ with gr.Blocks(
             for i in range(3):
                 envs.append(
                     gr.Textbox(
-                        visible=True,
+                        visible=False,
                         interactive=True,
                     )
                 )
@@ -438,6 +438,7 @@ with gr.Blocks(
         stop_translate_file,
         inputs=[state],
     )
+    demo.load(on_select_service, service, envs)
 
 
 def setup_gui(share=False):
",add example for loading service,
4559181f84fa537f499a7aa31896689ee738b0b3,doclayout.py,"@@ -1,4 +1,6 @@
 import abc
+import os.path
+
 import cv2
 import numpy as np
 import ast
@@ -11,7 +13,7 @@ class DocLayoutModel(abc.ABC):
     @staticmethod
     def load_onnx():
         model = OnnxModel.from_pretrained(
-            repo_id=""wybxc/DocLayout-YOLO-DocStructBench-onnx"",
+            repo_id='AI-ModelScope/DocLayout-YOLO-DocStructBench-onnx',
             filename=""doclayout_yolo_docstructbench_imgsz1024.onnx"",
         )
         return model
@@ -70,7 +72,9 @@ class OnnxModel(DocLayoutModel):
 
     @staticmethod
     def from_pretrained(repo_id: str, filename: str):
-        pth = hf_hub_download(repo_id=repo_id, filename=filename, etag_timeout=1)
+        from modelscope import snapshot_download
+        model_dir = snapshot_download(repo_id)
+        pth = os.path.join(model_dir, filename)
         return OnnxModel(pth)
 
     @property
",add doclayout-yolo-docstructbench-onnx,
fb3b70a15f411ede05ce3c4c9696f9d33b7a46ee,converter.py,"@@ -276,7 +276,7 @@ class TranslateConverter(PDFConverterEx):
                     if (                                                    # 根据当前字符修正段落属性
                         child.size > pstk[-1].size / 0.79                   # 1. 当前字符显著比段落字体大
                         or len(sstk[-1].strip()) == 1                       # 2. 当前字符为段落第二个文字（考虑首字母放大的情况）
-                    ):
+                    ) and child.get_text() != "" "":                          # 3. 当前字符不是空格
                         pstk[-1].y -= child.size - pstk[-1].size            # 修正段落初始纵坐标，假设两个不同大小字符的上边界对齐
                         pstk[-1].size = child.size
                     sstk[-1] += child.get_text()
",add support for 修正段落前字符二上边界对齐,
cbccf1686c17c69016c0c6f22543077744ad979b,gui.py,"@@ -164,9 +164,6 @@ def translate_file(
     lang_from = lang_map[lang_from]
     lang_to = lang_map[lang_to]
 
-    for i, env in enumerate(translator.envs.items()):
-        os.environ[env[0]] = envs[i]
-
     print(f""Files before translation: {os.listdir(output)}"")
 
     def progress_bar(t: tqdm.tqdm):
",update translation script,
cbccf1686c17c69016c0c6f22543077744ad979b,translator.py,"@@ -257,7 +257,7 @@ class ModelScopeTranslator(OpenAITranslator):
     envs = {
         ""MODELSCOPE_BASE_URL"": ""https://api-inference.modelscope.cn/v1"",
         ""MODELSCOPE_API_KEY"": None,
-        ""MODELSCOPE_MODEL"": ""Qwen/Qwen2.5-Coder-32B-Instruct"",
+        ""MODELSCOPE_MODEL"": ""Qwen/Qwen2.5-32B-Instruct"",
     }
 
     def __init__(self, lang_in, lang_out, model, base_url=None, api_key=None):
",add modelscope to openai,
7c7e0d17196a25e5960227f5a59067d6cd0df54e,gui.py,"@@ -167,7 +167,7 @@ def translate_file(
     _envs = {}
     for i, env in enumerate(translator.envs.items()):
         _envs[env[0]] = envs[i]
-
+    
     print(f""Files before translation: {os.listdir(output)}"")
 
     def progress_bar(t: tqdm.tqdm):
",add progress bar to translate_file,
7c7e0d17196a25e5960227f5a59067d6cd0df54e,high_level.py,"@@ -216,7 +216,7 @@ def translate_stream(
 
     fp = io.BytesIO()
     doc_zh.save(fp)
-    obj_patch: dict = translate_patch(fp, **locals())
+    obj_patch: dict = translate_patch(fp, envs=kwarg['envs'], **locals())
 
     for obj_id, ops_new in obj_patch.items():
         # ops_old=doc_en.xref_stream(obj_id)
@@ -282,7 +282,7 @@ def translate(
 
         doc_raw = open(file, ""rb"")
         s_raw = doc_raw.read()
-        s_mono, s_dual = translate_stream(s_raw, **locals())
+        s_mono, s_dual = translate_stream(s_raw, envs=kwarg['envs'], **locals())
         file_mono = Path(output) / f""{filename}-mono.pdf""
         file_dual = Path(output) / f""{filename}-dual.pdf""
         doc_mono = open(file_mono, ""wb"")
","add support for -282,7 +282,7",
7c7e0d17196a25e5960227f5a59067d6cd0df54e,translator.py,"@@ -3,7 +3,7 @@ import logging
 import os
 import re
 import unicodedata
-
+from copy import copy
 import deepl
 import ollama
 import openai
@@ -35,6 +35,7 @@ class BaseTranslator:
         self.model = model
 
     def set_envs(self, envs):
+        self.envs = copy(self.__class__.envs)
         for key in self.envs:
             if key in os.environ:
                 self.envs[key] = os.environ[key]
@@ -215,8 +216,7 @@ class OpenAITranslator(BaseTranslator):
         ""OPENAI_MODEL"": ""gpt-4o-mini"",
     }
 
-    def __init__(self, lang_in, lang_out, model, base_url=None, api_key=None, envs=None):
-        self.set_envs(envs)
+    def __init__(self, lang_in, lang_out, model, base_url=None, api_key=None):
         if not model:
             model = self.envs[""OPENAI_MODEL""]
         super().__init__(lang_in, lang_out, model)
",add missing docstrings,
cc27355ad7538e0b1e6322389d47e04775fa031b,__init__.py,"@@ -1,5 +1,8 @@
 import logging
+from pdf2zh.high_level import translate, translate_stream
+
 log = logging.getLogger(__name__)
 
 __version__ = ""1.8.8""
 __author__ = ""Byaidu""
+__all__ = [""translate"", ""translate_stream""]
",add version and author to the missing file,
cc27355ad7538e0b1e6322389d47e04775fa031b,converter.py,"@@ -1,4 +1,4 @@
-from typing import List, Dict
+from typing import Dict
 
 from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
 from pdfminer.pdffont import PDFCIDFont
",add missing import,
cc27355ad7538e0b1e6322389d47e04775fa031b,doclayout.py,"@@ -13,7 +13,7 @@ class DocLayoutModel(abc.ABC):
     @staticmethod
     def load_onnx():
         model = OnnxModel.from_pretrained(
-            repo_id='AI-ModelScope/DocLayout-YOLO-DocStructBench-onnx',
+            repo_id=""wybxc/DocLayout-YOLO-DocStructBench-onnx"",
             filename=""doclayout_yolo_docstructbench_imgsz1024.onnx"",
         )
         return model
@@ -72,9 +72,16 @@ class OnnxModel(DocLayoutModel):
 
     @staticmethod
     def from_pretrained(repo_id: str, filename: str):
-        from modelscope import snapshot_download
-        model_dir = snapshot_download(repo_id)
-        pth = os.path.join(model_dir, filename)
+        if os.environ.get(""USE_MODELSCOPE"", ""0"") == ""1"":
+            repo_mapping = {
+                # Edit here to add more models
+                ""wybxc/DocLayout-YOLO-DocStructBench-onnx"": ""AI-ModelScope/DocLayout-YOLO-DocStructBench-onnx""
+            }
+            from modelscope import snapshot_download
+            model_dir = snapshot_download(repo_mapping[repo_id])
+            pth = os.path.join(model_dir, filename)
+        else:
+            pth = hf_hub_download(repo_id=repo_id, filename=filename, etag_timeout=1)
         return OnnxModel(pth)
 
     @property
",add doclayout yolo doc struct benchmark,
cc27355ad7538e0b1e6322389d47e04775fa031b,gui.py,"@@ -292,7 +292,7 @@ with gr.Blocks(
             service = gr.Dropdown(
                 label=""Service"",
                 choices=service_map.keys(),
-                value=""ModelScope"",
+                value=""Google"",
             )
             envs = []
             for i in range(3):
@@ -440,7 +440,6 @@ with gr.Blocks(
         stop_translate_file,
         inputs=[state],
     )
-    demo.load(on_select_service, service, envs)
 
 
 def readuserandpasswd(file_path):
",add example,
cc27355ad7538e0b1e6322389d47e04775fa031b,pdf2zh.py,"@@ -9,11 +9,11 @@ import argparse
 import sys
 import logging
 from typing import List, Optional
+from pdf2zh import __version__, log
 from pdf2zh.high_level import translate
 
 
 def create_parser() -> argparse.ArgumentParser:
-    from pdf2zh import __version__
     parser = argparse.ArgumentParser(description=__doc__, add_help=True)
     parser.add_argument(
         ""files"",
@@ -144,7 +144,6 @@ def parse_args(args: Optional[List[str]]) -> argparse.Namespace:
 
 
 def main(args: Optional[List[str]] = None) -> int:
-    from pdf2zh import log
     logging.basicConfig()
 
     parsed_args = parse_args(args)
",add doc to the main function,
cc27355ad7538e0b1e6322389d47e04775fa031b,pyproject.toml,"@@ -50,4 +50,4 @@ requires = [""hatchling""]
 build-backend = ""hatchling.build""
 
 [project.scripts]
-pdf2zh = ""pdf2zh.entrance:main""
+pdf2zh = ""pdf2zh.pdf2zh:main""
",add missing example,
39fe9402f44abfae0f891abf007c58a572c42a34,translator.py,"@@ -35,7 +35,10 @@ class BaseTranslator:
         self.model = model
 
     def set_envs(self, envs):
-        self.envs = copy(self.__class__.envs)
+        # Detach from self.__class__.envs
+        # Cannot use self.envs = copy(self.__class__.envs)
+        # because if set_envs called twice, the second call will override the first call
+        self.envs = copy(self.envs)
         for key in self.envs:
             if key in os.environ:
                 self.envs[key] = os.environ[key]
@@ -216,7 +219,10 @@ class OpenAITranslator(BaseTranslator):
         ""OPENAI_MODEL"": ""gpt-4o-mini"",
     }
 
-    def __init__(self, lang_in, lang_out, model, base_url=None, api_key=None):
+    def __init__(
+        self, lang_in, lang_out, model, base_url=None, api_key=None, envs=None
+    ):
+        self.set_envs(envs)
         if not model:
             model = self.envs[""OPENAI_MODEL""]
         super().__init__(lang_in, lang_out, model)
",add missing docstrings,
752e9b37aed8a2fcb56350adec7acc2b606a5bff,high_level.py,"@@ -292,7 +292,7 @@ def translate(
 
         doc_raw = open(file, ""rb"")
         s_raw = doc_raw.read()
-        s_mono, s_dual = translate_stream(s_raw, envs=kwarg[""envs""], **locals())
+        s_mono, s_dual = translate_stream(s_raw, envs=kwarg.get('envs'), **locals())
         file_mono = Path(output) / f""{filename}-mono.pdf""
         file_dual = Path(output) / f""{filename}-dual.pdf""
         doc_mono = open(file_mono, ""wb"")
",update translate.rb,
4e2e12e902c3d68676187f243976aaa6ecb23f11,issue-translator.yml,"@@ -0,0 +1,15 @@
+name: 'issue-translator'
+on: 
+  issue_comment: 
+    types: [created]
+  issues: 
+    types: [opened]
+
+jobs:
+  build:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: usthe/issues-translate-action@v2.7
+        with:
+          IS_MODIFY_TITLE: true
+          CUSTOM_BOT_NOTE: The issue has been automatically translated into English.
\ No newline at end of file
",add missing missing tag,
40bbf7e9313113ed3d05808bfa77854251fe348d,gui.py,"@@ -445,6 +445,8 @@ with gr.Blocks(
 def readuserandpasswd(file_path):
     tuple_list = []
     content = """"
+    if file_path is None or len(file_path) == 0:
+        return tuple_list, content
     if len(file_path) == 2:
         try:
             with open(file_path[1], ""r"", encoding=""utf-8"") as file:
",add missing try/except block,
10d9cf19e837f47eb6de15045ac2b02c9cc0a5ef,gui.py,"@@ -64,6 +64,7 @@ page_map = {
     ""All"": None,
     ""First"": [0],
     ""First 5 pages"": list(range(0, 5)),
+    ""Others"": None,
 }
 
 flag_demo = False
@@ -125,6 +126,9 @@ def translate_file(
     lang_from,
     lang_to,
     page_range,
+    page_input,
+    prompt,
+    threads,
     recaptcha_response,
     state,
     progress=gr.Progress(),
@@ -161,7 +165,16 @@ def translate_file(
     file_dual = output / f""{filename}-dual.pdf""
 
     translator = service_map[service]
-    selected_page = page_map[page_range]
+    if page_range != ""Others"":
+        selected_page = page_map[page_range]
+    else:
+        selected_page = []
+        for p in page_input.split("",""):
+            if ""-"" in p:
+                start, end = p.split(""-"")
+                selected_page.extend(range(int(start) - 1, int(end)))
+            else:
+                selected_page.append(int(p) - 1)
     lang_from = lang_map[lang_from]
     lang_to = lang_map[lang_to]
 
@@ -181,10 +194,11 @@ def translate_file(
         ""lang_out"": lang_to,
         ""service"": f""{translator.name}"",
         ""output"": output,
-        ""thread"": 4,
+        ""thread"": int(threads),
         ""callback"": progress_bar,
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
+        ""prompt"": prompt,
     }
     try:
         translate(**param)
@@ -319,15 +333,30 @@ with gr.Blocks(
                 value=list(page_map.keys())[0],
             )
 
+            page_input = gr.Textbox(
+                label=""Page range"",
+                visible=False,
+                interactive=True,
+            )
+
+            with gr.Accordion(""Open for More Experimental Options!"", open=False):
+                gr.Markdown(""#### Experimental"")
+                threads = gr.Textbox(label=""number of threads"", interactive=True)
+                prompt = gr.Textbox(
+                    label=""Custom Prompt for llm"", interactive=True, visible=False
+                )
+                envs.append(prompt)
+
             def on_select_service(service, evt: gr.EventData):
                 translator = service_map[service]
                 _envs = []
-                for i in range(3):
+                for i in range(4):
                     _envs.append(gr.update(visible=False, value=""""))
                 for i, env in enumerate(translator.envs.items()):
                     _envs[i] = gr.update(
                         visible=True, label=env[0], value=os.getenv(env[0], env[1])
                     )
+                _envs[-1] = gr.update(visible=translator.CustomPrompt)
                 return _envs
 
             def on_select_filetype(file_type):
@@ -336,6 +365,12 @@ with gr.Blocks(
                     gr.update(visible=file_type == ""Link""),
                 )
 
+            def on_select_page(choice):
+                if choice == ""Others"":
+                    return gr.update(visible=True)
+                else:
+                    return gr.update(visible=False)
+
             output_title = gr.Markdown(""## Translated"", visible=False)
             output_file_mono = gr.File(
                 label=""Download Translation (Mono)"", visible=False
@@ -358,6 +393,7 @@ with gr.Blocks(
                 """""",
                 elem_classes=[""secondary-text""],
             )
+            page_range.select(on_select_page, page_range, page_input)
             service.select(
                 on_select_service,
                 service,
@@ -422,6 +458,9 @@ with gr.Blocks(
             lang_from,
             lang_to,
             page_range,
+            page_input,
+            prompt,
+            threads,
             recaptcha_response,
             state,
             *envs,
@@ -445,7 +484,7 @@ with gr.Blocks(
 def readuserandpasswd(file_path):
     tuple_list = []
     content = """"
-    if file_path is None:
+    if not file_path:
         return tuple_list, content
     if len(file_path) == 2:
         try:
","add examples for -64,6 +64,7",
10d9cf19e837f47eb6de15045ac2b02c9cc0a5ef,translator.py,"@@ -26,6 +26,7 @@ class BaseTranslator:
     name = ""base""
     envs = {}
     lang_map = {}
+    CustomPrompt = False
 
     def __init__(self, lang_in, lang_out, model):
         lang_in = self.lang_map.get(lang_in.lower(), lang_in)
@@ -200,6 +201,7 @@ class OllamaTranslator(BaseTranslator):
         ""OLLAMA_HOST"": ""http://127.0.0.1:11434"",
         ""OLLAMA_MODEL"": ""gemma2"",
     }
+    CustomPrompt = True
 
     def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
         self.set_envs(envs)
@@ -230,6 +232,7 @@ class OpenAITranslator(BaseTranslator):
         ""OPENAI_API_KEY"": None,
         ""OPENAI_MODEL"": ""gpt-4o-mini"",
     }
+    CustomPrompt = True
 
     def __init__(
         self,
@@ -265,6 +268,7 @@ class AzureOpenAITranslator(BaseTranslator):
         ""AZURE_OPENAI_API_KEY"": None,
         ""AZURE_OPENAI_MODEL"": ""gpt-4o-mini"",
     }
+    CustomPrompt = True
 
     def __init__(
         self,
@@ -306,6 +310,7 @@ class ModelScopeTranslator(OpenAITranslator):
         ""MODELSCOPE_API_KEY"": None,
         ""MODELSCOPE_MODEL"": ""Qwen/Qwen2.5-32B-Instruct"",
     }
+    CustomPrompt = True
 
     def __init__(
         self,
@@ -333,6 +338,7 @@ class ZhipuTranslator(OpenAITranslator):
         ""ZHIPU_API_KEY"": None,
         ""ZHIPU_MODEL"": ""glm-4-flash"",
     }
+    CustomPrompt = True
 
     def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
         self.set_envs(envs)
@@ -367,6 +373,7 @@ class SiliconTranslator(OpenAITranslator):
         ""SILICON_API_KEY"": None,
         ""SILICON_MODEL"": ""Qwen/Qwen2.5-7B-Instruct"",
     }
+    CustomPrompt = True
 
     def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
         self.set_envs(envs)
@@ -385,6 +392,7 @@ class GeminiTranslator(OpenAITranslator):
         ""GEMINI_API_KEY"": None,
         ""GEMINI_MODEL"": ""gemini-1.5-flash"",
     }
+    CustomPrompt = True
 
     def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
         self.set_envs(envs)
@@ -458,6 +466,7 @@ class AnythingLLMTranslator(BaseTranslator):
         ""AnythingLLM_URL"": None,
         ""AnythingLLM_APIKEY"": None,
     }
+    CustomPrompt = True
 
     def __init__(self, lang_out, lang_in, model, envs=None, prompt=None):
         self.set_envs(envs)
",add more tools to the translator,
ab2773e144fe9bcb5b88d992c72728f9ac719fce,gui.py,"@@ -187,6 +187,11 @@ def translate_file(
     def progress_bar(t: tqdm.tqdm):
         progress(t.n / t.total, desc=""Translating..."")
 
+    try:
+        threads = int(threads)
+    except ValueError:
+        threads = 1
+
     param = {
         ""files"": [str(file_raw)],
         ""pages"": selected_page,
@@ -194,7 +199,7 @@ def translate_file(
         ""lang_out"": lang_to,
         ""service"": f""{translator.name}"",
         ""output"": output,
-        ""thread"": int(threads),
+        ""thread"": threads,
         ""callback"": progress_bar,
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
@@ -341,7 +346,9 @@ with gr.Blocks(
 
             with gr.Accordion(""Open for More Experimental Options!"", open=False):
                 gr.Markdown(""#### Experimental"")
-                threads = gr.Textbox(label=""number of threads"", interactive=True)
+                threads = gr.Textbox(
+                    label=""number of threads"", interactive=True, value=""1""
+                )
                 prompt = gr.Textbox(
                     label=""Custom Prompt for llm"", interactive=True, visible=False
                 )
",add language output to translate_file,
69b02ee735b3cbedfd0c306d550a28feb897dfcc,gui.py,"@@ -1,35 +1,26 @@
+import asyncio
+import cgi
 import os
 import shutil
 import uuid
-import asyncio
 from asyncio import CancelledError
 from pathlib import Path
-from pdf2zh import __version__
-from pdf2zh.high_level import translate
-from pdf2zh.translator import (
-    BaseTranslator,
-    GoogleTranslator,
-    BingTranslator,
-    DeepLTranslator,
-    DeepLXTranslator,
-    OllamaTranslator,
-    AzureOpenAITranslator,
-    OpenAITranslator,
-    ZhipuTranslator,
-    ModelScopeTranslator,
-    SiliconTranslator,
-    GeminiTranslator,
-    AzureTranslator,
-    TencentTranslator,
-    DifyTranslator,
-    AnythingLLMTranslator,
-)
 
 import gradio as gr
-from gradio_pdf import PDF
-import tqdm
 import requests
-import cgi
+import tqdm
+from gradio_pdf import PDF
+
+from pdf2zh import __version__
+from pdf2zh.high_level import translate
+from pdf2zh.translator import (AnythingLLMTranslator, AzureOpenAITranslator,
+                               AzureTranslator, BaseTranslator, BingTranslator,
+                               DeepLTranslator, DeepLXTranslator,
+                               DifyTranslator, GeminiTranslator,
+                               GoogleTranslator, ModelScopeTranslator,
+                               OllamaTranslator, OpenAITranslator,
+                               SiliconTranslator, TencentTranslator,
+                               ZhipuTranslator)
 
 service_map: dict[str, BaseTranslator] = {
     ""Google"": GoogleTranslator,
@@ -481,7 +472,7 @@ with gr.Blocks(
     )
 
 
-def readuserandpasswd(file_path):
+def parse_user_passwd(file_path):
     tuple_list = []
     content = """"
     if not file_path:
@@ -503,7 +494,7 @@ def readuserandpasswd(file_path):
 
 
 def setup_gui(share=False, authfile=["""", """"]):
-    userlist, html = readuserandpasswd(authfile)
+    userlist, html = parse_user_passwd(authfile)
     if flag_demo:
         demo.launch(server_name=""0.0.0.0"", max_file_size=""5mb"", inbrowser=True)
     else:
",add support for google and google google translations,
5ce72a1fb88fcf0bbf18cc0463767fc7032075bc,gui.py,"@@ -13,14 +13,24 @@ from gradio_pdf import PDF
 
 from pdf2zh import __version__
 from pdf2zh.high_level import translate
-from pdf2zh.translator import (AnythingLLMTranslator, AzureOpenAITranslator,
-                               AzureTranslator, BaseTranslator, BingTranslator,
-                               DeepLTranslator, DeepLXTranslator,
-                               DifyTranslator, GeminiTranslator,
-                               GoogleTranslator, ModelScopeTranslator,
-                               OllamaTranslator, OpenAITranslator,
-                               SiliconTranslator, TencentTranslator,
-                               ZhipuTranslator)
+from pdf2zh.translator import (
+    AnythingLLMTranslator,
+    AzureOpenAITranslator,
+    AzureTranslator,
+    BaseTranslator,
+    BingTranslator,
+    DeepLTranslator,
+    DeepLXTranslator,
+    DifyTranslator,
+    GeminiTranslator,
+    GoogleTranslator,
+    ModelScopeTranslator,
+    OllamaTranslator,
+    OpenAITranslator,
+    SiliconTranslator,
+    TencentTranslator,
+    ZhipuTranslator,
+)
 
 service_map: dict[str, BaseTranslator] = {
     ""Google"": GoogleTranslator,
",add missing imports,
709697f972c6e01f45d62d4a8066f6dd5e6725e5,issue-translator.yml,"@@ -1,15 +0,0 @@
-name: 'Issue Translator'
-on: 
-  issue_comment: 
-    types: [created]
-  issues: 
-    types: [opened]
-
-jobs:
-  build:
-    runs-on: ubuntu-latest
-    steps:
-      - uses: usthe/issues-translate-action@v2.7
-        with:
-          IS_MODIFY_TITLE: true
-          CUSTOM_BOT_NOTE: The issue has been automatically translated into English.
\ No newline at end of file
",add missing missing options,
1e8ca491f8e4cd5e37e3378b10637e749faf79b1,high_level.py,"@@ -254,8 +254,7 @@ def convert_to_pdfa(input_path, output_path):
     Args:
         input_path: Path to source PDF file
         output_path: Path to save PDF/A file
-    """"""
-    import pikepdf
+    """"""pikepdf
     from pikepdf import Dictionary, Name, Pdf
 
     # Open the PDF file
@@ -347,7 +346,7 @@ def translate(
         filename = os.path.splitext(os.path.basename(file))[0]
 
         # If the commandline has specified converting to PDF/A format
-        ## --compatible / -cp
+        # --compatible / -cp
         if compatible:
             file_pdfa = file.replace("".pdf"", ""-pdfa.pdf"")
             print(f""Converting {file} to PDF/A format..."")
",add support for -pdfa format in the command line,
502de5d647022b9c8cef825f94d1ac548bacd682,high_level.py,"@@ -254,7 +254,7 @@ def convert_to_pdfa(input_path, output_path):
     Args:
         input_path: Path to source PDF file
         output_path: Path to save PDF/A file
-    """"""pikepdf
+    """"""
     from pikepdf import Dictionary, Name, Pdf
 
     # Open the PDF file
",add missing import,
b9ae66bd59fde45d3b52d499611cda4b5fb83466,pyproject.toml,"@@ -27,7 +27,7 @@ dependencies = [
     ""opencv-python-headless"",
     ""tencentcloud-sdk-python"",
     ""pdfminer.six>=20240706"",
-    ""gradio_pdf"",
+    ""gradio_pdf>=0.0.21"",
     ""pikepdf"",
 ]
 
",add missing dependency,
b1c0f917618c1b23916f054e9ddb09e2fa025e3a,test_cache.py,"@@ -3,9 +3,9 @@ import os
 import tempfile
 import shutil
 import time
-from unittest.mock import patch, mock_open
 from pdf2zh import cache
 
+
 class TestCache(unittest.TestCase):
     def setUp(self):
         # Create a temporary directory for testing
@@ -36,7 +36,7 @@ class TestCache(unittest.TestCase):
         test_dirs = [""dir1"", ""dir2"", ""dir3""]
         for dir_name in test_dirs:
             os.makedirs(os.path.join(self.test_cache_dir, dir_name))
-        
+
         # Create a file (should be ignored)
         with open(os.path.join(self.test_cache_dir, ""test.txt""), ""w"") as f:
             f.write(""test"")
@@ -51,7 +51,7 @@ class TestCache(unittest.TestCase):
         test_dir = os.path.join(self.test_cache_dir, ""test_dir"")
         os.makedirs(test_dir)
         test_time = 1234567890.0
-        
+
         with open(os.path.join(test_dir, cache.time_filename), ""w"") as f:
             f.write(str(test_time))
 
@@ -67,9 +67,9 @@ class TestCache(unittest.TestCase):
     def test_write_time(self):
         test_dir = os.path.join(self.test_cache_dir, ""test_dir"")
         os.makedirs(test_dir)
-        
+
         cache.write_time(test_dir)
-        
+
         self.assertTrue(os.path.exists(os.path.join(test_dir, cache.time_filename)))
         with open(os.path.join(test_dir, cache.time_filename)) as f:
             time_value = float(f.read())
@@ -84,7 +84,7 @@ class TestCache(unittest.TestCase):
             cache.write_time(dir_path)
 
         cache.remove_extra()
-        
+
         remaining_dirs = cache.get_dirs()
         self.assertLessEqual(len(remaining_dirs), cache.max_cache)
 
@@ -103,5 +103,6 @@ class TestCache(unittest.TestCase):
         cache.write_paragraph(test_hash, test_para_hash, test_content)
         self.assertEqual(cache.load_paragraph(test_hash, test_para_hash), test_content)
 
+
 if __name__ == ""__main__"":
     unittest.main()
",add tests for pdf2zh,
76924345955c87ac6ed0e0912efba4c8ba99b37e,translator.py,"@@ -213,37 +213,25 @@ class OllamaTranslator(BaseTranslator):
         self.prompttext = prompt
 
     def translate(self, text):
-        print(len(self.prompt(text, self.prompttext)))
-        print(self.prompt(text, self.prompttext)[0])
-        print(self.prompt(text, self.prompttext)[1])
-        maxlen = max(2000, len(text) * 3)
+        maxlen = max(2000, len(text) * 5)
         for model in self.model.split("";""):
-            for i in range(2):
-                if i:
-                    print(""[Retry]"")
+            try:
                 response = """"
-                try:
-                    stream = self.client.chat(
-                        model=model,
-                        options=self.options,
-                        messages=self.prompt(text, self.prompttext),
-                        stream=True,
-                    )
-                    for chunk in stream:
-                        chunk = chunk[""message""][""content""]
-                        print(chunk, end="""", flush=True)
-                        response += chunk
-                        if len(response) > maxlen:
-                            raise Exception(""Response too long"")
-                    if not response.endswith(""\n""):
-                        print()
-                    return response.strip()
-                except Exception as e:
-                    print()
-                    print(e)
-        print(""[Aborted.]"")
-        # if translation fails after multiple retries, return the original text to prevent hang-up
-        return text
+                stream = self.client.chat(
+                    model=model,
+                    options=self.options,
+                    messages=self.prompt(text, self.prompttext),
+                    stream=True,
+                )
+                for chunk in stream:
+                    chunk = chunk[""message""][""content""]
+                    response += chunk
+                    if len(response) > maxlen:
+                        raise Exception(""Response too long"")
+                return response.strip()
+            except Exception as e:
+                print(e)
+        raise Exception(""All models failed"")
 
 
 class OpenAITranslator(BaseTranslator):
",add retry to ollama translator,
3ca35f194e38438c5ce026df069a2a663706e8f8,high_level.py,"@@ -331,13 +331,12 @@ def translate(
             try:
                 r = requests.get(file, allow_redirects=True)
                 if r.status_code == 200:
-                    if not os.path.exists(""./pdf2zh_files""):
-                        print(""Making a temporary dir for downloading PDF files..."")
-                        os.mkdir(os.path.dirname(""./pdf2zh_files""))
-                    with open(""./pdf2zh_files/tmp_download.pdf"", ""wb"") as f:
+                    with tempfile.NamedTemporaryFile(
+                        suffix="".pdf"", delete=False
+                    ) as tmp_file:
                         print(f""Writing the file: {file}..."")
-                        f.write(r.content)
-                    file = ""./pdf2zh_files/tmp_download.pdf""
+                        tmp_file.write(r.content)
+                        file = tmp_file.name
                 else:
                     r.raise_for_status()
             except Exception as e:
@@ -349,13 +348,21 @@ def translate(
         # If the commandline has specified converting to PDF/A format
         # --compatible / -cp
         if compatible:
-            file_pdfa = file.replace("".pdf"", ""-pdfa.pdf"")
-            print(f""Converting {file} to PDF/A format..."")
-            convert_to_pdfa(file, file_pdfa)
-            doc_raw = open(file_pdfa, ""rb"")
+            with tempfile.NamedTemporaryFile(
+                suffix=""-pdfa.pdf"", delete=False
+            ) as tmp_pdfa:
+                print(f""Converting {file} to PDF/A format..."")
+                convert_to_pdfa(file, tmp_pdfa.name)
+                doc_raw = open(tmp_pdfa.name, ""rb"")
+                os.unlink(tmp_pdfa.name)
         else:
             doc_raw = open(file, ""rb"")
         s_raw = doc_raw.read()
+        doc_raw.close()
+
+        if file.startswith(tempfile.gettempdir()):
+            os.unlink(file)
+
         s_mono, s_dual = translate_stream(
             s_raw,
             envs=kwarg.get(""envs"", {}),
@@ -368,7 +375,8 @@ def translate(
         doc_dual = open(file_dual, ""wb"")
         doc_mono.write(s_mono)
         doc_dual.write(s_dual)
+        doc_mono.close()
+        doc_dual.close()
         result_files.append((str(file_mono), str(file_dual)))
 
     return result_files
-    return result_files
",add support for --compatible option in -pdfa,
ae573e225569fafb0bb8685f5ea7b3fe38818c53,high_level.py,"@@ -206,6 +206,8 @@ def translate_stream(
         font_list.append((""china-ss"", None))
 
     doc_en = Document(stream=stream)
+    stream = io.BytesIO()
+    doc_en.save(stream)
     doc_zh = Document(stream=stream)
     page_count = doc_zh.page_count
     # font_list = [(""china-ss"", None), (""tiro"", None)]
",update translate_stream.py,
58e2a1ed6e6c3cb1b93ea7632e7382748a38d070,converter.py,"@@ -278,7 +278,7 @@ class TranslateConverter(PDFConverterEx):
                         pstk.append(Paragraph(child.y0, child.x0, child.x0, child.x0, child.size, False))
                 if not cur_v:                                               # 文字入栈
                     if (                                                    # 根据当前字符修正段落属性
-                        child.size > pstk[-1].size / 0.79                   # 1. 当前字符显著比段落字体大
+                        child.size > pstk[-1].size                          # 1. 当前字符显著比段落字体大
                         or len(sstk[-1].strip()) == 1                       # 2. 当前字符为段落第二个文字（考虑首字母放大的情况）
                     ) and child.get_text() != "" "":                          # 3. 当前字符不是空格
                         pstk[-1].y -= child.size - pstk[-1].size            # 修正段落初始纵坐标，假设两个不同大小字符的上边界对齐
",add support for 当前字符为正段落字符二三标，假设三标，假设三标，假设三标，假设位�,
3568ff2cb801047e399c70bb445075a714bea421,python-build.yml,"@@ -16,7 +16,7 @@ jobs:
     - uses: actions/checkout@v4
     - name: Install dependencies
       run: |
-        uv pip install -e .[dev]
+        uv pip install --system -e .[dev]
 
     - name: Test - Code format
       run: |
",add missing line to description,
cb330b4368966f5188e02634b553f8f250dc7adb,python-build.yml,"@@ -9,15 +9,16 @@ jobs:
     runs-on: ubuntu-latest
 
     steps:
-    - name: Install the latest version of uv
-      uses: astral-sh/setup-uv@v4
-      with:
-        version: ""latest""
     - uses: actions/checkout@v4
+    - name: Set up Python
+      uses: actions/setup-python@v3
+      with:
+        python-version: '3.x'
+
     - name: Install dependencies
       run: |
-        uv venv
-        uv pip install -e .[dev]
+        pip3 install -U pip
+        pip3 install -e .[dev]
 
     - name: Test - Code format
       run: |
",add more info to the latest test,
b4b86d38e40c4363de591cf022a742696c96be7d,cache.py,"@@ -41,8 +41,7 @@ class TranslationCache:
     def __init__(self, translate_engine, translate_engine_params):
         self.translate_engine = translate_engine
         if not isinstance(translate_engine_params, str):
-            if isinstance(translate_engine_params, dict):
-                translate_engine_params = self._sort_dict_recursively(translate_engine_params)
+            translate_engine_params = self._sort_dict_recursively(translate_engine_params)
             translate_engine_params = json.dumps(translate_engine_params)
         self.translate_engine_params = translate_engine_params
 
",add missing type check,
03fd17589917fae1edeb098677df10e81f95a67b,cache.py,"@@ -57,14 +57,14 @@ class TranslationCache:
         self.params = params
         params = self._sort_dict_recursively(params)
         self.translate_engine_params = json.dumps(params)
-    
+
     def update_params(self, params: dict = None):
         if params is None:
             params = {}
         self.params.update(params)
         self.replace_params(self.params)
 
-    def append_params(self, k: str, v):
+    def add_params(self, k: str, v):
         self.params[k] = v
         self.replace_params(self.params)
 
",update translation cache,
03fd17589917fae1edeb098677df10e81f95a67b,test_cache.py,"@@ -138,7 +138,7 @@ class TestCache(unittest.TestCase):
         cache_instance = cache.TranslationCache(""test_engine"", {""initial"": ""value""})
 
         # Test appending new parameter
-        cache_instance.append_params(""new_param"", ""new_value"")
+        cache_instance.add_params(""new_param"", ""new_value"")
         self.assertEqual(cache_instance.params, {""initial"": ""value"", ""new_param"": ""new_value""})
 
         # Test that cache with appended params works correctly
@@ -146,7 +146,7 @@ class TestCache(unittest.TestCase):
         self.assertEqual(cache_instance.get(""hello""), ""你好"")
 
         # Test overwriting existing parameter
-        cache_instance.append_params(""initial"", ""new_value"")
+        cache_instance.add_params(""initial"", ""new_value"")
         self.assertEqual(cache_instance.params, {""initial"": ""new_value"", ""new_param"": ""new_value""})
 
         # Cache should work with updated params
",add more tests for cache.append_params,
c11eeb45e5eac25aaa8cae8195af4ae9d88dd509,translator.py,"@@ -46,9 +46,6 @@ class BaseTranslator:
             }
         )
 
-        if self.envs:
-            self.cache.update_params(self.envs)
-
     def set_envs(self, envs):
         # Detach from self.__class__.envs
         # Cannot use self.envs = copy(self.__class__.envs)
@@ -61,9 +58,6 @@ class BaseTranslator:
             for key in envs:
                 self.envs[key] = envs[key]
 
-        if getattr(self, 'cache', None) is not None:
-            self.cache.update_params(self.envs)
-
     def add_cache_impact_parameters(self, k: str, v):
         """"""
         Add parameters that affect the translation quality to distinguish the translation effects under different parameters.
@@ -83,7 +77,9 @@ class BaseTranslator:
             if cache is not None:
                 return cache
 
-        return self.do_translate(text)
+        translation = self.do_translate(text)
+        self.cache.set(text, translation)
+        return translation
 
     def do_translate(self, text):
         """"""
",add missing docstrings,
ddf54268c45f158efc7ef732b50a4d3c2217fac6,translator.py,"@@ -78,7 +78,8 @@ class BaseTranslator:
                 return cache
 
         translation = self.do_translate(text)
-        self.cache.set(text, translation)
+        if not self.ignore_cache:
+            self.cache.set(text, translation)
         return translation
 
     def do_translate(self, text):
",fix cache bug,
ba39fd53a041b84c58bda5d1559885cbf0aa357e,translator.py,"@@ -88,7 +88,7 @@ class BaseTranslator:
         :param text: text to translate
         :return: translated text
         """"""
-        pass
+        raise NotImplementedError
 
     def prompt(self, text, prompt):
         if prompt:
",add missing docstring,
97e9a90c31292fb9b898707439a017f0b33bfcbc,test_translator.py,"@@ -67,6 +67,11 @@ class TestTranslator(unittest.TestCase):
         another_result = translator.translate(text)
         self.assertNotEqual(second_result, another_result)
 
+    def test_base_translator_throw(self):
+        translator = BaseTranslator(""en"", ""zh"", ""test"")
+        with self.assertRaises(NotImplementedError):
+            translator.translate(""Hello World"")
+
 
 if __name__ == ""__main__"":
     unittest.main()
",add test for basetranslator,
f94c6e10477be3a45ff322ff281f77a547bd4ce1,gui.py,"@@ -89,12 +89,6 @@ if os.getenv(""PDF2ZH_DEMO""):
     client_key = os.getenv(""PDF2ZH_CLIENT_KEY"")
     server_key = os.getenv(""PDF2ZH_SERVER_KEY"")
 
-# Check if everything unconfigured
-if os.getenv(""PDF2ZH_INIT"") is not False:
-    service_map = {
-        ""Google"": GoogleTranslator,
-    }
-
 
 # Public demo control
 def verify_recaptcha(response):
",add support for pdf2zh_init,
4736d6fa4c7c4c9c98415d9abaf24964c921d11b,pyproject.toml,"@@ -29,6 +29,7 @@ dependencies = [
     ""pdfminer.six>=20240706"",
     ""gradio_pdf>=0.0.21"",
     ""pikepdf"",
+    ""peewee>=3.17.8"",
     ""argostranslate"",
 ]
 
",add missing dependencies,
cac001926adbd8b52592799989b243c742240f2c,high_level.py,"@@ -234,7 +234,7 @@ def translate_stream(
 
     fp = io.BytesIO()
     doc_zh.save(fp)
-    obj_patch: dict = translate_patch(fp, prompt=kwarg[""prompt""], **locals())
+    obj_patch: dict = translate_patch(fp, **locals())
 
     for obj_id, ops_new in obj_patch.items():
         # ops_old=doc_en.xref_stream(obj_id)
",update docutils.py,
90accb003e3b43ddad490546a42c6002f1e1d9f6,backend.py,"@@ -6,6 +6,9 @@ from pdf2zh import translate_stream
 import tqdm
 import json
 import io
+from pdf2zh.doclayout import OnnxModel
+
+model = OnnxModel.load_available()
 
 flask_app = Flask(""pdf2zh"")
 flask_app.config.from_mapping(
@@ -15,7 +18,6 @@ flask_app.config.from_mapping(
     )
 )
 
-
 def celery_init_app(app: Flask) -> Celery:
     class FlaskTask(Task):
         def __call__(self, *args, **kwargs):
@@ -47,6 +49,7 @@ def translate_task(
     doc_mono, doc_dual = translate_stream(
         stream,
         callback=progress_bar,
+        model=model,
         **args,
     )
     return doc_mono, doc_dual
",add missing celery task,
3e47b8d32e47086b0fdfc2dd073704aa9ad6f691,backend.py,"@@ -6,9 +6,7 @@ from pdf2zh import translate_stream
 import tqdm
 import json
 import io
-from pdf2zh.doclayout import OnnxModel
-
-model = OnnxModel.load_available()
+from pdf2zh.pdf2zh import model
 
 flask_app = Flask(""pdf2zh"")
 flask_app.config.from_mapping(
@@ -18,6 +16,7 @@ flask_app.config.from_mapping(
     )
 )
 
+
 def celery_init_app(app: Flask) -> Celery:
     class FlaskTask(Task):
         def __call__(self, *args, **kwargs):
",add missing task,
3e47b8d32e47086b0fdfc2dd073704aa9ad6f691,gui.py,"@@ -13,6 +13,7 @@ from gradio_pdf import PDF
 
 from pdf2zh import __version__
 from pdf2zh.high_level import translate
+from pdf2zh.pdf2zh import model
 from pdf2zh.translator import (
     AnythingLLMTranslator,
     AzureOpenAITranslator,
@@ -265,6 +266,7 @@ def translate_file(
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
         ""prompt"": prompt,
+        ""model"": model,
     }
     try:
         translate(**param)
",add missing import,
3e47b8d32e47086b0fdfc2dd073704aa9ad6f691,pdf2zh.py,"@@ -199,6 +199,9 @@ def find_all_files_in_directory(directory_path):
     return file_paths
 
 
+model = None
+
+
 def main(args: Optional[List[str]] = None) -> int:
     logging.basicConfig()
 
@@ -206,6 +209,11 @@ def main(args: Optional[List[str]] = None) -> int:
 
     if parsed_args.debug:
         log.setLevel(logging.DEBUG)
+    global model
+    if parsed_args.onnx:
+        model = OnnxModel(parsed_args.onnx)
+    else:
+        model = OnnxModel.load_available()
 
     if parsed_args.interactive:
         from pdf2zh.gui import setup_gui
@@ -238,12 +246,6 @@ def main(args: Optional[List[str]] = None) -> int:
         except Exception:
             raise ValueError(""prompt error."")
 
-    model = None
-    if parsed_args.onnx:
-        model = OnnxModel(parsed_args.onnx)
-    else:
-        model = OnnxModel.load_available()
-
     if parsed_args.dir:
         untranlate_file = find_all_files_in_directory(parsed_args.files[0])
         parsed_args.files = untranlate_file
",add new untranlate script,
88d85e4df588cecfa332aa4bcc2dba3b567a3e82,cache.py,"@@ -45,6 +45,7 @@ class TranslationCache:
         return obj
 
     def __init__(self, translate_engine: str, translate_engine_params: dict = None):
+        assert len(translate_engine) < 20, 'current cache require translate engine name less than 20 characters'
         self.translate_engine = translate_engine
         self.replace_params(translate_engine_params)
 
",add missing parameter to translationcache,
7850d321aa867e8813b99e78857f0959d50fc372,test_translator.py,"@@ -50,17 +50,17 @@ class TestTranslator(unittest.TestCase):
         self.assertNotEqual(first_result, second_result)
 
         # Test cache with ignore_cache=True
-        no_cache_result = translator.translate(text, ignore_cache=True)
-        self.assertNotEqual(first_result, no_cache_result)
+        no_cache_result1 = translator.translate(text, ignore_cache=True)
+        self.assertNotEqual(first_result, no_cache_result1)
 
         translator.ignore_cache = True
-        no_cache_result = translator.translate(text)
-        self.assertNotEqual(first_result, no_cache_result)
+        no_cache_result2 = translator.translate(text)
+        self.assertNotEqual(no_cache_result1, no_cache_result2)
 
         # Test cache with ignore_cache=False
         translator.ignore_cache = False
         cache_result = translator.translate(text)
-        self.assertEqual(second_result, cache_result)
+        self.assertEqual(no_cache_result2, cache_result)
 
         # Test cache with another parameter
         translator.add_cache_impact_parameters(""test2"", ""value2"")
",add tests for ignore_cache=true and ignore_cache=false,
05ac241d488a5fca373c2de3eaf99a2e9f0e1035,ADVANCED.md,"@@ -96,7 +96,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 Preserve `Latex`, `Mono`, `Code`, `Italic`, `Symbol` and `Math` fonts by default:
 
 ```bash
-pdf2zh example.pdf -f ""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
+pdf2zh example.pdf -f ""(CM[^R]|MS.M|XY|MT|BL|RM|EU|LA|RS|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
 ```
 
 [⬆️ Back to top](#toc)
",update example to use latest version,
05ac241d488a5fca373c2de3eaf99a2e9f0e1035,README_ja-JP.md,"@@ -252,7 +252,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 デフォルトで `Latex`、`Mono`、`Code`、`Italic`、`Symbol` および `Math` フォントを保持します：
 
 ```bash
-pdf2zh example.pdf -f ""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
+pdf2zh example.pdf -f ""(CM[^R]|MS.M|XY|MT|BL|RM|EU|LA|RS|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
 ```
 
 <h3 id=""threads"">スレッド数を指定</h3>
",add examples for the threads example,
05ac241d488a5fca373c2de3eaf99a2e9f0e1035,README_zh-CN.md,"@@ -252,7 +252,7 @@ pdf2zh example.pdf -f ""(CM[^RT].*|MS.*|.*Ital)"" -c ""(\(|\||\)|\+|=|\d|[\u0080-\u
 默认保留 `Latex`, `Mono`, `Code`, `Italic`, `Symbol` 以及 `Math` 字体：
 
 ```bash
-pdf2zh example.pdf -f ""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
+pdf2zh example.pdf -f ""(CM[^R]|MS.M|XY|MT|BL|RM|EU|LA|RS|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)""
 ```
 
 <h3 id=""threads"">指定线程数量</h3>
",add examples for 指定线程数量,
05ac241d488a5fca373c2de3eaf99a2e9f0e1035,converter.py,"@@ -189,7 +189,7 @@ class TranslateConverter(PDFConverterEx):
                     return True
             else:
                 if re.match(                                            # latex 字体
-                    r""(CM[^R]|(MS|XY|MT|BL|RM|EU|LA|RS)[A-Z]|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
+                    r""(CM[^R]|MS.M|XY|MT|BL|RM|EU|LA|RS|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)"",
                     font,
                 ):
                     return True
@@ -278,7 +278,7 @@ class TranslateConverter(PDFConverterEx):
                         pstk.append(Paragraph(child.y0, child.x0, child.x0, child.x0, child.size, False))
                 if not cur_v:                                               # 文字入栈
                     if (                                                    # 根据当前字符修正段落属性
-                        child.size > pstk[-1].size / 0.79                   # 1. 当前字符显著比段落字体大
+                        child.size > pstk[-1].size                          # 1. 当前字符比段落字体大
                         or len(sstk[-1].strip()) == 1                       # 2. 当前字符为段落第二个文字（考虑首字母放大的情况）
                     ) and child.get_text() != "" "":                          # 3. 当前字符不是空格
                         pstk[-1].y -= child.size - pstk[-1].size            # 修正段落初始纵坐标，假设两个不同大小字符的上边界对齐
",add support for 字符为段落符二个文字（而文字）,
71107a4ea84f9a69727a778b730c592819c2730b,converter.py,"@@ -36,6 +36,9 @@ from pdf2zh.translator import (
     AnythingLLMTranslator,
     XinferenceTranslator,
     ArgosTranslator,
+    GorkTranslator,
+    DeepseekTranslator,
+    OpenAIlikedTranslator,
 )
 from pymupdf import Font
 
@@ -151,7 +154,8 @@ class TranslateConverter(PDFConverterEx):
         service_name = param[0]
         service_model = param[1] if len(param) > 1 else None
         for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, XinferenceTranslator, AzureOpenAITranslator,
-                           OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator]:
+    OpenAIlikedTranslator,
+                           OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GorkTranslator, DeepseekTranslator,OpenAIlikedTranslator,]:
             if service_name == translator.name:
                 self.translator = translator(lang_in, lang_out, service_model, envs=envs, prompt=prompt)
         if not self.translator:
","add support for -151,7,15",
71107a4ea84f9a69727a778b730c592819c2730b,gui.py,"@@ -35,7 +35,7 @@ from pdf2zh.translator import (
     ZhipuTranslator,
     GorkTranslator,
     DeepseekTranslator,
-    OpenAIlikeTranslator,
+    OpenAIlikedTranslator,
 )
 
 # The following variables associate strings with translators
@@ -59,7 +59,7 @@ service_map: dict[str, BaseTranslator] = {
     ""Argos Translate"": ArgosTranslator,
     ""Gork"": GorkTranslator,
     ""DeepSeek"": DeepseekTranslator,
-    ""OpenAI-liked"": OpenAIlikeTranslator,
+    ""OpenAI-liked"": OpenAIlikedTranslator,
 }
 
 # The following variables associate strings with specific languages
",add service map for the zhipu translator,
71107a4ea84f9a69727a778b730c592819c2730b,high_level.py,"@@ -102,8 +102,8 @@ def translate_patch(
         service,
         resfont,
         noto,
-        kwarg.get(""envs"", {}),
-        kwarg.get(""prompt"", []),
+        kwarg[""kwarg""].get(""envs"", {}),
+        kwarg[""kwarg""].get(""prompt"", []),
     )
 
     assert device is not None
",add missing assertion,
71107a4ea84f9a69727a778b730c592819c2730b,translator.py,"@@ -744,42 +744,25 @@ class DeepseekTranslator(OpenAITranslator):
             self.add_cache_impact_parameters(""prompt"", prompt)
 
 
-class OpenAIlikeTranslator(BaseTranslator):
-    # https://github.com/openai/openai-python
-    name = ""openai-liked""
+class OpenAIlikedTranslator(OpenAITranslator):
+    name = ""openailiked""
     envs = {
-        ""OPENAILIKE_BASE_URL"": None,
-        ""OPENAILIKE_API_KEY"": None,
-        ""OPENAILIKE_MODEL"": None,
+        ""OPENAILIKED_BASE_URL"": None,
+        ""OPENAILIKED_API_KEY"": None,
+        ""OPENAILIKED_MODEL"": None,
     }
     CustomPrompt = True
 
-    def __init__(
-        self,
-        lang_in,
-        lang_out,
-        model,
-        base_url=None,
-        api_key=None,
-        envs=None,
-        prompt=None,
-    ):
+    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
         self.set_envs(envs)
+        base_url = self.envs[""OPENAILIKED_BASE_URL""]
         if not model:
-            model = self.envs[""OPENAILIKE_MODEL""]
-        super().__init__(lang_in, lang_out, model)
-        self.options = {""temperature"": 0}  # 随机采样可能会打断公式标记
-        if (
-            self.envs[""OPENAILIKE_BASE_URL""] == None
-            or self.envs[""OPENAILIKE_API_KEY""] == None
-            or self.envs[""OPENAILIKE_MODEL""] == None
-        ):
-            raise ValueError(""The variables are invalid."")
-        self.client = openai.OpenAI(
-            base_url=base_url or self.envs[""OPENAILIKE_BASE_URL""],
-            api_key=api_key or self.envs[""OPENAILIKE_API_KEY""],
-        )
+            model = self.envs[""OPENAILIKED_MODEL""]
+        if self.envs[""OPENAILIKED_API_KEY""] is None:
+            api_key = ""openailiked""
+        else:
+            api_key = self.envs[""OPENAILIKED_API_KEY""]
+        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
         if prompt:
             self.add_cache_impact_parameters(""prompt"", prompt)
",add openailiked translator,
d057e1d97c0a9454b230ecbec7918e3564e62719,converter.py,"@@ -153,6 +153,10 @@ class TranslateConverter(PDFConverterEx):
         param = service.split("":"", 1)
         service_name = param[0]
         service_model = param[1] if len(param) > 1 else None
+        if not envs:
+            envs = {}
+        if not prompt:
+            prompt = []
         for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, XinferenceTranslator, AzureOpenAITranslator,
                            OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GorkTranslator, DeepseekTranslator, OpenAIlikedTranslator,]:
             if service_name == translator.name:
",add missing env and prompt,
d057e1d97c0a9454b230ecbec7918e3564e62719,high_level.py,"@@ -8,7 +8,7 @@ import tempfile
 import urllib.request
 from asyncio import CancelledError
 from pathlib import Path
-from typing import Any, BinaryIO, List, Optional
+from typing import Any, BinaryIO, List, Optional, Dict
 
 import numpy as np
 import requests
@@ -87,6 +87,8 @@ def translate_patch(
     callback: object = None,
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
+    envs: Dict = None,
+    prompt: List = None,
     **kwarg: Any,
 ) -> None:
     rsrcmgr = PDFResourceManager()
@@ -102,8 +104,8 @@ def translate_patch(
         service,
         resfont,
         noto,
-        kwarg[""kwarg""].get(""envs"", {}),
-        kwarg[""kwarg""].get(""prompt"", []),
+        envs,
+        prompt,
     )
 
     assert device is not None
@@ -179,6 +181,8 @@ def translate_stream(
     callback: object = None,
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
+    envs: Dict = None,
+    prompt: List = None,
     **kwarg: Any,
 ):
     font_list = [(""tiro"", None)]
@@ -313,6 +317,8 @@ def translate(
     compatible: bool = False,
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
+    envs: Dict = None,
+    prompt: List = None,
     **kwarg: Any,
 ):
     if not files:
@@ -367,8 +373,6 @@ def translate(
             os.unlink(file)
         s_mono, s_dual = translate_stream(
             s_raw,
-            envs=kwarg.get(""envs"", {}),
-            prompt=kwarg.get(""prompt"", []),
             **locals(),
         )
         file_mono = Path(output) / f""{filename}-mono.pdf""
",add docstrings for translate_stream and translate_patch,
d057e1d97c0a9454b230ecbec7918e3564e62719,translator.py,"@@ -254,8 +254,8 @@ class OllamaTranslator(BaseTranslator):
         self.client = ollama.Client()
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -297,8 +297,8 @@ class XinferenceTranslator(BaseTranslator):
         self.client = xinference_client.RESTfulClient(self.envs[""XINFERENCE_HOST""])
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -361,8 +361,8 @@ class OpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -406,8 +406,8 @@ class AzureOpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -444,8 +444,8 @@ class ModelScopeTranslator(OpenAITranslator):
             model = self.envs[""MODELSCOPE_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
 
 class ZhipuTranslator(OpenAITranslator):
@@ -465,8 +465,8 @@ class ZhipuTranslator(OpenAITranslator):
             model = self.envs[""ZHIPU_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text) -> str:
         try:
@@ -502,8 +502,8 @@ class SiliconTranslator(OpenAITranslator):
             model = self.envs[""SILICON_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
 
 class GeminiTranslator(OpenAITranslator):
@@ -523,8 +523,8 @@ class GeminiTranslator(OpenAITranslator):
             model = self.envs[""GEMINI_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
 
 class AzureTranslator(BaseTranslator):
@@ -602,8 +602,8 @@ class AnythingLLMTranslator(BaseTranslator):
             ""Content-Type"": ""application/json"",
         }
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
     def do_translate(self, text):
         messages = self.prompt(text, self.prompttext)
@@ -720,8 +720,8 @@ class GorkTranslator(OpenAITranslator):
             model = self.envs[""GORK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
 
 class DeepseekTranslator(OpenAITranslator):
@@ -740,8 +740,8 @@ class DeepseekTranslator(OpenAITranslator):
             model = self.envs[""DEEPSEEK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
 
 
 class OpenAIlikedTranslator(OpenAITranslator):
@@ -770,5 +770,5 @@ class OpenAIlikedTranslator(OpenAITranslator):
             api_key = self.envs[""OPENAILIKED_API_KEY""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt)
+        # if prompt:
+        #     self.add_cache_impact_parameters(""prompt"", prompt)
",add more translations,
69cd4dad3ae41351009c13f5e20d8f487c6b8d62,translator.py,"@@ -254,8 +254,8 @@ class OllamaTranslator(BaseTranslator):
         self.client = ollama.Client()
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -297,8 +297,8 @@ class XinferenceTranslator(BaseTranslator):
         self.client = xinference_client.RESTfulClient(self.envs[""XINFERENCE_HOST""])
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -361,8 +361,8 @@ class OpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -406,8 +406,8 @@ class AzureOpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -444,8 +444,8 @@ class ModelScopeTranslator(OpenAITranslator):
             model = self.envs[""MODELSCOPE_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class ZhipuTranslator(OpenAITranslator):
@@ -465,8 +465,8 @@ class ZhipuTranslator(OpenAITranslator):
             model = self.envs[""ZHIPU_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         try:
@@ -502,8 +502,8 @@ class SiliconTranslator(OpenAITranslator):
             model = self.envs[""SILICON_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class GeminiTranslator(OpenAITranslator):
@@ -523,8 +523,8 @@ class GeminiTranslator(OpenAITranslator):
             model = self.envs[""GEMINI_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class AzureTranslator(BaseTranslator):
@@ -602,8 +602,8 @@ class AnythingLLMTranslator(BaseTranslator):
             ""Content-Type"": ""application/json"",
         }
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         messages = self.prompt(text, self.prompttext)
@@ -720,8 +720,8 @@ class GorkTranslator(OpenAITranslator):
             model = self.envs[""GORK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class DeepseekTranslator(OpenAITranslator):
@@ -740,8 +740,8 @@ class DeepseekTranslator(OpenAITranslator):
             model = self.envs[""DEEPSEEK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class OpenAIlikedTranslator(OpenAITranslator):
@@ -770,5 +770,5 @@ class OpenAIlikedTranslator(OpenAITranslator):
             api_key = self.envs[""OPENAILIKED_API_KEY""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        # if prompt:
-        #     self.add_cache_impact_parameters(""prompt"", prompt)
+        if prompt:
+            self.add_cache_impact_parameters(""prompt"", prompt.template)
",add more translations,
09726b46eb25b1d5800ab3733cc070e55171b25a,backend.py,"@@ -6,7 +6,7 @@ from pdf2zh import translate_stream
 import tqdm
 import json
 import io
-from pdf2zh.pdf2zh import model
+from pdf2zh.doclayout import ModelInstance
 
 flask_app = Flask(""pdf2zh"")
 flask_app.config.from_mapping(
@@ -48,7 +48,7 @@ def translate_task(
     doc_mono, doc_dual = translate_stream(
         stream,
         callback=progress_bar,
-        model=model,
+        model=ModelInstance.value,
         **args,
     )
     return doc_mono, doc_dual
",add missing doc_nolist,
09726b46eb25b1d5800ab3733cc070e55171b25a,doclayout.py,"@@ -60,6 +60,7 @@ class YoloBox:
 
 
 class OnnxModel(DocLayoutModel):
+
     def __init__(self, model_path: str):
         self.model_path = model_path
 
@@ -173,3 +174,7 @@ class OnnxModel(DocLayoutModel):
             (new_h, new_w), preds[..., :4], (orig_h, orig_w)
         )
         return [YoloResult(boxes=preds, names=self._names)]
+
+
+class ModelInstance:
+    value: OnnxModel = None
",add docstrings for onnx model,
09726b46eb25b1d5800ab3733cc070e55171b25a,gui.py,"@@ -13,7 +13,7 @@ from gradio_pdf import PDF
 
 from pdf2zh import __version__
 from pdf2zh.high_level import translate
-from pdf2zh.pdf2zh import model
+from pdf2zh.doclayout import ModelInstance
 from pdf2zh.translator import (
     AnythingLLMTranslator,
     AzureOpenAITranslator,
@@ -274,7 +274,7 @@ def translate_file(
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
         ""prompt"": prompt,
-        ""model"": model,
+        ""model"": ModelInstance.value,
     }
     try:
         translate(**param)
",add missing import,
09726b46eb25b1d5800ab3733cc070e55171b25a,pdf2zh.py,"@@ -13,7 +13,7 @@ from typing import List, Optional
 
 from pdf2zh import __version__, log
 from pdf2zh.high_level import translate
-from pdf2zh.doclayout import OnnxModel
+from pdf2zh.doclayout import OnnxModel, ModelInstance
 import os
 
 
@@ -199,9 +199,6 @@ def find_all_files_in_directory(directory_path):
     return file_paths
 
 
-model = None
-
-
 def main(args: Optional[List[str]] = None) -> int:
     logging.basicConfig()
 
@@ -209,11 +206,11 @@ def main(args: Optional[List[str]] = None) -> int:
 
     if parsed_args.debug:
         log.setLevel(logging.DEBUG)
-    global model
+
     if parsed_args.onnx:
-        model = OnnxModel(parsed_args.onnx)
+        ModelInstance.value = OnnxModel(parsed_args.onnx)
     else:
-        model = OnnxModel.load_available()
+        ModelInstance.value = OnnxModel.load_available()
 
     if parsed_args.interactive:
         from pdf2zh.gui import setup_gui
@@ -250,10 +247,10 @@ def main(args: Optional[List[str]] = None) -> int:
         untranlate_file = find_all_files_in_directory(parsed_args.files[0])
         parsed_args.files = untranlate_file
         print(parsed_args)
-        translate(model=model, **vars(parsed_args))
+        translate(model=ModelInstance.value, **vars(parsed_args))
         return 0
     # print(parsed_args)
-    translate(model=model, **vars(parsed_args))
+    translate(model=ModelInstance.value, **vars(parsed_args))
     return 0
 
 
",add docstrings for translate,
7ed13c2983a84fdf1396780714ed0789306d7fa9,pyproject.toml,"@@ -32,6 +32,7 @@ dependencies = [
     ""pikepdf"",
     ""peewee>=3.17.8"",
     ""argostranslate"",
+    ""fontTools""
 ]
 
 [project.optional-dependencies]
",add missing dependencies,
720be55a8c40796b99c80bc909945cb7f8021270,python-build.yml,"@@ -33,11 +33,11 @@ jobs:
 
     - name: Test - Translate a PDF file with plain text only
       run:
-        pdf2zh ./test/file/translate.cli.plain.text.pdf
+        pdf2zh ./test/file/translate.cli.plain.text.pdf -o ./test/file
 
     - name: Test - Translate a PDF file figure
       run:
-        pdf2zh ./test/file/translate.cli.text.with.figure.pdf
+        pdf2zh ./test/file/translate.cli.text.with.figure.pdf -o ./test/file
 
     # - name: Test - Translate a PDF file with unknown font
     #   run:
",add missing jobs,
4cf8eec2f8dd27a6a149ba83ea4c4d7c27dc4507,converter.py,"@@ -188,7 +188,10 @@ class TranslateConverter(PDFConverterEx):
 
         def vflag(font: str, char: str):    # 匹配公式（和角标）字体
             if isinstance(font, bytes):     # 不一定能 decode，直接转 str
-                font = str(font)
+                try:
+                    font = font.decode('utf-8')  # 尝试使用 UTF-8 解码
+                except UnicodeDecodeError:
+                    font = """"
             font = font.split(""+"")[-1]      # 字体名截断
             if re.match(r""\(cid:"", char):
                 return True
",add support for unicode font,
2b3734e4ccd62e4272a2cbc521d81e1b1b5ab917,config.py,"@@ -1,15 +1,17 @@
 import json
 from pathlib import Path
-from threading import Lock
+from threading import RLock  # 改成 RLock
 import os
+import copy
 
 class ConfigManager:
     _instance = None
-    _lock = Lock()  # 用于线程安全
+    _lock = RLock()  # 用 RLock 替换 Lock，允许在同一个线程中重复获取锁
 
     @classmethod
     def get_instance(cls):
         """"""获取单例实例""""""
+        # 先判断是否存在实例，如果不存在再加锁进行初始化
         if cls._instance is None:
             with cls._lock:
                 if cls._instance is None:
@@ -17,15 +19,21 @@ class ConfigManager:
         return cls._instance
 
     def __init__(self):
+        # 防止重复初始化
         if hasattr(self, ""_initialized"") and self._initialized:
-            return  # 防止重复初始化
+            return
         self._initialized = True
+
         self._config_path = Path.home() / "".config"" / ""PDFMathTranslate"" / ""config.json""
         self._config_data = {}
+
+        # 这里不要再加锁，因为外层可能已经加了锁 (get_instance), RLock也无妨
         self._ensure_config_exists()
 
     def _ensure_config_exists(self, isInit=True):
         """"""确保配置文件存在，如果不存在则创建默认配置""""""
+        # 这里也不需要显式再次加锁，原因同上，方法体中再调用 _load_config()，
+        # 而 _load_config() 内部会加锁。因为 RLock 是可重入的，不会阻塞。
         if not self._config_path.exists():
             if isInit:
                 self._config_path.parent.mkdir(parents=True, exist_ok=True)
@@ -37,14 +45,35 @@ class ConfigManager:
             self._load_config()
 
     def _load_config(self):
-        """"""从config.json中加载配置""""""
-        with self._config_path.open(""r"", encoding=""utf-8"") as f:
-            self._config_data = json.load(f)
+        """"""从 config.json 中加载配置""""""
+        with self._lock:  # 加锁确保线程安全
+            with self._config_path.open(""r"", encoding=""utf-8"") as f:
+                self._config_data = json.load(f)
 
     def _save_config(self):
-        """"""保存配置到config.json""""""
-        with self._config_path.open(""w"", encoding=""utf-8"") as f:
-            json.dump(self._config_data, f, indent=4, ensure_ascii=False)
+        """"""保存配置到 config.json""""""
+        with self._lock:  # 加锁确保线程安全
+            # 移除循环引用并写入
+            cleaned_data = self._remove_circular_references(self._config_data)
+            with self._config_path.open(""w"", encoding=""utf-8"") as f:
+                json.dump(cleaned_data, f, indent=4, ensure_ascii=False)
+
+    def _remove_circular_references(self, obj, seen=None):
+        """"""递归移除循环引用""""""
+        if seen is None:
+            seen = set()
+        obj_id = id(obj)
+        if obj_id in seen:
+            return None  # 遇到已处理过的对象，视为循环引用
+        seen.add(obj_id)
+
+        if isinstance(obj, dict):
+            return {
+                k: self._remove_circular_references(v, seen) for k, v in obj.items()
+            }
+        elif isinstance(obj, list):
+            return [self._remove_circular_references(i, seen) for i in obj]
+        return obj
 
     @classmethod
     def custome_config(cls, file_path):
@@ -52,10 +81,11 @@ class ConfigManager:
         custom_path = Path(file_path)
         if not custom_path.exists():
             raise ValueError(f""Config file {custom_path} not found!"")
-        # 销毁现有的实例并重新初始化
+        # 加锁
         with cls._lock:
             instance = cls()
             instance._config_path = custom_path
+            # 此处传 isInit=False，若不存在则报错；若存在则正常 _load_config()
             instance._ensure_config_exists(isInit=False)
             cls._instance = instance
 
@@ -63,29 +93,35 @@ class ConfigManager:
     def get(cls, key, default=None):
         """"""获取配置值""""""
         instance = cls.get_instance()
-        ret = instance._config_data.get(key)
-        if not ret:
-            env_get = os.environ.get(key)
-            if not env_get:
-                if not default:
-                    raise ValueError(f""{key} is not found in environment or config file."")
-                else:
-                    instance._config_data[key] = default
-                    instance._save_config()
-                    return default
-            else:
-                instance._config_data[key] = env_get
-                instance._save_config()
-                return env_get
-        else:
-            return ret
+        # 读取时，加锁或不加锁都行。但为了统一，我们在修改配置前后都要加锁。
+        # get 只要最终需要保存，则会加锁 -> _save_config()
+        if key in instance._config_data:
+            return instance._config_data[key]
+
+        # 若环境变量中存在该 key，则使用环境变量并写回 config
+        if key in os.environ:
+            value = os.environ[key]
+            instance._config_data[key] = value
+            instance._save_config()
+            return value
+
+        # 若 default 不为 None，则设置并保存
+        if default is not None:
+            instance._config_data[key] = default
+            instance._save_config()
+            return default
+
+        # 找不到则抛出异常
+        # raise KeyError(f""{key} is not found in config file or environment variables."")
+        return default
 
     @classmethod
     def set(cls, key, value):
         """"""设置配置值并保存""""""
         instance = cls.get_instance()
-        instance._config_data[key] = value
-        instance._save_config()
+        with instance._lock:
+            instance._config_data[key] = value
+            instance._save_config()
 
     @classmethod
     def get_translator_by_name(cls, name):
@@ -94,46 +130,63 @@ class ConfigManager:
         translators = instance._config_data.get(""translators"", [])
         for translator in translators:
             if translator.get(""name"") == name:
-                return translator
+                return translator[""envs""]
         return None
-    
+
     @classmethod
     def set_translator_by_name(cls, name, new_translator_envs):
         """"""根据 name 设置或更新 translator 配置""""""
         instance = cls.get_instance()
+        with instance._lock:
+            translators = instance._config_data.get(""translators"", [])
+            for translator in translators:
+                if translator.get(""name"") == name:
+                    translator[""envs""] = copy.deepcopy(new_translator_envs)
+                    instance._save_config()
+                    return
+            translators.append({""name"": name, ""envs"": copy.deepcopy(new_translator_envs)})
+            instance._config_data[""translators""] = translators
+            instance._save_config()
+
+    @classmethod
+    def get_env_by_translatername(cls, translater_name, name, default=None):
+        """"""根据 name 获取对应的 translator 配置""""""
+        instance = cls.get_instance()
         translators = instance._config_data.get(""translators"", [])
-        
         for translator in translators:
-            if translator.get(""name"") == name:
-                translator.update({""envs"": new_translator_envs})
-                instance._save_config()
-                return
-        
-        # 如果未找到匹配的 name，则添加新的 translator
-        translators.append({""name"": name, ""envs"": new_translator_envs})
-        instance._config_data[""translators""] = translators
-        instance._save_config()
-
+            if translator.get(""name"") == translater_name.name:
+                if translator[""envs""][name]:
+                    return translator[""envs""][name]
+                else:
+                    with instance._lock:
+                        translator[""envs""][name] = default
+                        instance._save_config()
+                        return default
+                    
+        with instance._lock:
+            translators = instance._config_data.get(""translators"", [])
+            for translator in translators:
+                if translator.get(""name"") == translater_name.name:
+                    translator[""envs""][name] = default
+                    instance._save_config()
+                    return default
+            translators.append({""name"": translater_name.name, ""envs"": copy.deepcopy(translater_name.envs)})
+            instance._config_data[""translators""] = translators
+            instance._save_config()
+            return default
 
     @classmethod
     def delete(cls, key):
         """"""删除配置值并保存""""""
         instance = cls.get_instance()
-        if key in instance._config_data:
-            del instance._config_data[key]
-            instance._save_config()
+        with instance._lock:
+            if key in instance._config_data:
+                del instance._config_data[key]
+                instance._save_config()
 
     @classmethod
     def all(cls):
         """"""返回所有配置项""""""
         instance = cls.get_instance()
+        # 这里只做读取操作，一般可不加锁。不过为了保险也可以加锁。
         return instance._config_data
-
-# 使用示例
-# 默认路径加载
-# ConfigManager.set(""username"", ""admin"")
-# print(ConfigManager.get(""username""))
-
-# 自定义路径加载
-# ConfigManager.custome_config(""/path/to/custom_config.json"")
-# print(ConfigManager.get(""custom_key""))
",add support for 全后线程一个线程中重复取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取斋取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取取斋取斋取揖取取取取取取取取取取取取取取取取取取取取取取取取取取取取取揖揖揖揖揖揖揖揖取 揖 揖 揖 揖 揖 揖 揖 揖 揖 揖 揖,
2b3734e4ccd62e4272a2cbc521d81e1b1b5ab917,gui.py,"@@ -448,7 +448,7 @@ with gr.Blocks(
                     _envs.append(gr.update(visible=False, value=""""))
                 for i, env in enumerate(translator.envs.items()):
                     _envs[i] = gr.update(
-                        visible=True, label=env[0], value=os.getenv(env[0], env[1])
+                        visible=True, label=env[0], value=ConfigManager.get_env_by_translatername(translator,env[0],env[1])
                     )
                 _envs[-1] = gr.update(visible=translator.CustomPrompt)
                 return _envs
",fix env update in translator.py,
2b3734e4ccd62e4272a2cbc521d81e1b1b5ab917,high_level.py,"@@ -24,6 +24,8 @@ from pdf2zh.converter import TranslateConverter
 from pdf2zh.doclayout import OnnxModel
 from pdf2zh.pdfinterp import PDFPageInterpreterEx
 
+from pdf2zh.config import ConfigManager
+
 NOTO_NAME = ""noto""
 
 noto_list = [
",add missing noto_name in doc,
2b3734e4ccd62e4272a2cbc521d81e1b1b5ab917,translator.py,"@@ -54,7 +54,7 @@ class BaseTranslator:
         # Cannot use self.envs = copy(self.__class__.envs)
         # because if set_envs called twice, the second call will override the first call
         self.envs = copy(self.envs)
-        if not ConfigManager.get_translator_by_name(self.name):
+        if ConfigManager.get_translator_by_name(self.name):
             self.envs = ConfigManager.get_translator_by_name(self.name)
         needUpdate=False
         for key in self.envs:
",fix typo in basetranslator.py,
5f24432a2babf513f9caddc245c84ff0e58a71f2,converter.py,"@@ -1,4 +1,5 @@
 from typing import Dict, List
+from enum import Enum
 
 from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
 from pdfminer.pdffont import PDFCIDFont
@@ -373,11 +374,11 @@ class TranslateConverter(PDFConverterEx):
                 return """".join([""%02x"" % ord(c) for c in cstk])
 
         # 根据目标语言获取默认行距
-        lang_space = {
+        LANG_LINEHEIGHT_MAP = {
             ""zh-cn"": 1.4, ""zh-tw"": 1.4, ""zh-hans"": 1.4, ""zh-hant"": 1.4, ""zh"": 1.4,
             ""ja"": 1.1, ""ko"": 1.2, ""en"": 1.2, ""ar"": 1.0, ""ru"": 0.8, ""uk"": 0.8, ""ta"": 0.8
         }
-        default_line_spacing = lang_space.get(self.translator.lang_out.lower(), 1.1)
+        default_line_height = LANG_LINEHEIGHT_MAP.get(self.translator.lang_out.lower(), 1.1) # 小语种默认1.1
 
         _x, _y = 0, 0
 
@@ -394,7 +395,7 @@ class TranslateConverter(PDFConverterEx):
             brk: bool = pstk[id].brk                    # 段落换行标记
             cstk: str = """"                              # 当前文字栈
             fcur: str = None                            # 当前字体 ID
-            line = 0                                    # 记录换行次数
+            lidx = 0                                    # 记录换行次数
             tx = x
             fcur_ = fcur
             ptr = 0
@@ -438,18 +439,18 @@ class TranslateConverter(PDFConverterEx):
                 ):
                     if cstk:
                         ops_vals.append({
-                            ""type"": ""text"",
+                            ""type"": OpType.TEXT,
                             ""font"": fcur,
                             ""size"": size,
                             ""x"": tx,
                             ""dy"": 0,
                             ""rtxt"": raw_string(fcur, cstk),
-                            ""line"": line
+                            ""lidx"": lidx
                         })
                         cstk = """"
                 if brk and x + adv > x1 + 0.1 * size:  # 到达右边界且原文段落存在换行
                     x = x0
-                    line += 1
+                    lidx += 1
                 if vy_regex:  # 插入公式
                     fix = 0
                     if fcur is not None:  # 段落内公式修正纵向偏移
@@ -457,13 +458,13 @@ class TranslateConverter(PDFConverterEx):
                     for vch in var[vid]:  # 排版公式字符
                         vc = chr(vch.cid)
                         ops_vals.append({
-                            ""type"": ""text"",
+                            ""type"": OpType.TEXT,
                             ""font"": self.fontid[vch.font],
                             ""size"": vch.size,
                             ""x"": x + vch.x0 - var[vid][0].x0,
                             ""dy"": fix + vch.y0 - var[vid][0].y0,
                             ""rtxt"": raw_string(self.fontid[vch.font], vc),
-                            ""line"": line
+                            ""lidx"": lidx
                         })
                         if log.isEnabledFor(logging.DEBUG):
                             lstk.append(LTLine(0.1, (_x, _y), (x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0)))
@@ -471,13 +472,13 @@ class TranslateConverter(PDFConverterEx):
                     for l in varl[vid]:  # 排版公式线条
                         if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
                             ops_vals.append({
-                                ""type"": ""formula"",
+                                ""type"": OpType.LINE,
                                 ""x"": l.pts[0][0] + x - var[vid][0].x0,
                                 ""dy"": l.pts[0][1] + fix - var[vid][0].y0,
                                 ""linewidth"": l.linewidth,
                                 ""xlen"": l.pts[1][0] - l.pts[0][0],
                                 ""ylen"": l.pts[1][1] - l.pts[0][1],
-                                ""line"": line
+                                ""lidx"": lidx
                             })
                 else:  # 插入文字缓冲区
                     if not cstk:  # 单行开头
@@ -497,26 +498,25 @@ class TranslateConverter(PDFConverterEx):
             # 处理结尾
             if cstk:
                 ops_vals.append({
-                    ""type"": ""text"",
+                    ""type"": OpType.TEXT,
                     ""font"": fcur,
                     ""size"": size,
                     ""x"": tx,
                     ""dy"": 0,
                     ""rtxt"": raw_string(fcur, cstk),
-                    ""line"": line
+                    ""lidx"": lidx
                 })
 
-            line_spacing = default_line_spacing
+            line_height = default_line_height
 
-            while (line + 1) * size * line_spacing > height and line_spacing >= 1:
-                line_spacing -= 0.05
+            while (lidx + 1) * size * line_height > height and line_height >= 1:
+                line_height -= 0.05
 
             for vals in ops_vals:
-                match vals[""type""]:
-                    case ""text"":
-                        ops_list.append(gen_op_txt(vals[""font""], vals[""size""], vals[""x""], vals[""dy""] + y - vals[""line""] * size * line_spacing, vals[""rtxt""]))
-                    case ""formula"":
-                        ops_list.append(gen_op_line(vals[""x""], vals[""dy""] + y - vals[""line""] * size * line_spacing, vals[""xlen""], vals[""ylen""], vals[""linewidth""]))
+                if vals[""type""] == OpType.TEXT:
+                    ops_list.append(gen_op_txt(vals[""font""], vals[""size""], vals[""x""], vals[""dy""] + y - vals[""lidx""] * size * line_height, vals[""rtxt""]))
+                elif vals[""type""] == OpType.LINE:
+                    ops_list.append(gen_op_line(vals[""x""], vals[""dy""] + y - vals[""lidx""] * size * line_height, vals[""xlen""], vals[""ylen""], vals[""linewidth""]))
 
         for l in lstk:  # 排版全局线条
             if l.linewidth < 5:  # hack 有的文档会用粗线条当图片背景
@@ -524,3 +524,7 @@ class TranslateConverter(PDFConverterEx):
 
         ops = f""BT {''.join(ops_list)}ET ""
         return ops
+
+class OpType(Enum):
+    TEXT = ""text""
+    LINE = ""line""
","add support for -373,11,7,7,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9",
696845e9add3c652c4d41f991a0e31c14630a5fc,config.py,"@@ -192,9 +192,23 @@ class ConfigManager:
                 del instance._config_data[key]
                 instance._save_config()
 
+    @classmethod
+    def clear(cls):
+        """"""删除配置值并保存""""""
+        instance = cls.get_instance()
+        with instance._lock:
+            instance._config_data={}
+            instance._save_config()
+
     @classmethod
     def all(cls):
         """"""返回所有配置项""""""
         instance = cls.get_instance()
         # 这里只做读取操作，一般可不加锁。不过为了保险也可以加锁。
         return instance._config_data
+    
+    @classmethod
+    def remove(cls):
+        instance = cls.get_instance()
+        with instance._lock:
+            os.remove(instance._config_path)
",add configmanager methods,
696845e9add3c652c4d41f991a0e31c14630a5fc,test_translator.py,"@@ -2,6 +2,7 @@ import unittest
 from pdf2zh.translator import BaseTranslator
 from pdf2zh.translator import OpenAIlikedTranslator
 from pdf2zh import cache
+from pdf2zh.config import ConfigManager
 
 
 class AutoIncreaseTranslator(BaseTranslator):
@@ -81,9 +82,11 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
             ""OPENAILIKED_API_KEY"": ""test_api_key"",
             ""OPENAILIKED_MODEL"": ""test_model"",
         }
+        ConfigManager.custome_config(""config.json"")
 
     def test_missing_base_url_raises_error(self):
         """"""测试缺失 OPENAILIKED_BASE_URL 时抛出异常""""""
+        ConfigManager.clear()
         with self.assertRaises(ValueError) as context:
             OpenAIlikedTranslator(
                 lang_in=""en"", lang_out=""zh"", model=""test_model"", envs={}
@@ -96,6 +99,7 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
             ""OPENAILIKED_BASE_URL"": ""https://api.openailiked.com"",
             ""OPENAILIKED_API_KEY"": ""test_api_key"",
         }
+        ConfigManager.clear()
         with self.assertRaises(ValueError) as context:
             OpenAIlikedTranslator(
                 lang_in=""en"", lang_out=""zh"", model=None, envs=envs_without_model
@@ -104,6 +108,7 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
 
     def test_initialization_with_valid_envs(self):
         """"""测试使用有效的环境变量初始化""""""
+        ConfigManager.clear()
         translator = OpenAIlikedTranslator(
             lang_in=""en"",
             lang_out=""zh"",
@@ -126,6 +131,7 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
             ""OPENAILIKED_BASE_URL"": ""https://api.openailiked.com"",
             ""OPENAILIKED_MODEL"": ""test_model"",
         }
+        ConfigManager.clear()
         translator = OpenAIlikedTranslator(
             lang_in=""en"",
             lang_out=""zh"",
",add tests for autoincrease,
e1b7cbcf7f7c4e744d27547b9dc8c96c0e819c15,test_translator.py,"@@ -82,7 +82,6 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
             ""OPENAILIKED_API_KEY"": ""test_api_key"",
             ""OPENAILIKED_MODEL"": ""test_model"",
         }
-        ConfigManager.custome_config(""config.json"")
 
     def test_missing_base_url_raises_error(self):
         """"""测试缺失 OPENAILIKED_BASE_URL 时抛出异常""""""
",add missing test,
59b676100cdeb7385d28ec9b4ca5cb556bca8b31,high_level.py,"@@ -312,7 +312,7 @@ def translate(
     result_files = []
 
     for file in files:
-        if file is str and (file.startswith(""http://"") or file.startswith(""https://"")):
+        if type(file) is str and (file.startswith(""http://"") or file.startswith(""https://"")):
             print(""Online files detected, downloading..."")
             try:
                 r = requests.get(file, allow_redirects=True)
",add download script,
6639e9eda415957f487dcb6fe223df715ad75270,gui.py,"@@ -10,6 +10,7 @@ import gradio as gr
 import requests
 import tqdm
 from gradio_pdf import PDF
+from string import Template
 
 from pdf2zh import __version__
 from pdf2zh.high_level import translate
@@ -276,7 +277,7 @@ def translate_file(
         ""callback"": progress_bar,
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
-        ""prompt"": prompt,
+        ""prompt"": Template(prompt),
         ""model"": ModelInstance.value,
     }
     try:
",add doc for translate_file,
b78cea10f7b03fa5a79d9c1bdf81bbf34b905884,converter.py,"@@ -377,7 +377,7 @@ class TranslateConverter(PDFConverterEx):
         # 根据目标语言获取默认行距
         LANG_LINEHEIGHT_MAP = {
             ""zh-cn"": 1.4, ""zh-tw"": 1.4, ""zh-hans"": 1.4, ""zh-hant"": 1.4, ""zh"": 1.4,
-            ""ja"": 1.1, ""ko"": 1.2, ""en"": 1.2, ""ar"": 1.0, ""ru"": 0.8, ""uk"": 0.8, ""ta"": 0.8
+            ""ja"": 1.4, ""ko"": 1.2, ""en"": 1.2, ""ar"": 1.0, ""ru"": 0.8, ""uk"": 0.8, ""ta"": 0.8
         }
         default_line_height = LANG_LINEHEIGHT_MAP.get(self.translator.lang_out.lower(), 1.1) # 小语种默认1.1
         _x, _y = 0, 0
",add support for english language lines,
c7172c8d9021e9006cd59d46078efb356cc9f6a9,pyproject.toml,"@@ -33,7 +33,7 @@ dependencies = [
     ""peewee>=3.17.8"",
     ""argostranslate"",
     ""fontTools"",
-    ""yadt>=0.0.1a15"",
+    ""yadt>=0.0.1a15, <0.0.2"",
 ]
 
 [project.optional-dependencies]
",add missing dependencies,
e53fb51bba6aa47515be62cd1b3397126757f5b8,python-build.yml,"@@ -13,7 +13,7 @@ jobs:
     - name: Set up Python
       uses: actions/setup-python@v5
       with:
-        python-version: '3.12' # avoid bugs in new versions
+        python-version: '3.11' # avoid bugs in new versions
         cache: 'pip'
         cache-dependency-path: pyproject.toml
 
",add missing line to error message,
167b3666d5aeb0ce247126f03931f6923a83a7b1,converter.py,"@@ -1,4 +1,4 @@
-from typing import Dict, List
+from typing import Dict
 from enum import Enum
 
 from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
@@ -17,6 +17,7 @@ import re
 import concurrent.futures
 import numpy as np
 import unicodedata
+from string import Template
 from tenacity import retry, wait_fixed
 from pdf2zh.translator import (
     AzureOpenAITranslator,
@@ -144,7 +145,7 @@ class TranslateConverter(PDFConverterEx):
         noto_name: str = """",
         noto: Font = None,
         envs: Dict = None,
-        prompt: List = None,
+        prompt: Template = None,
     ) -> None:
         super().__init__(rsrcmgr)
         self.vfont = vfont
@@ -159,8 +160,6 @@ class TranslateConverter(PDFConverterEx):
         service_model = param[1] if len(param) > 1 else None
         if not envs:
             envs = {}
-        if not prompt:
-            prompt = []
         for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, XinferenceTranslator, AzureOpenAITranslator,
                            OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GorkTranslator, GroqTranslator, DeepseekTranslator, OpenAIlikedTranslator,]:
             if service_name == translator.name:
",add translate converter,
167b3666d5aeb0ce247126f03931f6923a83a7b1,gui.py,"@@ -277,7 +277,7 @@ def translate_file(
         ""callback"": progress_bar,
         ""cancellation_event"": cancellation_event_map[session_id],
         ""envs"": _envs,
-        ""prompt"": Template(prompt),
+        ""prompt"": Template(prompt) if prompt else None,
         ""model"": ModelInstance.value,
     }
     try:
",add missing missing tag,
167b3666d5aeb0ce247126f03931f6923a83a7b1,high_level.py,"@@ -8,6 +8,7 @@ import tempfile
 import urllib.request
 from asyncio import CancelledError
 from pathlib import Path
+from string import Template
 from typing import Any, BinaryIO, List, Optional, Dict
 
 import numpy as np
@@ -78,7 +79,7 @@ def translate_patch(
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
     envs: Dict = None,
-    prompt: List = None,
+    prompt: Template = None,
     **kwarg: Any,
 ) -> None:
     rsrcmgr = PDFResourceManager()
@@ -172,7 +173,7 @@ def translate_stream(
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
     envs: Dict = None,
-    prompt: List = None,
+    prompt: Template = None,
     **kwarg: Any,
 ):
     font_list = [(""tiro"", None)]
@@ -297,7 +298,7 @@ def translate(
     cancellation_event: asyncio.Event = None,
     model: OnnxModel = None,
     envs: Dict = None,
-    prompt: List = None,
+    prompt: Template = None,
     **kwarg: Any,
 ):
     if not files:
",add docstrings for translate,
167b3666d5aeb0ce247126f03931f6923a83a7b1,translator.py,"@@ -277,8 +277,6 @@ class OllamaTranslator(BaseTranslator):
         self.client = ollama.Client()
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -320,8 +318,6 @@ class XinferenceTranslator(BaseTranslator):
         self.client = xinference_client.RESTfulClient(self.envs[""XINFERENCE_HOST""])
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
@@ -384,8 +380,6 @@ class OpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -438,8 +432,6 @@ class AzureOpenAITranslator(BaseTranslator):
         )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -476,8 +468,6 @@ class ModelScopeTranslator(OpenAITranslator):
             model = self.envs[""MODELSCOPE_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class ZhipuTranslator(OpenAITranslator):
@@ -497,8 +487,6 @@ class ZhipuTranslator(OpenAITranslator):
             model = self.envs[""ZHIPU_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text) -> str:
         try:
@@ -534,8 +522,6 @@ class SiliconTranslator(OpenAITranslator):
             model = self.envs[""SILICON_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class GeminiTranslator(OpenAITranslator):
@@ -555,8 +541,6 @@ class GeminiTranslator(OpenAITranslator):
             model = self.envs[""GEMINI_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class AzureTranslator(BaseTranslator):
@@ -634,8 +618,6 @@ class AnythingLLMTranslator(BaseTranslator):
             ""Content-Type"": ""application/json"",
         }
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
     def do_translate(self, text):
         messages = self.prompt(text, self.prompttext)
@@ -752,8 +734,6 @@ class GorkTranslator(OpenAITranslator):
             model = self.envs[""GORK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class GroqTranslator(OpenAITranslator):
@@ -772,8 +752,6 @@ class GroqTranslator(OpenAITranslator):
             model = self.envs[""GROQ_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class DeepseekTranslator(OpenAITranslator):
@@ -792,8 +770,6 @@ class DeepseekTranslator(OpenAITranslator):
             model = self.envs[""DEEPSEEK_MODEL""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
 
 
 class OpenAIlikedTranslator(OpenAITranslator):
@@ -822,5 +798,3 @@ class OpenAIlikedTranslator(OpenAITranslator):
             api_key = self.envs[""OPENAILIKED_API_KEY""]
         super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key)
         self.prompttext = prompt
-        if prompt:
-            self.add_cache_impact_parameters(""prompt"", prompt.template)
",add missing aliases in the translation script,
01394b0b8004f64d5970378fd8b94f1dae76f2e6,setup.bat,"@@ -20,6 +20,7 @@ if not exist Scripts/pip.exe (
 )
 path Scripts
 
+pip install --no-warn-script-location --upgrade setuptools -i !PIP_MIRROR!
 pip install --no-warn-script-location --upgrade pdf2zh -i !PIP_MIRROR!
 pdf2zh -i
 
",add missing install script,
540e9e72bde8ff655c547ee9030a9d997f7c62e7,README_ja-JP.md,"@@ -215,27 +215,27 @@ pdf2zh example.pdf -li en -lo ja
 
 以下の表は、各翻訳サービスに必要な [環境変数](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4) を示しています。各サービスを使用する前に、これらの変数を設定してください。
 
-|**Translator**|**Service**|**Environment Variables**|**Default Values**|**Notes**|
+|**Translator**| **Service**    |**Environment Variables**|**Default Values**|**Notes**|
 |-|-|-|-|-|
-|**Google (Default)**|`google`|None|N/A|None|
-|**Bing**|`bing`|None|N/A|None|
-|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
-|**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
-|**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
-|**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
-|**AzureOpenAI**|`azure-openai`|`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
-|**Zhipu**|`zhipu`|`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
-| **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
-|**Silicon**|`silicon`|`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
-|**Gemini**|`gemini`|`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
-|**Azure**|`azure`|`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
-|**Tencent**|`tencent`|`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`|See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)|
-|**Dify**|`dify`|`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`|See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.|
-|**AnythingLLM**|`anythingllm`|`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`|See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)|
-|**Argos Translate**|`argos`| | |See [argos-translate](https://github.com/argosopentech/argos-translate)|
-|**Grok**|`grok`| `GORK_API_KEY`, `GORK_MODEL` | `[Your GORK_API_KEY]`, `grok-2-1212` |See [Grok](https://docs.x.ai/docs/overview)|
-|**DeepSeek**|`deepseek`| `DEEPSEEK_API_KEY`, `DEEPSEEK_MODEL` | `[Your DEEPSEEK_API_KEY]`, `deepseek-chat` |See [DeepSeek](https://www.deepseek.com/)|
-|**OpenAI-Liked**|`openai-liked`| `OPENAILIKE_BASE_URL`, `OPENAILIKE_API_KEY`, `OPENAILIKE_MODEL` | `url`, `[Your Key]`, `model name` | None |
+|**Google (Default)**| `google`       |None|N/A|None|
+|**Bing**| `bing`         |None|N/A|None|
+|**DeepL**| `deepl`        |`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepLX**| `deeplx`       |`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
+|**Ollama**| `ollama`       |`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
+|**OpenAI**| `openai`       |`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
+|**AzureOpenAI**| `azure-openai` |`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
+|**Zhipu**| `zhipu`        |`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
+| **ModelScope**       | `modelscope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
+|**Silicon**| `silicon`      |`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
+|**Gemini**| `gemini`       |`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
+|**Azure**| `azure`        |`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
+|**Tencent**| `tencent`      |`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`|See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)|
+|**Dify**| `dify`         |`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`|See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.|
+|**AnythingLLM**| `anythingllm`  |`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`|See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)|
+|**Argos Translate**| `argos`        | | |See [argos-translate](https://github.com/argosopentech/argos-translate)|
+|**Grok**| `grok`         | `GORK_API_KEY`, `GORK_MODEL` | `[Your GORK_API_KEY]`, `grok-2-1212` |See [Grok](https://docs.x.ai/docs/overview)|
+|**DeepSeek**| `deepseek`     | `DEEPSEEK_API_KEY`, `DEEPSEEK_MODEL` | `[Your DEEPSEEK_API_KEY]`, `deepseek-chat` |See [DeepSeek](https://www.deepseek.com/)|
+|**OpenAI-Liked**| `openai-liked` | `OPENAILIKE_BASE_URL`, `OPENAILIKE_API_KEY`, `OPENAILIKE_MODEL` | `url`, `[Your Key]`, `model name` | None |
 
 (need Japenese translation)
 For large language models that are compatible with the OpenAI API but not listed in the table above, you can set environment variables using the same method outlined for OpenAI in the table.
",add more examples to the 2zh example,
540e9e72bde8ff655c547ee9030a9d997f7c62e7,README_zh-CN.md,"@@ -227,7 +227,7 @@ pdf2zh example.pdf -li en -lo ja
 |**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
 |**AzureOpenAI**|`azure-openai`|`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
 |**Zhipu**|`zhipu`|`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
-| **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
+| **ModelScope**       | `modelscope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
 |**Silicon**|`silicon`|`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
 |**Gemini**|`gemini`|`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
 |**Azure**|`azure`|`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
",add missing examples to pdf2zh example,
540e9e72bde8ff655c547ee9030a9d997f7c62e7,README_zh-TW.md,"@@ -219,7 +219,7 @@ pdf2zh example.pdf -li en -lo ja
 |**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|參閱 [OpenAI](https://platform.openai.com/docs/overview)|
 |**AzureOpenAI**|`azure-openai`|`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|參閱 [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
 |**Zhipu**|`zhipu`|`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|參閱 [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
-| **ModelScope**       | `ModelScope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| 參閱 [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
+| **ModelScope**       | `modelscope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| 參閱 [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
 |**Silicon**|`silicon`|`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|參閱 [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
 |**Gemini**|`gemini`|`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|參閱 [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
 |**Azure**|`azure`|`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|參閱 [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
",add examples for pdf2zh,
4f9bedb792245ee224426a45d7053fe994cadf91,README_ja-JP.md,"@@ -215,27 +215,27 @@ pdf2zh example.pdf -li en -lo ja
 
 以下の表は、各翻訳サービスに必要な [環境変数](https://chatgpt.com/share/6734a83d-9d48-800e-8a46-f57ca6e8bcb4) を示しています。各サービスを使用する前に、これらの変数を設定してください。
 
-|**Translator**| **Service**    |**Environment Variables**|**Default Values**|**Notes**|
+|**Translator**|**Service**|**Environment Variables**|**Default Values**|**Notes**|
 |-|-|-|-|-|
-|**Google (Default)**| `google`       |None|N/A|None|
-|**Bing**| `bing`         |None|N/A|None|
-|**DeepL**| `deepl`        |`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
-|**DeepLX**| `deeplx`       |`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
-|**Ollama**| `ollama`       |`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
-|**OpenAI**| `openai`       |`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
-|**AzureOpenAI**| `azure-openai` |`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
-|**Zhipu**| `zhipu`        |`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
+|**Google (Default)**|`google`|None|N/A|None|
+|**Bing**|`bing`|None|N/A|None|
+|**DeepL**|`deepl`|`DEEPL_AUTH_KEY`|`[Your Key]`|See [DeepL](https://support.deepl.com/hc/en-us/articles/360020695820-API-Key-for-DeepL-s-API)|
+|**DeepLX**|`deeplx`|`DEEPLX_ENDPOINT`|`https://api.deepl.com/translate`|See [DeepLX](https://github.com/OwO-Network/DeepLX)|
+|**Ollama**|`ollama`|`OLLAMA_HOST`, `OLLAMA_MODEL`|`http://127.0.0.1:11434`, `gemma2`|See [Ollama](https://github.com/ollama/ollama)|
+|**OpenAI**|`openai`|`OPENAI_BASE_URL`, `OPENAI_API_KEY`, `OPENAI_MODEL`|`https://api.openai.com/v1`, `[Your Key]`, `gpt-4o-mini`|See [OpenAI](https://platform.openai.com/docs/overview)|
+|**AzureOpenAI**|`azure-openai`|`AZURE_OPENAI_BASE_URL`, `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_MODEL`|`[Your Endpoint]`, `[Your Key]`, `gpt-4o-mini`|See [Azure OpenAI](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cjavascript-keyless%2Ctypescript-keyless%2Cpython&pivots=programming-language-python)|
+|**Zhipu**|`zhipu`|`ZHIPU_API_KEY`, `ZHIPU_MODEL`|`[Your Key]`, `glm-4-flash`|See [Zhipu](https://open.bigmodel.cn/dev/api/thirdparty-frame/openai-sdk)|
 | **ModelScope**       | `modelscope`   |`MODELSCOPE_API_KEY`, `MODELSCOPE_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-Coder-32B-Instruct`| See [ModelScope](https://www.modelscope.cn/docs/model-service/API-Inference/intro)|
-|**Silicon**| `silicon`      |`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
-|**Gemini**| `gemini`       |`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
-|**Azure**| `azure`        |`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
-|**Tencent**| `tencent`      |`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`|See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)|
-|**Dify**| `dify`         |`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`|See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.|
-|**AnythingLLM**| `anythingllm`  |`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`|See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)|
-|**Argos Translate**| `argos`        | | |See [argos-translate](https://github.com/argosopentech/argos-translate)|
-|**Grok**| `grok`         | `GORK_API_KEY`, `GORK_MODEL` | `[Your GORK_API_KEY]`, `grok-2-1212` |See [Grok](https://docs.x.ai/docs/overview)|
-|**DeepSeek**| `deepseek`     | `DEEPSEEK_API_KEY`, `DEEPSEEK_MODEL` | `[Your DEEPSEEK_API_KEY]`, `deepseek-chat` |See [DeepSeek](https://www.deepseek.com/)|
-|**OpenAI-Liked**| `openai-liked` | `OPENAILIKE_BASE_URL`, `OPENAILIKE_API_KEY`, `OPENAILIKE_MODEL` | `url`, `[Your Key]`, `model name` | None |
+|**Silicon**|`silicon`|`SILICON_API_KEY`, `SILICON_MODEL`|`[Your Key]`, `Qwen/Qwen2.5-7B-Instruct`|See [SiliconCloud](https://docs.siliconflow.cn/quickstart)|
+|**Gemini**|`gemini`|`GEMINI_API_KEY`, `GEMINI_MODEL`|`[Your Key]`, `gemini-1.5-flash`|See [Gemini](https://ai.google.dev/gemini-api/docs/openai)|
+|**Azure**|`azure`|`AZURE_ENDPOINT`, `AZURE_API_KEY`|`https://api.translator.azure.cn`, `[Your Key]`|See [Azure](https://docs.azure.cn/en-us/ai-services/translator/text-translation-overview)|
+|**Tencent**|`tencent`|`TENCENTCLOUD_SECRET_ID`, `TENCENTCLOUD_SECRET_KEY`|`[Your ID]`, `[Your Key]`|See [Tencent](https://www.tencentcloud.com/products/tmt?from_qcintl=122110104)|
+|**Dify**|`dify`|`DIFY_API_URL`, `DIFY_API_KEY`|`[Your DIFY URL]`, `[Your Key]`|See [Dify](https://github.com/langgenius/dify),Three variables, lang_out, lang_in, and text, need to be defined in Dify's workflow input.|
+|**AnythingLLM**|`anythingllm`|`AnythingLLM_URL`, `AnythingLLM_APIKEY`|`[Your AnythingLLM URL]`, `[Your Key]`|See [anything-llm](https://github.com/Mintplex-Labs/anything-llm)|
+|**Argos Translate**|`argos`| | |See [argos-translate](https://github.com/argosopentech/argos-translate)|
+|**Grok**|`grok`| `GORK_API_KEY`, `GORK_MODEL` | `[Your GORK_API_KEY]`, `grok-2-1212` |See [Grok](https://docs.x.ai/docs/overview)|
+|**DeepSeek**|`deepseek`| `DEEPSEEK_API_KEY`, `DEEPSEEK_MODEL` | `[Your DEEPSEEK_API_KEY]`, `deepseek-chat` |See [DeepSeek](https://www.deepseek.com/)|
+|**OpenAI-Liked**|`openai-liked`| `OPENAILIKE_BASE_URL`, `OPENAILIKE_API_KEY`, `OPENAILIKE_MODEL` | `url`, `[Your Key]`, `model name` | None |
 
 (need Japenese translation)
 For large language models that are compatible with the OpenAI API but not listed in the table above, you can set environment variables using the same method outlined for OpenAI in the table.
",add more examples to the 2zh example,
52e5129cc1b27fa1f613ca0103af01f6966f5353,Dockerfile,"@@ -15,7 +15,7 @@ ADD ""https://github.com/timelic/source-han-serif/releases/download/main/SourceHa
 ADD ""https://github.com/timelic/source-han-serif/releases/download/main/SourceHanSerifKR-Regular.ttf"" /app/
 
 RUN apt-get update && \
-     apt-get install --no-install-recommends -y libgl1 && \
+     apt-get install --no-install-recommends -y libgl1 libglib2.0-0 && \
      rm -rf /var/lib/apt/lists/* && uv pip install --system --no-cache huggingface-hub && \
      python3 -c ""from huggingface_hub import hf_hub_download; hf_hub_download('wybxc/DocLayout-YOLO-DocStructBench-onnx','doclayout_yolo_docstructbench_imgsz1024.onnx');""
 
",add sourcehanench to the hub,
52e5129cc1b27fa1f613ca0103af01f6966f5353,translator.py,"@@ -274,7 +274,7 @@ class OllamaTranslator(BaseTranslator):
             model = self.envs[""OLLAMA_MODEL""]
         super().__init__(lang_in, lang_out, model)
         self.options = {""temperature"": 0}  # 随机采样可能会打断公式标记
-        self.client = ollama.Client()
+        self.client = ollama.Client(host=self.envs[""OLLAMA_HOST""])
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
 
",add missing options,
82abf21191216e682e98c67919e4215a4c5a1e9d,translator.py,"@@ -280,7 +280,6 @@ class OllamaTranslator(BaseTranslator):
 
     def do_translate(self, text):
         maxlen = max(2000, len(text) * 5)
-        print(""Prompt:"", self.prompt(text, self.prompttext), ""Maxlen:"" , maxlen)
         for model in self.model.split("";""):
             try:
                 response = """"
@@ -307,7 +306,6 @@ class OllamaTranslator(BaseTranslator):
                     else:
                         response += chunk
                     if len(response) > maxlen:
-                        print(response)
                         raise Exception(""Response too long"")
                 return response.strip()
             except Exception as e:
",fix ollama translator,
be5e2d466583ec8f99bd329ecfded45a674c3712,Dockerfile,"@@ -15,7 +15,7 @@ ADD ""https://github.com/timelic/source-han-serif/releases/download/main/SourceHa
 ADD ""https://github.com/timelic/source-han-serif/releases/download/main/SourceHanSerifKR-Regular.ttf"" /app/
 
 RUN apt-get update && \
-     apt-get install --no-install-recommends -y libgl1 libglib2.0-0 && \
+     apt-get install --no-install-recommends -y libgl1 libglib2.0-0 libxext6 libsm6 libxrender1 && \
      rm -rf /var/lib/apt/lists/* && uv pip install --system --no-cache huggingface-hub && \
      python3 -c ""from huggingface_hub import hf_hub_download; hf_hub_download('wybxc/DocLayout-YOLO-DocStructBench-onnx','doclayout_yolo_docstructbench_imgsz1024.onnx');""
 
",add sourcehan-serif kR to app,
ad501f9ee8f387aa0eeb5c86df45452f7c867796,high_level.py,"@@ -65,23 +65,23 @@ def check_files(files: List[str]) -> List[str]:
 
 
 def translate_patch(
-    inf: BinaryIO,
-    pages: Optional[list[int]] = None,
-    vfont: str = """",
-    vchar: str = """",
-    thread: int = 0,
-    doc_zh: Document = None,
-    lang_in: str = """",
-    lang_out: str = """",
-    service: str = """",
-    noto_name: str = """",
-    noto: Font = None,
-    callback: object = None,
-    cancellation_event: asyncio.Event = None,
-    model: OnnxModel = None,
-    envs: Dict = None,
-    prompt: Template = None,
-    **kwarg: Any,
+        inf: BinaryIO,
+        pages: Optional[list[int]] = None,
+        vfont: str = """",
+        vchar: str = """",
+        thread: int = 0,
+        doc_zh: Document = None,
+        lang_in: str = """",
+        lang_out: str = """",
+        service: str = """",
+        noto_name: str = """",
+        noto: Font = None,
+        callback: object = None,
+        cancellation_event: asyncio.Event = None,
+        model: OnnxModel = None,
+        envs: Dict = None,
+        prompt: Template = None,
+        **kwarg: Any,
 ) -> None:
     rsrcmgr = PDFResourceManager()
     layout = {}
@@ -162,20 +162,20 @@ def translate_patch(
 
 
 def translate_stream(
-    stream: bytes,
-    pages: Optional[list[int]] = None,
-    lang_in: str = """",
-    lang_out: str = """",
-    service: str = """",
-    thread: int = 0,
-    vfont: str = """",
-    vchar: str = """",
-    callback: object = None,
-    cancellation_event: asyncio.Event = None,
-    model: OnnxModel = None,
-    envs: Dict = None,
-    prompt: Template = None,
-    **kwarg: Any,
+        stream: bytes,
+        pages: Optional[list[int]] = None,
+        lang_in: str = """",
+        lang_out: str = """",
+        service: str = """",
+        thread: int = 0,
+        vfont: str = """",
+        vchar: str = """",
+        callback: object = None,
+        cancellation_event: asyncio.Event = None,
+        model: OnnxModel = None,
+        envs: Dict = None,
+        prompt: Template = None,
+        **kwarg: Any,
 ):
     font_list = [(""tiro"", None)]
 
@@ -199,25 +199,21 @@ def translate_stream(
         for label in [""Resources/"", """"]:  # 可能是基于 xobj 的 res
             try:  # xref 读写可能出错
                 font_res = doc_zh.xref_get_key(xref, f""{label}Font"")
+                target_key_prefix = f""{label}Font/""
                 if font_res[0] == ""xref"":
                     resource_xref_id = re.search(""(\\d+) 0 R"", font_res[1]).group(1)
                     xref = int(resource_xref_id)
-                    font_res = doc_zh.xref_object(xref)
-                    for font in font_list:
-                        font_exist = doc_zh.xref_get_key(xref, f""{font[0]}"")
-                        if font_exist[0] == ""null"":
-                            doc_zh.xref_set_key(
-                                xref,
-                                f""{font[0]}"",
-                                f""{font_id[font[0]]} 0 R"",
-                            )
+                    font_res = (""dict"", doc_zh.xref_object(xref))
+                    target_key_prefix = """"
+
                 if font_res[0] == ""dict"":
                     for font in font_list:
-                        font_exist = doc_zh.xref_get_key(xref, f""{label}Font/{font[0]}"")
+                        target_key = f""{target_key_prefix}{font[0]}""
+                        font_exist = doc_zh.xref_get_key(xref, target_key)
                         if font_exist[0] == ""null"":
                             doc_zh.xref_set_key(
                                 xref,
-                                f""{label}Font/{font[0]}"",
+                                target_key,
                                 f""{font_id[font[0]]} 0 R"",
                             )
             except Exception:
@@ -297,22 +293,22 @@ def convert_to_pdfa(input_path, output_path):
 
 
 def translate(
-    files: list[str],
-    output: str = """",
-    pages: Optional[list[int]] = None,
-    lang_in: str = """",
-    lang_out: str = """",
-    service: str = """",
-    thread: int = 0,
-    vfont: str = """",
-    vchar: str = """",
-    callback: object = None,
-    compatible: bool = False,
-    cancellation_event: asyncio.Event = None,
-    model: OnnxModel = None,
-    envs: Dict = None,
-    prompt: Template = None,
-    **kwarg: Any,
+        files: list[str],
+        output: str = """",
+        pages: Optional[list[int]] = None,
+        lang_in: str = """",
+        lang_out: str = """",
+        service: str = """",
+        thread: int = 0,
+        vfont: str = """",
+        vchar: str = """",
+        callback: object = None,
+        compatible: bool = False,
+        cancellation_event: asyncio.Event = None,
+        model: OnnxModel = None,
+        envs: Dict = None,
+        prompt: Template = None,
+        **kwarg: Any,
 ):
     if not files:
         raise PDFValueError(""No files to process."")
@@ -329,14 +325,14 @@ def translate(
 
     for file in files:
         if type(file) is str and (
-            file.startswith(""http://"") or file.startswith(""https://"")
+                file.startswith(""http://"") or file.startswith(""https://"")
         ):
             print(""Online files detected, downloading..."")
             try:
                 r = requests.get(file, allow_redirects=True)
                 if r.status_code == 200:
                     with tempfile.NamedTemporaryFile(
-                        suffix="".pdf"", delete=False
+                            suffix="".pdf"", delete=False
                     ) as tmp_file:
                         print(f""Writing the file: {file}..."")
                         tmp_file.write(r.content)
@@ -353,7 +349,7 @@ def translate(
         # --compatible / -cp
         if compatible:
             with tempfile.NamedTemporaryFile(
-                suffix=""-pdfa.pdf"", delete=False
+                    suffix=""-pdfa.pdf"", delete=False
             ) as tmp_pdfa:
                 print(f""Converting {file} to PDF/A format..."")
                 convert_to_pdfa(file, tmp_pdfa.name)
",add support for vfont/vttext/vttext.py,
55fd6c64f707df13cd9bcefa155ae88f7249ff10,pdfinterp.py,"@@ -224,6 +224,8 @@ class PDFPageInterpreterEx(PDFPageInterpreter):
                 [xobj],
                 ctm=ctm,
             )
+            self.ncs = interpreter.ncs
+            self.scs = interpreter.scs
             try:  # 有的时候 form 字体加不上这里会烂掉
                 self.device.fontid = interpreter.fontid
                 self.device.fontmap = interpreter.fontmap
",add missing properties to pageinterpreterex,
c77cc3a4ee85303def26211c34faaa0617ac033d,gui.py,"@@ -61,7 +61,7 @@ service_map: dict[str, BaseTranslator] = {
     ""Dify"": DifyTranslator,
     ""AnythingLLM"": AnythingLLMTranslator,
     ""Argos Translate"": ArgosTranslator,
-    ""Gork"": GorkTranslator,
+    ""Grok"": GorkTranslator,
     ""Groq"": GroqTranslator,
     ""DeepSeek"": DeepseekTranslator,
     ""OpenAI-liked"": OpenAIlikedTranslator,
",add missing service map,
2e2e878928f8e67489a59ffe41ce3d4c4f717c40,translator.py,"@@ -400,6 +400,11 @@ class OpenAITranslator(BaseTranslator):
             **self.options,
             messages=self.prompt(text, self.prompttext),
         )
+        if not response.choices:
+            if hasattr(response, ""error""):
+                raise ValueError(""Empty response from OpenAI API"", response.error)
+            else:
+                raise ValueError(""Empty response from OpenAI API"")
         return response.choices[0].message.content.strip()
 
     def get_formular_placeholder(self, id: int):
",add missing check for error message,
30baa626af5cd6426642947e78b983610a6871db,功能请求.md,"@@ -1,11 +0,0 @@
----
-name: 功能请求
-about: Suggest an idea for this project
-title: ''
-labels: enhancement
-assignees: ''
-
----
-
-## 功能描述
-请描述需要添加的功能，以及是否有类似项目可以参考
",add missing description,
30baa626af5cd6426642947e78b983610a6871db,功能请求_cn.yaml,"@@ -0,0 +1,25 @@
+name: 功能请求
+description: 使用中文进行功能请求
+labels: ['enhancement']
+body:
+  - type: textarea
+    id: describe
+    attributes:
+      label: 你的功能请求是否与问题有关？
+      description: 简要描述相关的问题
+    validations:
+      required: false
+  - type: textarea
+    id: solution
+    attributes:
+      label: 解决方案
+      description: 描述你想要的解决方案
+    validations:
+      required: false
+  - type: textarea
+    id: additional
+    attributes:
+      label: 其他内容
+      description: 关于该功能请求的任何其他项目。
+    validations:
+      required: false
\ No newline at end of file
",add missing attributes to doc block,
30baa626af5cd6426642947e78b983610a6871db,功能请求_en.yaml,"@@ -0,0 +1,26 @@
+name: Feature request
+description: Suggest an idea for this project
+labels: ['enhancement']
+body:
+  - type: textarea
+    id: describe
+    attributes:
+      label: Is your feature request related to a problem?
+      description: A clear and concise description of what the problem is
+      placeholder: Ex. I'm always frustrated when ...
+    validations:
+      required: false
+  - type: textarea
+    id: solution
+    attributes:
+      label: Describe the solution you'd like
+      description: A clear and concise description of what you want to happen
+    validations:
+      required: false
+  - type: textarea
+    id: additional
+    attributes:
+      label: Additional context
+      description: Add any other projects about the feature request here.
+    validations:
+      required: false
\ No newline at end of file
",add missing missing attributes to feature request,
30baa626af5cd6426642947e78b983610a6871db,问题反馈.md,"@@ -1,17 +0,0 @@
----
-name: 问题反馈
-about: Create a report to help us improve
-title: ''
-labels: bug
-assignees: ''
-
----
-
-## 问题描述
-请对问题进行描述，并提供日志或截图
-请确认 issues 中没有相同问题且完整阅读 wiki
-**本项目不处理网络环境引发的问题**（例如 empty translation result/connection reset/check_hostname requires server_hostname/certificate verify failed/unable to connect to proxy/LocalEntryNotFoundError）
-
-## 测试文档
-> [!IMPORTANT]
-> 请提供用于复现测试的 PDF 文档
",add missing report,
30baa626af5cd6426642947e78b983610a6871db,问题反馈_cn.yaml,"@@ -0,0 +1,87 @@
+name: 上报 Bug
+description: 使用中文进行 Bug 报告
+labels: ['bug']
+body:
+  - type: checkboxes
+    id: checks
+    attributes:
+      label: 在提问之前...
+      options:
+      - label: 我已经搜索了现有的 issues
+        required: true
+      - label: 我在提问题之前至少花费了 5 分钟来思考和准备
+        required: true
+      - label: 我已经认真且完整的阅读了 wiki
+        required: true
+      - label: 我已经认真检查了问题和网络环境无关
+        required: true
+  - type: markdown
+    attributes:
+      value: |
+        感谢您使用本项目并反馈！
+  - type: textarea
+    id: environment
+    attributes:
+      label: 使用的环境
+      description: |
+        examples:
+          - **OS**: Ubuntu 24.10  
+          - **Python**: 3.12.0  
+          - **pdf2zh**: 1.9.0
+      value: |
+          - OS:
+          - Python:
+          - pdf2zh:
+      render: markdown
+    validations:
+      required: false
+  - type: textarea
+    id: describe
+    attributes:
+      label: 描述你的问题
+      description: 简要描述你的问题
+    validations:
+      required: true
+  - type: textarea
+    id: reproduce
+    attributes:
+      label: 如何复现
+      description: 重现该行为的步骤
+      value: |
+        1. 执行 '...'
+        2. 选择 '....'
+        3. 出现问题
+    validations:
+      required: false
+  - type: textarea
+    id: expected
+    attributes:
+      label: 预期行为
+      description: 简要描述你期望得到的反馈
+    validations:
+      required: false
+  - type: textarea
+    id: logs
+    attributes:
+      label: 相关 Logs
+      description: 请复制并粘贴任何相关的日志输出。
+      render: Text
+    validations:
+      required: false
+  - type: textarea
+    id: PDFfile
+    attributes:
+      label: 原始PDF文件
+      description: |
+        如果涉及到排版错误的问题，请一定提供原始的PDF文件，方便复现错误。
+    validations:
+      required: false
+  - type: textarea
+    id: others
+    attributes:
+      label: 还有别的吗？
+      description: |
+        相关的配置？链接？参考资料？
+        任何能让我们对你所遇到的问题有更多了解的东西。
+    validations:
+      required: false
\ No newline at end of file
",add missing tag to bug_test.js,
30baa626af5cd6426642947e78b983610a6871db,问题反馈_en.yaml,"@@ -0,0 +1,87 @@
+name: Bug Report
+description: Create a report to help us improve
+labels: ['bug']
+body:
+  - type: checkboxes
+    id: checks
+    attributes:
+      label: Before you asking
+      options:
+      - label: I have searched the existing issues
+        required: true
+      - label: I spend at least 5 minutes for thinking and preparing
+        required: true
+      - label: I have thoroughly and completely read the wiki.
+        required: true
+      - label: I have carefully checked the issue, and it is unrelated to the network environment.
+        required: true
+  - type: markdown
+    attributes:
+      value: |
+        Thank you for using this project and providing feedback!
+  - type: textarea
+    id: environment
+    attributes:
+      label: Environment
+      description: |
+        examples:
+          - **OS**: Ubuntu 24.10
+          - **Python**: 3.12.0
+          - **pdf2zh**: 1.9.0
+      value: |
+          - OS:
+          - Python:
+          - pdf2zh:
+      render: markdown
+    validations:
+      required: false
+  - type: textarea
+    id: describe
+    attributes:
+      label: Describe the bug
+      description: A clear and concise description of what the bug is.
+    validations:
+      required: true
+  - type: textarea
+    id: reproduce
+    attributes:
+      label: To Reproduce
+      description: Steps to reproduce the behavior
+      value: |
+        1. execute '...'
+        2. select '....'
+        3. see errors
+    validations:
+      required: false
+  - type: textarea
+    id: expected
+    attributes:
+      label: Expected behavior
+      description: A clear and concise description of what you expected to happen.
+    validations:
+      required: false
+  - type: textarea
+    id: logs
+    attributes:
+      label: Relevant log output
+      description: Please copy and paste any relevant log output. This will be automatically formatted into code, so no need for backticks.
+      render: Text
+    validations:
+      required: false
+  - type: textarea
+    id: PDFfile
+    attributes:
+      label: Origin PDF file
+      description: |
+        If the issue involves formatting errors, please provide the original PDF file to facilitate reproduction of the error.
+    validations:
+      required: false
+  - type: textarea
+    id: others
+    attributes:
+      label: Anything else?
+      description: |
+        Related configs? Links? References?
+        Anything that will give us more context about the issue you are encountering!
+    validations:
+      required: false
\ No newline at end of file
",add missing docs to bug report,
2c531f02dd0cc7d98e437ae2d34665e30c215114,功能请求_cn.yaml,"@@ -5,8 +5,8 @@ body:
   - type: textarea
     id: describe
     attributes:
-      label: 你的功能请求是否与问题有关？
-      description: 简要描述相关的问题
+      label: 在什么场景下，需要你请求的功能？
+      description: 简要描述相关的使用场景
     validations:
       required: false
   - type: textarea
",update textarea.js,
efd674ee6501cc3fe4616052143279001eea387a,pdf2zh.py,"@@ -330,6 +330,7 @@ def yadt_main(parsed_args) -> int:
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
+        QwenMtTranslator,
     )
 
     for translator in [
@@ -354,6 +355,7 @@ def yadt_main(parsed_args) -> int:
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
+        QwenMtTranslator,
     ]:
         if service_name == translator.name:
             translator = translator(
",add more translations,
8e6c33751a93b0b99e9e9a9883ac8bfd007ef90a,translator.py,"@@ -286,6 +286,7 @@ class OllamaTranslator(BaseTranslator):
                     options=self.options,
                     messages=self.prompt(text, self.prompttext),
                 )
+                response = response[""message""][""content""].strip()
                 if (
                     ""deepseek-r1"" in model
                     and ""<think>"" in response[""message""][""content""].strip()
",add missing line,
d7bd3617c00762d9a1ebf1e4e4c8f8d76e0477e3,exe-build.yml,"@@ -24,7 +24,7 @@ jobs:
           New-Item -Path ""./dep_build"" -ItemType Directory -Force
 
           Write-Host ""==== 复制代码到 dep_build ====""
-          Copy-Item -Path ""./*"" -Destination ""./dep_build"" -Recurse -Force
+          Get-ChildItem -Path ""./"" -Exclude ""dep_build"", ""build"" | Copy-Item -Destination ""./dep_build"" -Recurse -Force
 
           Write-Host ""==== 下载并解压 Python 3.12.9 ====""
           $pythonUrl = ""https://www.python.org/ftp/python/3.12.9/python-3.12.9-embed-amd64.zip""
",add build job to run_build.php,
31240b003f97189630d7a6bd9897dc232914eda2,exe-build.yml,"@@ -15,6 +15,12 @@ jobs:
       - name: 检出代码
         uses: actions/checkout@v4
 
+      - name: 设置 Python 3.12
+        uses: actions/setup-python@v5
+        with:
+          python-version: '3.12'
+
+
       - name: 执行所有任务（创建目录、下载、解压、复制文件、安装依赖）
         shell: pwsh
         run: |
@@ -49,7 +55,7 @@ jobs:
           }
 
           Write-Host ""==== 创建 Python venv 在 dep_build ====""
-          .\build\runtime\python.exe -m venv .\dep_build\venv
+          python3.12.exe -m venv .\dep_build\venv
 
           Write-Host ""==== 在 venv 环境中安装项目依赖 ====""
           .\dep_build\venv\Scripts\python.exe -m pip install --upgrade pip
",add more info to the list of available jobs,
30357290f16afae733dbbb7505094608c23dba06,exe-build.yml,"@@ -55,7 +55,7 @@ jobs:
           }
 
           Write-Host ""==== 创建 Python venv 在 dep_build ====""
-          python3.12.exe -m venv .\dep_build\venv
+          python -m venv .\dep_build\venv
 
           Write-Host ""==== 在 venv 环境中安装项目依赖 ====""
           .\dep_build\venv\Scripts\python.exe -m pip install --upgrade pip
",add more info to the list of jobs,
d43ce5297f486f27912e86c225c5b698c5162aa1,doclayout.py,"@@ -4,8 +4,18 @@ import os.path
 import cv2
 import numpy as np
 import ast
-import onnx
-import onnxruntime
+
+try:
+    import onnx
+    import onnxruntime
+except ImportError as e:
+    if ""DLL load failed"" in str(e):
+        raise OSError(
+            ""Microsoft Visual C++ Redistributable is not installed. ""
+            ""Download it at https://aka.ms/vs/17/release/vc_redist.x64.exe""
+        ) from e
+    raise
+
 from huggingface_hub import hf_hub_download
 
 from pdf2zh.config import ConfigManager
",add missing exception,
0d4b7b62bb78fe76e2bb5f12abde5405c866dbfd,converter.py,"@@ -1,50 +1,45 @@
-from typing import Dict
-from enum import Enum
-
-from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
-from pdfminer.pdffont import PDFCIDFont
-from pdfminer.converter import PDFConverter
-from pdfminer.pdffont import PDFUnicodeNotDefined
-from pdfminer.utils import apply_matrix_pt, mult_matrix
-from pdfminer.layout import (
-    LTChar,
-    LTFigure,
-    LTLine,
-    LTPage,
-)
+import concurrent.futures
 import logging
 import re
-import concurrent.futures
-import numpy as np
 import unicodedata
+from enum import Enum
 from string import Template
+from typing import Dict
+
+import numpy as np
+from pdfminer.converter import PDFConverter
+from pdfminer.layout import LTChar, LTFigure, LTLine, LTPage
+from pdfminer.pdffont import PDFCIDFont, PDFUnicodeNotDefined
+from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
+from pdfminer.utils import apply_matrix_pt, mult_matrix
+from pymupdf import Font
 from tenacity import retry, wait_fixed
+
 from pdf2zh.translator import (
+    AnythingLLMTranslator,
+    ArgosTranslator,
     AzureOpenAITranslator,
+    AzureTranslator,
     BaseTranslator,
-    GoogleTranslator,
     BingTranslator,
     DeepLTranslator,
     DeepLXTranslator,
-    OllamaTranslator,
-    OpenAITranslator,
-    ZhipuTranslator,
-    ModelScopeTranslator,
-    SiliconTranslator,
-    GeminiTranslator,
-    AzureTranslator,
-    TencentTranslator,
+    DeepseekTranslator,
     DifyTranslator,
-    AnythingLLMTranslator,
-    XinferenceTranslator,
-    ArgosTranslator,
+    GeminiTranslator,
+    GoogleTranslator,
     GorkTranslator,
     GroqTranslator,
-    DeepseekTranslator,
+    ModelScopeTranslator,
+    OllamaTranslator,
     OpenAIlikedTranslator,
+    OpenAITranslator,
     QwenMtTranslator,
+    SiliconTranslator,
+    TencentTranslator,
+    XinferenceTranslator,
+    ZhipuTranslator,
 )
-from pymupdf import Font
 
 log = logging.getLogger(__name__)
 
@@ -156,6 +151,7 @@ class TranslateConverter(PDFConverterEx):
         self.noto_name = noto_name
         self.noto = noto
         self.translator: BaseTranslator = None
+        # e.g. ""ollama:gemma2:9b"" -> [""ollama"", ""gemma2:9b""]
         param = service.split("":"", 1)
         service_name = param[0]
         service_model = param[1] if len(param) > 1 else None
",add translations for all the translations,
0d4b7b62bb78fe76e2bb5f12abde5405c866dbfd,translator.py,"@@ -1,25 +1,30 @@
 import html
+import json
 import logging
 import os
 import re
 import unicodedata
 from copy import copy
+from string import Template
+from typing import Any
+
+import argostranslate.package
+import argostranslate.translate
 import deepl
 import ollama
 import openai
-import xinference_client
 import requests
-from pdf2zh.cache import TranslationCache
+import xinference_client
 from azure.ai.translation.text import TextTranslationClient
 from azure.core.credentials import AzureKeyCredential
 from tencentcloud.common import credential
+from tencentcloud.tmt.v20180321.models import (
+    TextTranslateRequest,
+    TextTranslateResponse,
+)
 from tencentcloud.tmt.v20180321.tmt_client import TmtClient
-from tencentcloud.tmt.v20180321.models import TextTranslateRequest
-from tencentcloud.tmt.v20180321.models import TextTranslateResponse
-import argostranslate.package
-import argostranslate.translate
 
-import json
+from pdf2zh.cache import TranslationCache
 from pdf2zh.config import ConfigManager
 
 
@@ -30,11 +35,11 @@ def remove_control_characters(s):
 class BaseTranslator:
     name = ""base""
     envs = {}
-    lang_map = {}
+    lang_map: dict[str, str] = {}
     CustomPrompt = False
     ignore_cache = False
 
-    def __init__(self, lang_in, lang_out, model):
+    def __init__(self, lang_in: str, lang_out: str, model: str):
         lang_in = self.lang_map.get(lang_in.lower(), lang_in)
         lang_out = self.lang_map.get(lang_out.lower(), lang_out)
         self.lang_in = lang_in
@@ -77,7 +82,7 @@ class BaseTranslator:
         """"""
         self.cache.add_params(k, v)
 
-    def translate(self, text, ignore_cache=False):
+    def translate(self, text: str, ignore_cache=False) -> str:
         """"""
         Translate the text, and the other part should call this method.
         :param text: text to translate
@@ -92,7 +97,7 @@ class BaseTranslator:
         self.cache.set(text, translation)
         return translation
 
-    def do_translate(self, text):
+    def do_translate(self, text: str) -> str:
         """"""
         Actual translate text, override this method
         :param text: text to translate
@@ -100,25 +105,28 @@ class BaseTranslator:
         """"""
         raise NotImplementedError
 
-    def prompt(self, text, prompt):
+    def prompt(self, text: str, prompt: Template | None = None) -> list[dict[str, Any]]:
         if prompt:
-            context = {
+            template_fill_values = {
                 ""lang_in"": self.lang_in,
                 ""lang_out"": self.lang_out,
                 ""text"": text,
             }
-            return eval(prompt.safe_substitute(context))
-        else:
-            return [
-                {
-                    ""role"": ""system"",
-                    ""content"": ""You are a professional,authentic machine translation engine. Only Output the translated text, do not include any other text."",
-                },
-                {
-                    ""role"": ""user"",
-                    ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",  # noqa: E501
-                },
-            ]
+            prompt_string = prompt.substitute(template_fill_values)
+            prompt_as_json = json.loads(prompt_string)
+            logging.info(""Use the prompt provided by the user."")
+            return prompt_as_json
+
+        return [
+            {
+                ""role"": ""system"",
+                ""content"": ""You are a professional,authentic machine translation engine. Only Output the translated text, do not include any other text."",
+            },
+            {
+                ""role"": ""user"",
+                ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",  # noqa: E501
+            },
+        ]
 
     def __str__(self):
         return f""{self.name} {self.lang_in} {self.lang_out} {self.model}""
@@ -268,49 +276,50 @@ class OllamaTranslator(BaseTranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None):
+    def __init__(
+        self,
+        lang_in: str,
+        lang_out: str,
+        model: str,
+        envs=None,
+        prompt: Template | None = None,
+    ):
         self.set_envs(envs)
         if not model:
             model = self.envs[""OLLAMA_MODEL""]
         super().__init__(lang_in, lang_out, model)
-        self.options = {""temperature"": 0}  # 随机采样可能会打断公式标记
+        self.options = {
+            ""temperature"": 0,  # 随机采样可能会打断公式标记
+        }
         self.client = ollama.Client(host=self.envs[""OLLAMA_HOST""])
-        self.prompttext = prompt
+        self.prompt_template = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
 
-    def do_translate(self, text):
-        maxlen = max(2000, len(text) * 5)
-        for model in self.model.split("";""):
-            try:
-                response = """"
-                stream = self.client.chat(
-                    model=model,
-                    options=self.options,
-                    messages=self.prompt(text, self.prompttext),
-                    stream=True,
-                )
-                in_think_block = False
-                is_deepseek_r1 = ""deepseek-r1"" in model
-                for chunk in stream:
-                    chunk = chunk[""message""][""content""]
-                    # 只在 deepseek-r1 模型下检查 <think> 块
-                    if is_deepseek_r1:
-                        if ""<think>"" in chunk:
-                            in_think_block = True
-                            chunk = chunk.split(""<think>"")[0]
-                        if ""</think>"" in chunk:
-                            in_think_block = False
-                            chunk = chunk.split(""</think>"")[1]
-                        if not in_think_block:
-                            response += chunk
-                    else:
-                        response += chunk
-                    if len(response) > maxlen:
-                        raise Exception(""Response too long"")
-                return response.strip()
-            except Exception as e:
-                print(e)
-        raise Exception(""All models failed"")
+    def do_translate(self, text: str) -> str:
+        max_token = {""num_predict"": max(2000, len(text) * 5)}
+        self.options.update(max_token)
+
+        response = self.client.chat(
+            model=self.model,
+            messages=self.prompt(text, self.prompt_template),
+            options=self.options,
+            stream=False,
+        )
+        content = self._remove_cot_content(response.message.content or """")
+        return content.strip()
+
+    @staticmethod
+    def _remove_cot_content(content: str) -> str:
+        """"""Remove text content with the thought chain from the chat response
+
+        :param content: Non-streaming text content
+        :return: Text without a thought chain
+        """"""
+        matched_thought_ending_tag = re.search(r""</think>(.*)"", content, re.DOTALL)
+        if matched_thought_ending_tag:
+            return matched_thought_ending_tag.group(1)
+
+        return content
 
 
 class XinferenceTranslator(BaseTranslator):
",add docstrings for base translator,
0d4b7b62bb78fe76e2bb5f12abde5405c866dbfd,test_translator.py,"@@ -1,8 +1,13 @@
 import unittest
-from pdf2zh.translator import BaseTranslator
-from pdf2zh.translator import OpenAIlikedTranslator
+from unittest import mock
+
 from pdf2zh import cache
 from pdf2zh.config import ConfigManager
+from pdf2zh.translator import BaseTranslator, OllamaTranslator, OpenAIlikedTranslator
+
+# Since it is necessary to test whether the functionality meets the expected requirements,
+# private functions and private methods are allowed to be called.
+# pyright: reportPrivateUsage=false
 
 
 class AutoIncreaseTranslator(BaseTranslator):
@@ -144,5 +149,29 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
         self.assertEqual(translator.envs[""OPENAILIKED_API_KEY""], None)
 
 
+class TestOllamaTranslator(unittest.TestCase):
+    def setUp(self) -> None:
+        self.mock_translator = mock.MagicMock()
+
+    def test_do_translate(self):
+        self.mock_translator.do_translate(text=""The sky appears blue because of..."")
+        self.mock_translator.do_translate.return_value = ""天空呈现蓝色是因为...""
+        self.mock_translator.do_translate.assert_called_once()
+
+    def test_remove_cot_content(self):
+        fake_cot_resp_text = """"""<think>
+
+        </think>
+
+        The sky appears blue because...
+        """"""
+        removed_cot_content = OllamaTranslator._remove_cot_content(fake_cot_resp_text)
+        excepted_content = ""The sky appears blue because...""
+        self.assertEqual(excepted_content, removed_cot_content.strip())
+
+        non_cot_content = OllamaTranslator._remove_cot_content(excepted_content)
+        self.assertEqual(excepted_content, non_cot_content)
+
+
 if __name__ == ""__main__"":
     unittest.main()
",add tests for ollama,
37c6df983fcb28abb83c142242f5cf3e3d002aa9,问题反馈_cn.yaml,"@@ -13,12 +13,13 @@ body:
         required: true
       - label: 我已经认真且完整的阅读了 wiki
         required: true
-      - label: 我已经认真检查了问题和网络环境无关
+      - label: 我已经认真检查了问题和网络环境无关（包括但不限于Google不可用，模型下载失败）
         required: true
   - type: markdown
     attributes:
       value: |
         感谢您使用本项目并反馈！
+        请再次确认上述复选框所述的内容已经认真执行！
   - type: textarea
     id: environment
     attributes:
",add jsdoc tag to env.js,
e5d09cdecd24c1eb30ed702b2321be31a51f2839,translator.py,"@@ -105,29 +105,48 @@ class BaseTranslator:
         """"""
         raise NotImplementedError
 
-    def prompt(self, text: str, prompt: Template | None = None) -> list[dict[str, Any]]:
-        if prompt:
-            template_fill_values = {
-                ""lang_in"": self.lang_in,
-                ""lang_out"": self.lang_out,
-                ""text"": text,
-            }
-            prompt_string = prompt.substitute(template_fill_values)
-            prompt_as_json = json.loads(prompt_string)
-            logging.info(""Use the prompt provided by the user."")
-            return prompt_as_json
-
-        return [
+    def prompt(
+        self, text: str, prompt_template: Template | None = None
+    ) -> list[dict[str, Any]]:
+        default_prompt = [
             {
                 ""role"": ""system"",
                 ""content"": ""You are a professional,authentic machine translation engine. Only Output the translated text, do not include any other text."",
             },
             {
                 ""role"": ""user"",
-                ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",  # noqa: E501
+                ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",
             },
         ]
 
+        if prompt_template:
+            template_fill_values = {
+                ""lang_in"": self.lang_in,
+                ""lang_out"": self.lang_out,
+                ""text"": text,
+            }
+            prompt_as_json: list[dict[str, Any]] = json.loads(
+                prompt_template.safe_substitute({})
+            )
+
+            for msg_turn in prompt_as_json:
+                # current is user message turn
+                if msg_turn[""role""] == ""user"":
+                    # substitute values into template variables
+                    msg_turn[""content""] = Template(msg_turn[""content""]).substitute(
+                        template_fill_values
+                    )
+                    logging.info(""Use the prompt provided by the user."")
+                    return prompt_as_json
+
+            logging.warning(""There is no *User message turn* provided in the prompt."")
+            logging.warning(
+                ""The default prompt will be used instead of the user-provided prompt.""
+            )
+
+        logging.info(""Use the default prompt."")
+        return default_prompt
+
     def __str__(self):
         return f""{self.name} {self.lang_in} {self.lang_out} {self.model}""
 
@@ -303,7 +322,6 @@ class OllamaTranslator(BaseTranslator):
             model=self.model,
             messages=self.prompt(text, self.prompt_template),
             options=self.options,
-            stream=False,
         )
         content = self._remove_cot_content(response.message.content or """")
         return content.strip()
",add default_prompt to basetranslator,
a08f108f8403d71c3a60597a57c79f6b4b0f6565,translator.py,"@@ -27,6 +27,9 @@ from tencentcloud.tmt.v20180321.tmt_client import TmtClient
 from pdf2zh.cache import TranslationCache
 from pdf2zh.config import ConfigManager
 import ast
+import logging
+
+logger = logging.getLogger(__name__)
 
 def remove_control_characters(s):
     return """".join(ch for ch in s if unicodedata.category(ch)[0] != ""C"")
@@ -118,34 +121,21 @@ class BaseTranslator:
                 ""content"": f""Translate the following markdown source text to {self.lang_out}. Keep the formula notation {{v*}} unchanged. Output translation directly without any additional text.\nSource Text: {text}\nTranslated Text:"",
             },
         ]
+        try:
+            if prompt_template:
+                template_fill_values = {
+                    ""lang_in"": self.lang_in,
+                    ""lang_out"": self.lang_out,
+                    ""text"": text,
+                }
+                prompt: list[dict[str, Any]] = ast.literal_eval(
+                    prompt_template.safe_substitute(template_fill_values)
+                )
 
-        if prompt_template:
-            template_fill_values = {
-                ""lang_in"": self.lang_in,
-                ""lang_out"": self.lang_out,
-                ""text"": text,
-            }
-            prompt_as_json: list[dict[str, Any]] = ast.literal_eval(
-                prompt_template.safe_substitute({})
-            )
-
-            for msg_turn in prompt_as_json:
-                # current is user message turn
-                if msg_turn[""role""] == ""user"":
-                    # substitute values into template variables
-                    msg_turn[""content""] = Template(msg_turn[""content""]).substitute(
-                        template_fill_values
-                    )
-                    logging.info(""Use the prompt provided by the user."")
-                    return prompt_as_json
-
-            logging.warning(""There is no *User message turn* provided in the prompt."")
-            logging.warning(
-                ""The default prompt will be used instead of the user-provided prompt.""
-            )
-
-        logging.info(""Use the default prompt."")
-        return default_prompt
+                return prompt
+        except Exception:
+            logging.exception(""Error parsing prompt, use the default prompt."")
+            return default_prompt
 
     def __str__(self):
         return f""{self.name} {self.lang_in} {self.lang_out} {self.model}""
",add base translator,
983853ec7974a1dde8547761698b97c179a16413,translator.py,"@@ -142,7 +142,7 @@ class GoogleTranslator(BaseTranslator):
     def __init__(self, lang_in, lang_out, model, **kwargs):
         super().__init__(lang_in, lang_out, model)
         self.session = requests.Session()
-        self.endpoint = ""http://translate.google.com/m""
+        self.endpoint = ""https://translate.google.com/m""
         self.headers = {
             ""User-Agent"": ""Mozilla/4.0 (compatible;MSIE 6.0;Windows NT 5.1;SV1;.NET CLR 1.1.4322;.NET CLR 2.0.50727;.NET CLR 3.0.04506.30)""  # noqa: E501
         }
",add google support,
8d45f6e1f3c7b785bfab7f36699a9eec131bbb51,translator.py,"@@ -132,10 +132,10 @@ class BaseTranslator:
             {
                 ""role"": ""user"",
                 ""content"": (
-                    ""You are a professional,authentic machine translation engine.""
+                    ""You are a professional, authentic machine translation engine. ""
                     ""Only Output the translated text, do not include any other text.""
                     ""\n\n""
-                    f""Translate the following markdown source text to {self.lang_out}.""
+                    f""Translate the following markdown source text to {self.lang_out}. ""
                     ""Keep the formula notation {v*} unchanged. ""
                     ""Output translation directly without any additional text.""
                     ""\n\n""
@@ -308,14 +308,15 @@ class OllamaTranslator(BaseTranslator):
         super().__init__(lang_in, lang_out, model)
         self.options = {
             ""temperature"": 0,  # 随机采样可能会打断公式标记
+            ""num_predict"": 2000,
         }
         self.client = ollama.Client(host=self.envs[""OLLAMA_HOST""])
         self.prompt_template = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
 
     def do_translate(self, text: str) -> str:
-        max_token = {""num_predict"": max(2000, len(text) * 5)}
-        self.options.update(max_token)
+        if (max_token := len(text) * 5) > self.options[""num_predict""]:
+            self.options[""num_predict""] = max_token
 
         response = self.client.chat(
             model=self.model,
",add ollama translator,
8d45f6e1f3c7b785bfab7f36699a9eec131bbb51,test_translator.py,"@@ -2,6 +2,8 @@ import unittest
 from textwrap import dedent
 from unittest import mock
 
+from ollama import ResponseError as OllamaResponseError
+
 from pdf2zh import cache
 from pdf2zh.config import ConfigManager
 from pdf2zh.translator import BaseTranslator, OllamaTranslator, OpenAIlikedTranslator
@@ -151,33 +153,38 @@ class TestOpenAIlikedTranslator(unittest.TestCase):
 
 
 class TestOllamaTranslator(unittest.TestCase):
-    def setUp(self) -> None:
-        self.mock_translator = mock.MagicMock()
-
     def test_do_translate(self):
-        # Create mock client
-        mock_client = mock.MagicMock()
-        mock_response = mock.MagicMock()
-        mock_response.message.content = ""<think>123</think>天空呈现蓝色是因为...""
-        mock_client.chat.return_value = mock_response
-
-        # Create translator with mock client
-        translator = OllamaTranslator(""en"", ""zh"", ""test"")
-        translator.client = mock_client
-
-        # Test translation
-        text = ""The sky appears blue because of...""
-        result = translator.do_translate(text)
-
-        # Verify mock was called correctly
-        mock_client.chat.assert_called_once_with(
-            model=""test"",
-            messages=translator.prompt(text, None),
-            options={""temperature"": 0, ""num_predict"": max(2000, len(text) * 5)},
-        )
+        translator = OllamaTranslator(lang_in=""en"", lang_out=""zh"", model=""test:3b"")
+        with (
+            mock.patch.object(translator, ""client"") as mock_client,
+        ):
+            chat_response = mock_client.chat.return_value
+            chat_response.message.content = dedent(
+                """"""\
+                <think>
+                Thinking...
+                </think>
+                    
+                天空呈现蓝色是因为...
+                """"""
+            )
+
+            text = ""The sky appears blue because of...""
+            translated_result = translator.do_translate(text)
+            mock_client.chat.assert_called_once_with(
+                model=""test:3b"",
+                messages=translator.prompt(text, prompt_template=None),
+                options={
+                    ""temperature"": translator.options[""temperature""],
+                    ""num_predict"": translator.options[""num_predict""],
+                },
+            )
+            self.assertEqual(""天空呈现蓝色是因为..."", translated_result)
 
-        # Verify result
-        self.assertEqual(""天空呈现蓝色是因为..."", result)
+            # response error
+            mock_client.chat.side_effect = OllamaResponseError(""an error status"")
+            with self.assertRaises(OllamaResponseError):
+                mock_client.chat()
 
     def test_remove_cot_content(self):
         fake_cot_resp_text = dedent(
",add tests for ollama translator,
8f96257ae3324808af16684d99f5569824e02859,cache.py,"@@ -1,3 +1,4 @@
+import logging
 import os
 import json
 from peewee import Model, SqliteDatabase, AutoField, CharField, TextField, SQL
@@ -6,7 +7,7 @@ from typing import Optional
 
 # we don't init the database here
 db = SqliteDatabase(None)
-
+logger = logging.getLogger(__name__)
 
 class _TranslationCache(Model):
     id = AutoField()
@@ -82,12 +83,15 @@ class TranslationCache:
         return result.translation if result else None
 
     def set(self, original_text: str, translation: str):
-        _TranslationCache.create(
-            translate_engine=self.translate_engine,
-            translate_engine_params=self.translate_engine_params,
-            original_text=original_text,
-            translation=translation,
-        )
+        try:
+            _TranslationCache.create(
+                translate_engine=self.translate_engine,
+                translate_engine_params=self.translate_engine_params,
+                original_text=original_text,
+                translation=translation,
+            )
+        except Exception as e:
+            logger.debug(f""Error setting cache: {e}"")
 
 
 def init_db(remove_exists=False):
",add missing docstrings,
8f96257ae3324808af16684d99f5569824e02859,test_cache.py,"@@ -159,55 +159,56 @@ class TestCache(unittest.TestCase):
         cache_instance.set(""hello2"", ""你好2"")
         self.assertEqual(cache_instance.get(""hello2""), ""你好2"")
 
-    def test_thread_safety(self):
-        """"""Test thread safety of cache operations""""""
-        cache_instance = cache.TranslationCache(""test_engine"")
-        lock = threading.Lock()
-        results = []
-        num_threads = multiprocessing.cpu_count()
-        items_per_thread = 100
-
-        def generate_random_text(length=10):
-            return """".join(
-                random.choices(string.ascii_letters + string.digits, k=length)
-            )
-
-        def worker():
-            thread_results = []  # 线程本地存储结果
-            for _ in range(items_per_thread):
-                text = generate_random_text()
-                translation = f""翻译_{text}""
-
-                # Write operation
-                cache_instance.set(text, translation)
-
-                # Read operation - verify our own write
-                result = cache_instance.get(text)
-                thread_results.append((text, result))
-
-            # 所有操作完成后，一次性加锁并追加结果
-            with lock:
-                results.extend(thread_results)
-
-        # Create threads equal to CPU core count
-        threads = []
-        for _ in range(num_threads):
-            thread = threading.Thread(target=worker)
-            threads.append(thread)
-            thread.start()
-
-        # Wait for all threads to complete
-        for thread in threads:
-            thread.join()
-
-        # Verify all operations were successful
-        expected_total = num_threads * items_per_thread
-        self.assertEqual(len(results), expected_total)
-
-        # Verify each thread got its correct value
-        for text, result in results:
-            expected = f""翻译_{text}""
-            self.assertEqual(result, expected)
+    # Sometimes the problem of ""database is locked"" occurs. Temporarily disable this test.
+    # def test_thread_safety(self):
+    #     """"""Test thread safety of cache operations""""""
+    #     cache_instance = cache.TranslationCache(""test_engine"")
+    #     lock = threading.Lock()
+    #     results = []
+    #     num_threads = multiprocessing.cpu_count()
+    #     items_per_thread = 100
+
+    #     def generate_random_text(length=10):
+    #         return """".join(
+    #             random.choices(string.ascii_letters + string.digits, k=length)
+    #         )
+
+    #     def worker():
+    #         thread_results = []  # 线程本地存储结果
+    #         for _ in range(items_per_thread):
+    #             text = generate_random_text()
+    #             translation = f""翻译_{text}""
+
+    #             # Write operation
+    #             cache_instance.set(text, translation)
+
+    #             # Read operation - verify our own write
+    #             result = cache_instance.get(text)
+    #             thread_results.append((text, result))
+
+    #         # 所有操作完成后，一次性加锁并追加结果
+    #         with lock:
+    #             results.extend(thread_results)
+
+    #     # Create threads equal to CPU core count
+    #     threads = []
+    #     for _ in range(num_threads):
+    #         thread = threading.Thread(target=worker)
+    #         threads.append(thread)
+    #         thread.start()
+
+    #     # Wait for all threads to complete
+    #     for thread in threads:
+    #         thread.join()
+
+    #     # Verify all operations were successful
+    #     expected_total = num_threads * items_per_thread
+    #     self.assertEqual(len(results), expected_total)
+
+    #     # Verify each thread got its correct value
+    #     for text, result in results:
+    #         expected = f""翻译_{text}""
+    #         self.assertEqual(result, expected)
 
 
 if __name__ == ""__main__"":
",add test for thread safety of cache operations,
a5b881b7f24ee283871f2d978724f9fb1d2756fa,pyproject.toml,"@@ -42,7 +42,7 @@ backend = [
     ""redis""
 ]
 argostranslate = [
-    ""argos-translate""
+    ""argostranslate""
 ]
 
 [dependency-groups]
",add missing comma,
21a2b4fbb735d0557444c887cc17f84d2c4974ee,docker-ghrc-dev.yml,"@@ -6,8 +6,7 @@ on:
 
 env:
   REGISTRY: ghcr.io
-  IMAGE_NAME: ${{ github.repository }}
-  TARGET_PLATFORMS: linux/amd64,linux/arm64
+  REPO_LOWER: ${{ github.repository_owner }}/${{ github.event.repository.name }}
   GHCR_REPO: ghcr.io/${{ github.repository }}
 
 jobs:
@@ -27,6 +26,10 @@ jobs:
       packages: write
       
     steps:
+      - name: Convert to lowercase
+        run: |
+          echo ""GHCR_REPO_LOWER=$(echo ${{ env.GHCR_REPO }} | tr '[:upper:]' '[:lower:]')"" >> $GITHUB_ENV
+
       - name: Prepare
         run: |
           platform=${{ matrix.platform }}
@@ -40,7 +43,7 @@ jobs:
         uses: docker/metadata-action@v5
         with:
           images: |
-            ${{ env.GHCR_REPO }}
+            ${{ env.GHCR_REPO_LOWER }}
 
       - name: Login to GHCR
         uses: docker/login-action@v3
@@ -59,7 +62,7 @@ jobs:
         with:
           platforms: ${{ matrix.platform }}
           labels: ${{ steps.meta.outputs.labels }}
-          outputs: type=image,name=${{ env.GHCR_REPO }},push-by-digest=true,name-canonical=true,push=true
+          outputs: type=image,name=${{ env.GHCR_REPO_LOWER }},push-by-digest=true,name-canonical=true,push=true
 
       - name: Export digest
         run: |
@@ -80,6 +83,10 @@ jobs:
     needs:
       - build
     steps:
+      - name: Convert to lowercase
+        run: |
+          echo ""GHCR_REPO_LOWER=$(echo ${{ env.GHCR_REPO }} | tr '[:upper:]' '[:lower:]')"" >> $GITHUB_ENV
+
       - name: Download digests
         uses: actions/download-artifact@v4
         with:
@@ -102,7 +109,7 @@ jobs:
         uses: docker/metadata-action@v5
         with:
           images: |
-            ${{ env.GHCR_REPO }}
+            ${{ env.GHCR_REPO_LOWER }}
           tags: |
             type=ref,event=branch
             type=ref,event=pr
@@ -113,8 +120,8 @@ jobs:
         working-directory: ${{ runner.temp }}/digests
         run: |
           docker buildx imagetools create $(jq -cr '.tags | map(""-t "" + .) | join("" "")' <<< ""$DOCKER_METADATA_OUTPUT_JSON"") \
-            $(printf '${{ env.GHCR_REPO }}@sha256:%s ' *)
+            $(printf '${{ env.GHCR_REPO_LOWER }}@sha256:%s ' *)
 
       - name: Inspect image
         run: |
-          docker buildx imagetools inspect ${{ env.GHCR_REPO }}:${{ steps.meta.outputs.version }}
\ No newline at end of file
+          docker buildx imagetools inspect ${{ env.GHCR_REPO_LOWER }}:${{ steps.meta.outputs.version }}
\ No newline at end of file
",add more info about the build and commit steps,
a958048ef44d5d8c9ac573ceeab1387ff56f1c82,python-publish.yml,"@@ -183,7 +183,7 @@ jobs:
       - name: Set version from build job
         if: needs.build.outputs.is_release == ''
         run: |
-          uv tools install bumpver
+          uv tool install bumpver
           echo ""Using version: ${{ needs.build.outputs.version }}""
           bumpver update --set-version ${{ needs.build.outputs.version }}
 
",add missing command,
543af18a2c7b409b62be095b64849dc92ea87f19,python-test.yml,"@@ -23,7 +23,7 @@ jobs:
       - uses: actions/checkout@v4
       - name: Cached models
         id: cache-mods
-        uses: actions/cache@v4.2.0
+        uses: actions/cache@v4.2.1
         with:
           path: ~/.cache/huggingface/hub/models--wybxc--DocLayout-YOLO-DocStructBench-onnx
           key: ${{runner.os}}-huggingmodel-wybxc--DocLayout-YOLO-DocStructBench-onnx
",add missing script tag,
3f742fb0053030cbb977df1d226c15f23d71f978,python-publish.yml,"@@ -16,7 +16,7 @@ env:
   REPO_LOWER: ${{ github.repository_owner }}/${{ github.event.repository.name }}
   GHCR_REPO: ghcr.io/${{ github.repository }}
   DOCKERHUB_REPO: byaidu/pdf2zh
-  WIN_EXE_PYTHON_VERSION: 3.12.9
+  WIN_EXE_PYTHON_VERSION: ""3.12.9""
 
 jobs:
   check-repository:
@@ -340,6 +340,7 @@ jobs:
           Get-ChildItem -Path ""./"" -Exclude ""dep_build"", ""build"" | Copy-Item -Destination ""./dep_build"" -Recurse -Force
 
           Write-Host ""==== 下载并解压 Python ${{ env.WIN_EXE_PYTHON_VERSION }} ====""
+          Write-Host ""pythonUrl: https://www.python.org/ftp/python/{{ env.WIN_EXE_PYTHON_VERSION }}/python-{{ env.WIN_EXE_PYTHON_VERSION }}-embed-amd64.zip""
           $pythonUrl = ""https://www.python.org/ftp/python/{{ env.WIN_EXE_PYTHON_VERSION }}/python-{{ env.WIN_EXE_PYTHON_VERSION }}-embed-amd64.zip""
           $pythonZip = ""./dep_build/python.zip""
           Invoke-WebRequest -Uri $pythonUrl -OutFile $pythonZip
",add win_explorer_build script,
cf5c4c945953ce413a4556e207c2c570207b940a,python-publish.yml,"@@ -489,7 +489,7 @@ jobs:
           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
         run: |
           # Get the latest release (including drafts and pre-releases)
-          LATEST_RELEASE=needs.release-draft.outputs.tag_name
+          LATEST_RELEASE=${{ needs.release-draft.outputs.tag_name }}
           echo ""Latest release tag: $LATEST_RELEASE""
           
           # Upload the zip file to the release
",add missing example,
30a4c42b8243c50fa8c74c36e8c896717a851c6c,python-publish.yml,"@@ -257,6 +257,7 @@ jobs:
       - build-docker-image
       - check-repository
       - test-win64-exe
+      - build
     if: needs.check-repository.outputs.is_main_repo == 'true'
     steps:
       - name: Convert to lowercase
",add missing comment,
f56a7d12accaeb59ae578fe00d1d2277bf0553ff,translator.py,"@@ -423,6 +423,9 @@ class OpenAITranslator(BaseTranslator):
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
+        think_filter_regex = r""^<think>.+?\n*(</think>|\n)+(</think>)\n*""
+        self.add_cache_impact_parameters('think_filter_regex', think_filter_regex)
+        self.think_filter_regex = re.compile(think_filter_regex, flags=re.DOTALL)
 
     def do_translate(self, text) -> str:
         response = self.client.chat.completions.create(
@@ -434,7 +437,7 @@ class OpenAITranslator(BaseTranslator):
             if hasattr(response, ""error""):
                 raise ValueError(""Error response from Service"", response.error)
         content = response.choices[0].message.content.strip()
-        content = re.sub(r""^<think>.+?</think>"", """", content, flags=re.DOTALL).strip()
+        content = self.think_filter_regex.sub("""", content).strip()
         return content
 
     def get_formular_placeholder(self, id: int):
",add some more info to the translator,
a0e6c288f27c214a5c6063c2655c64c3532c8d83,translator.py,"@@ -423,7 +423,7 @@ class OpenAITranslator(BaseTranslator):
         self.prompttext = prompt
         self.add_cache_impact_parameters(""temperature"", self.options[""temperature""])
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
-        think_filter_regex = r""^<think>.+?\n*(</think>|\n)+(</think>)\n*""
+        think_filter_regex = r""^<think>.+?\n*(</think>|\n)*(</think>)\n*""
         self.add_cache_impact_parameters('think_filter_regex', think_filter_regex)
         self.think_filter_regex = re.compile(think_filter_regex, flags=re.DOTALL)
 
",fix typo in openai_translator.py,
171192bd5a61edfba33f3a120af89fc65d1261b4,fork-build.yml,"@@ -231,15 +231,26 @@ jobs:
           $sourcePath = Resolve-Path ""./dep_build/venv/Lib/site-packages""
           $targetPath = ""./build/site-packages""
           
-          # 在 Windows 上创建目录符号链接 (需要管理员权限)
-          # 在 GitHub Actions 上使用 mklink /J (junction) 不需要管理员权限
-          cmd /c mklink /J ""$targetPath"" ""$sourcePath""
-          
-          if (-not (Test-Path $targetPath)) {
-              Write-Host ""警告: 创建软链接失败，回退到复制方式""
+          try {
+              # 确保目标路径的父目录存在，但目标路径本身不存在
+              if (Test-Path $targetPath) {
+                  Remove-Item -Path $targetPath -Recurse -Force
+              }
+              
+              # 使用完整路径并用双引号包围路径
+              $command = ""cmd.exe /c mklink /J `""$targetPath`"" `""$sourcePath`""""
+              Write-Host ""执行命令: $command""
+              Invoke-Expression $command
+              
+              if (Test-Path $targetPath) {
+                  Write-Host ""成功创建软链接: $targetPath -> $sourcePath""
+              } else {
+                  throw ""软链接创建后无法访问""
+              }
+          } catch {
+              Write-Host ""警告: 创建软链接失败，错误信息: $_""
+              Write-Host ""回退到复制方式""
               Copy-Item -Path ""$sourcePath"" -Destination ""$targetPath"" -Recurse -Force
-          } else {
-              Write-Host ""成功创建软链接: $targetPath -> $sourcePath""
           }
 
           Write-Host ""==== 复制 script/_pystand_static.int 到 build/ ====""
",add test for mklink,
4b024fe100603dde684dbda0acf46d87773414e4,fork-build.yml,"@@ -157,19 +157,6 @@ jobs:
       - check-repository
     if: needs.check-repository.outputs.is_main_repo != 'true'
     steps:
-      - name: checkout babeldoc metadata
-        uses: actions/checkout@v4
-        with:
-          repository: funstory-ai/BabelDOC
-          path: babeldoctemp1234567
-          token: ${{ secrets.GITHUB_TOKEN }}
-          sparse-checkout: babeldoc/assets/embedding_assets_metadata.py
-      - name: Cached Assets
-        id: cache-assets
-        uses: actions/cache@v4.2.0
-        with:
-          path: ~/.cache/babeldoc
-          key: test-1-babeldoc-assets-${{ hashFiles('babeldoctemp1234567/babeldoc/assets/embedding_assets_metadata.py') }}
       - name: 检出代码
         uses: actions/checkout@v4
 
",add missing test,
4b024fe100603dde684dbda0acf46d87773414e4,python-publish.yml,"@@ -24,7 +24,7 @@ jobs:
     runs-on: ubuntu-latest
     outputs:
       # debug purpose
-      is_main_repo: ${{ github.repository != 'Byaidu/PDFMathTranslate' }}
+      is_main_repo: ${{ github.repository == 'Byaidu/PDFMathTranslate' }}
     steps:
       - run: echo ""Running repository check""
 
@@ -321,6 +321,19 @@ jobs:
       - check-repository
     if: needs.check-repository.outputs.is_main_repo == 'true'
     steps:
+      - name: checkout babeldoc metadata
+        uses: actions/checkout@v4
+        with:
+          repository: funstory-ai/BabelDOC
+          path: babeldoctemp1234567
+          token: ${{ secrets.GITHUB_TOKEN }}
+          sparse-checkout: babeldoc/assets/embedding_assets_metadata.py
+      - name: Cached Assets
+        id: cache-assets
+        uses: actions/cache@v4.2.0
+        with:
+          path: ~/.cache/babeldoc
+          key: test-1-babeldoc-assets-${{ hashFiles('babeldoctemp1234567/babeldoc/assets/embedding_assets_metadata.py') }}
       - name: 检出代码
         uses: actions/checkout@v4
 
",add test for repository check,
9823cbd73305c93b98dc506e88ecf8e25f74891b,translator.py,"@@ -428,17 +428,24 @@ class OpenAITranslator(BaseTranslator):
         self.think_filter_regex = re.compile(think_filter_regex, flags=re.DOTALL)
 
     def do_translate(self, text) -> str:
-        response = self.client.chat.completions.create(
-            model=self.model,
-            **self.options,
-            messages=self.prompt(text, self.prompttext),
-        )
-        if not response.choices:
-            if hasattr(response, ""error""):
-                raise ValueError(""Error response from Service"", response.error)
-        content = response.choices[0].message.content.strip()
-        content = self.think_filter_regex.sub("""", content).strip()
-        return content
+        try:
+            response = self.client.chat.completions.create(
+                model=self.model,
+                **self.options,
+                messages=self.prompt(text, self.prompttext),
+            )
+            if not response.choices:
+                if hasattr(response, ""error""):
+                    raise ValueError(""Error response from Service"", response.error)
+            content = response.choices[0].message.content.strip()
+            content = self.think_filter_regex.sub("""", content).strip()
+            return content
+        except openai.RateLimitError:
+            # 遇到速率限制错误时暂停6秒
+            import time
+            time.sleep(6)
+            # 重试一次
+            return self.do_translate(self, text)
 
     def get_formular_placeholder(self, id: int):
         return ""{{v"" + str(id) + ""}}""
",add retry to openai translator,
ad48d86460615c6c2b07f7bee431d567e2e26fe5,exe-build.yml,"@@ -24,7 +24,7 @@ jobs:
           sparse-checkout: babeldoc/assets/embedding_assets_metadata.py
       - name: Cached Assets
         id: cache-assets
-        uses: actions/cache@v4.2.0
+        uses: actions/cache@v4.2.2
         with:
           path: ~/.cache/babeldoc
           key: test-1-babeldoc-assets-${{ hashFiles('babeldoctemp1234567/babeldoc/assets/embedding_assets_metadata.py') }}
",add missing test for,
ad48d86460615c6c2b07f7bee431d567e2e26fe5,python-publish.yml,"@@ -330,7 +330,7 @@ jobs:
           sparse-checkout: babeldoc/assets/embedding_assets_metadata.py
       - name: Cached Assets
         id: cache-assets
-        uses: actions/cache@v4.2.0
+        uses: actions/cache@v4.2.2
         with:
           path: ~/.cache/babeldoc
           key: test-1-babeldoc-assets-${{ hashFiles('babeldoctemp1234567/babeldoc/assets/embedding_assets_metadata.py') }}
",add missing test,
ad48d86460615c6c2b07f7bee431d567e2e26fe5,python-test.yml,"@@ -29,7 +29,7 @@ jobs:
           sparse-checkout: babeldoc/assets/embedding_assets_metadata.py
       - name: Cached Assets
         id: cache-assets
-        uses: actions/cache@v4.2.0
+        uses: actions/cache@v4.2.2
         with:
           path: ~/.cache/babeldoc
           key: test-1-babeldoc-assets-${{ hashFiles('babeldoctemp1234567/babeldoc/assets/embedding_assets_metadata.py') }}
",add missing test,
038c0bd0e241f2b8191bcb5655c4b297c58f63b1,high_level.py,"@@ -365,8 +365,17 @@ def translate(
         s_raw = doc_raw.read()
         doc_raw.close()
 
-        if file.startswith(tempfile.gettempdir()):
-            os.unlink(file)
+        temp_dir = Path(tempfile.gettempdir())
+        file_path = Path(file)
+        try:
+            if file_path.exists() and file_path.resolve().is_relative_to(
+                temp_dir.resolve()
+            ):
+                file_path.unlink(missing_ok=True)
+                logger.debug(f""Cleaned temp file: {file_path}"")
+        except Exception as e:
+            logger.warning(f""Failed to clean temp file {file_path}"", exc_info=True)
+
         s_mono, s_dual = translate_stream(
             s_raw,
             **locals(),
",fix translate function,
1da044a29ac64ac86521c3ad55be57549098c00b,gui.py,"@@ -148,6 +148,7 @@ def download_with_limit(url: str, save_path: str, size_limit: int) -> str:
             filename = params[""filename""]
         except Exception:  # filename from url
             filename = os.path.basename(url)
+        filename = os.path.splitext(os.path.basename(filename))[0] + "".pdf""
         with open(save_path / filename, ""wb"") as file:
             for chunk in response.iter_content(chunk_size=chunk_size):
                 total_size += len(chunk)
",add support for large downloads,
29988ceb72f755d9ffc1c25f46f2f3fb2c943c78,translator.py,"@@ -36,6 +36,11 @@ from pdf2zh.cache import TranslationCache
 from pdf2zh.config import ConfigManager
 
 
+from tenacity import retry, retry_if_exception_type
+from tenacity import stop_after_attempt
+from tenacity import wait_exponential
+
+
 def remove_control_characters(s):
     return """".join(ch for ch in s if unicodedata.category(ch)[0] != ""C"")
 
@@ -427,6 +432,15 @@ class OpenAITranslator(BaseTranslator):
         self.add_cache_impact_parameters(""think_filter_regex"", think_filter_regex)
         self.think_filter_regex = re.compile(think_filter_regex, flags=re.DOTALL)
 
+    @retry(
+        retry=retry_if_exception_type(openai.RateLimitError),
+        stop=stop_after_attempt(100),
+        wait=wait_exponential(multiplier=1, min=1, max=15),
+        before_sleep=lambda retry_state: logger.warning(
+            f""RateLimitError, retrying in {retry_state.next_action.sleep} seconds... ""
+            f""(Attempt {retry_state.attempt_number}/3)""
+        ),
+    )
     def do_translate(self, text) -> str:
         try:
             response = self.client.chat.completions.create(
@@ -445,7 +459,7 @@ class OpenAITranslator(BaseTranslator):
             import time
             time.sleep(6)
             # 重试一次
-            return self.do_translate(self, text)
+            return self.do_translate(text)
 
     def get_formular_placeholder(self, id: int):
         return ""{{v"" + str(id) + ""}}""
",add openai translator,
5b658dcf554de82e62a1fcfbbcb4bad1360a82b1,translator.py,"@@ -442,24 +442,17 @@ class OpenAITranslator(BaseTranslator):
         ),
     )
     def do_translate(self, text) -> str:
-        try:
-            response = self.client.chat.completions.create(
-                model=self.model,
-                **self.options,
-                messages=self.prompt(text, self.prompttext),
-            )
-            if not response.choices:
-                if hasattr(response, ""error""):
-                    raise ValueError(""Error response from Service"", response.error)
-            content = response.choices[0].message.content.strip()
-            content = self.think_filter_regex.sub("""", content).strip()
-            return content
-        except openai.RateLimitError:
-            # 遇到速率限制错误时暂停6秒
-            import time
-            time.sleep(6)
-            # 重试一次
-            return self.do_translate(text)
+        response = self.client.chat.completions.create(
+            model=self.model,
+            **self.options,
+            messages=self.prompt(text, self.prompttext),
+        )
+        if not response.choices:
+            if hasattr(response, ""error""):
+                raise ValueError(""Error response from Service"", response.error)
+        content = response.choices[0].message.content.strip()
+        content = self.think_filter_regex.sub("""", content).strip()
+        return content
 
     def get_formular_placeholder(self, id: int):
         return ""{{v"" + str(id) + ""}}""
",add retry to openai translator,
5663206e01bbb9e43a7edb168a6db6e0b53410b9,translator.py,"@@ -438,7 +438,7 @@ class OpenAITranslator(BaseTranslator):
         wait=wait_exponential(multiplier=1, min=1, max=15),
         before_sleep=lambda retry_state: logger.warning(
             f""RateLimitError, retrying in {retry_state.next_action.sleep} seconds... ""
-            f""(Attempt {retry_state.attempt_number}/3)""
+            f""(Attempt {retry_state.attempt_number}/100)""
         ),
     )
     def do_translate(self, text) -> str:
",add more retry logic to openai translator,
79eeb76a6786a3bd39ae5c84ca853254cc56b15e,pdf2zh.py,"@@ -389,7 +389,12 @@ def yadt_main(parsed_args) -> int:
     ]:
         if service_name == translator.name:
             translator = translator(
-                lang_in, lang_out, service_model, envs=envs, prompt=prompt, ignore_cache=ignore_cache
+                lang_in,
+                lang_out,
+                service_model,
+                envs=envs,
+                prompt=prompt,
+                ignore_cache=ignore_cache,
             )
             break
     else:
",fix yadt command,
79eeb76a6786a3bd39ae5c84ca853254cc56b15e,translator.py,"@@ -252,7 +252,9 @@ class DeepLTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs
+    ):
         self.set_envs(envs)
         super().__init__(lang_in, lang_out, model, ignore_cache)
         auth_key = self.envs[""DEEPL_AUTH_KEY""]
@@ -274,7 +276,9 @@ class DeepLXTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs
+    ):
         self.set_envs(envs)
         super().__init__(lang_in, lang_out, model, ignore_cache)
         self.endpoint = self.envs[""DEEPLX_ENDPOINT""]
@@ -357,7 +361,9 @@ class XinferenceTranslator(BaseTranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         if not model:
             model = self.envs[""XINFERENCE_MODEL""]
@@ -536,7 +542,14 @@ class ModelScopeTranslator(OpenAITranslator):
         api_key = self.envs[""MODELSCOPE_API_KEY""]
         if not model:
             model = self.envs[""MODELSCOPE_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
 
@@ -550,13 +563,22 @@ class ZhipuTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://open.bigmodel.cn/api/paas/v4""
         api_key = self.envs[""ZHIPU_API_KEY""]
         if not model:
             model = self.envs[""ZHIPU_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
 
@@ -586,13 +608,22 @@ class SiliconTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://api.siliconflow.cn/v1""
         api_key = self.envs[""SILICON_API_KEY""]
         if not model:
             model = self.envs[""SILICON_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
 
@@ -606,13 +637,22 @@ class GeminiTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://generativelanguage.googleapis.com/v1beta/openai/""
         api_key = self.envs[""GEMINI_API_KEY""]
         if not model:
             model = self.envs[""GEMINI_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
         self.add_cache_impact_parameters(""prompt"", self.prompt("""", self.prompttext))
 
@@ -626,7 +666,9 @@ class AzureTranslator(BaseTranslator):
     }
     lang_map = {""zh"": ""zh-Hans""}
 
-    def __init__(self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs
+    ):
         self.set_envs(envs)
         super().__init__(lang_in, lang_out, model, ignore_cache)
         endpoint = self.envs[""AZURE_ENDPOINT""]
@@ -657,7 +699,9 @@ class TencentTranslator(BaseTranslator):
         ""TENCENTCLOUD_SECRET_KEY"": None,
     }
 
-    def __init__(self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, ignore_cache=False, **kwargs
+    ):
         self.set_envs(envs)
         super().__init__(lang_in, lang_out, model, ignore_cache)
         cred = credential.DefaultCredentialProvider().get_credential()
@@ -681,7 +725,9 @@ class AnythingLLMTranslator(BaseTranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_out, lang_in, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_out, lang_in, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         super().__init__(lang_out, lang_in, model, ignore_cache)
         self.api_url = self.envs[""AnythingLLM_URL""]
@@ -718,7 +764,9 @@ class DifyTranslator(BaseTranslator):
         ""DIFY_API_KEY"": None,  # 替换为实际 API 密钥
     }
 
-    def __init__(self, lang_out, lang_in, model, envs=None, ignore_cache=False, **kwargs):
+    def __init__(
+        self, lang_out, lang_in, model, envs=None, ignore_cache=False, **kwargs
+    ):
         self.set_envs(envs)
         super().__init__(lang_out, lang_in, model, ignore_cache)
         self.api_url = self.envs[""DIFY_API_URL""]
@@ -800,13 +848,22 @@ class GorkTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://api.x.ai/v1""
         api_key = self.envs[""GORK_API_KEY""]
         if not model:
             model = self.envs[""GORK_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
 
 
@@ -818,13 +875,22 @@ class GroqTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://api.groq.com/openai/v1""
         api_key = self.envs[""GROQ_API_KEY""]
         if not model:
             model = self.envs[""GROQ_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
 
 
@@ -836,13 +902,22 @@ class DeepseekTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://api.deepseek.com/v1""
         api_key = self.envs[""DEEPSEEK_API_KEY""]
         if not model:
             model = self.envs[""DEEPSEEK_MODEL""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
 
 
@@ -855,7 +930,9 @@ class OpenAIlikedTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         if self.envs[""OPENAILIKED_BASE_URL""]:
             base_url = self.envs[""OPENAILIKED_BASE_URL""]
@@ -870,7 +947,14 @@ class OpenAIlikedTranslator(OpenAITranslator):
             api_key = ""openailiked""
         else:
             api_key = self.envs[""OPENAILIKED_API_KEY""]
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
 
 
@@ -889,7 +973,9 @@ class QwenMtTranslator(OpenAITranslator):
     }
     CustomPrompt = True
 
-    def __init__(self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False):
+    def __init__(
+        self, lang_in, lang_out, model, envs=None, prompt=None, ignore_cache=False
+    ):
         self.set_envs(envs)
         base_url = ""https://dashscope.aliyuncs.com/compatible-mode/v1""
         api_key = self.envs[""ALI_API_KEY""]
@@ -897,7 +983,14 @@ class QwenMtTranslator(OpenAITranslator):
         if not model:
             model = self.envs[""ALI_MODEL""]
 
-        super().__init__(lang_in, lang_out, model, base_url=base_url, api_key=api_key, ignore_cache=ignore_cache)
+        super().__init__(
+            lang_in,
+            lang_out,
+            model,
+            base_url=base_url,
+            api_key=api_key,
+            ignore_cache=ignore_cache,
+        )
         self.prompttext = prompt
 
     @staticmethod
",add missing docstrings,
79eeb76a6786a3bd39ae5c84ca853254cc56b15e,test_translator.py,"@@ -30,7 +30,7 @@ class TestTranslator(unittest.TestCase):
         cache.clean_test_db(self.test_db)
 
     def test_cache(self):
-        translator = AutoIncreaseTranslator(""en"", ""zh"", ""test"")
+        translator = AutoIncreaseTranslator(""en"", ""zh"", ""test"", False)
         # First translation should be cached
         text = ""Hello World""
         first_result = translator.translate(text)
@@ -50,7 +50,7 @@ class TestTranslator(unittest.TestCase):
         self.assertNotEqual(first_result, no_cache_result)
 
     def test_add_cache_impact_parameters(self):
-        translator = AutoIncreaseTranslator(""en"", ""zh"", ""test"")
+        translator = AutoIncreaseTranslator(""en"", ""zh"", ""test"", False)
 
         # Test cache with added parameters
         text = ""Hello World""
@@ -78,7 +78,7 @@ class TestTranslator(unittest.TestCase):
         self.assertNotEqual(second_result, another_result)
 
     def test_base_translator_throw(self):
-        translator = BaseTranslator(""en"", ""zh"", ""test"")
+        translator = BaseTranslator(""en"", ""zh"", ""test"", False)
         with self.assertRaises(NotImplementedError):
             translator.translate(""Hello World"")
 
",add tests for translation,
a109c3abdcd9e020f68ac4299b9bdf43f4664a99,README_zh-CN.md,"@@ -36,7 +36,7 @@
 科学 PDF 文档翻译及双语对照工具
 
 - 📊 保留公式、图表、目录和注释 *([预览效果](#preview))*
-- 🌐 支持 [多种语言](#language) 和 [诸多翻译服务](#services)
+- 🌐 支持 [多种语言](./ADVANCED.md#language) 和 [诸多翻译服务](./ADVANCED.md#services)
 - 🤖 提供 [命令行工具](#usage)，[图形交互界面](#gui)，以及 [容器化部署](#docker)
 
 欢迎在 [GitHub Issues](https://github.com/Byaidu/PDFMathTranslate/issues) 或 [Telegram 用户群](https://t.me/+Z9_SgnxmsmA5NzBl)
@@ -103,7 +103,7 @@
 </details>
 
 <details>
-  <summary>3. 图形用户界面</summary>
+  <summary id=""gui"">3. 图形用户界面</summary>
 1. 安装 Python (3.10 <= 版本 <= 3.12)
 2. 安装我们的包：
 
@@ -130,7 +130,7 @@ pip install pdf2zh
 </details>
 
 <details>
-  <summary>4. Docker</summary>
+  <summary id=""docker"">4. Docker</summary>
 
 1. 拉取并运行：
 
@@ -242,7 +242,8 @@ $env:HF_ENDPOINT = https://hf-mirror.com
 | `--config`   | [配置文件](https://github.com/Byaidu/PDFMathTranslate/blob/main/docs/ADVANCED.md#cofig)                       | `pdf2zh --config /path/to/config/config.json`  |
 | `--serverport` | [自定义 gradio 服务器端口]                                                                                 | `pdf2zh --serverport 7860`                     |
 | `--babeldoc`| 使用实验性后端 [BabelDOC](https://funstory-ai.github.io/BabelDOC/) 翻译 |`pdf2zh --babeldoc` -s openai example.pdf|
-|有关详细说明，请参阅我们的文档 [高级用法](./ADVANCED.md)，以获取每个选项的完整列表。|||
+
+有关详细说明，请参阅我们的文档 [高级用法](./ADVANCED.md)，以获取每个选项的完整列表。
 
 <h2 id=""downstream"">二次开发 (API)</h2>
 
",add examples to the examples,
df286b5ab84cb5319a20f61fc6434db40b5d799c,translator.py,"@@ -7,17 +7,6 @@ import unicodedata
 from copy import copy
 from string import Template
 from typing import cast
-
-logger = logging.getLogger(__name__)
-
-try:
-    import argostranslate.package
-    import argostranslate.translate
-except ImportError:
-    logger.warning(
-        ""argos-translate is not installed, if you want to use argostranslate, please install it. If you don't use argostranslate translator, you can safely ignore this warning.""
-    )
-
 import deepl
 import ollama
 import openai
@@ -41,6 +30,17 @@ from tenacity import stop_after_attempt
 from tenacity import wait_exponential
 
 
+logger = logging.getLogger(__name__)
+
+try:
+    import argostranslate.package
+    import argostranslate.translate
+except ImportError:
+    logger.warning(
+        ""argos-translate is not installed, if you want to use argostranslate, please install it. If you don't use argostranslate translator, you can safely ignore this warning.""
+    )
+
+
 def remove_control_characters(s):
     return """".join(ch for ch in s if unicodedata.category(ch)[0] != ""C"")
 
@@ -50,7 +50,7 @@ class BaseTranslator:
     envs = {}
     lang_map: dict[str, str] = {}
     CustomPrompt = False
-    ignore_cache = False
+    ignore_cache = True
 
     def __init__(self, lang_in: str, lang_out: str, model: str):
         lang_in = self.lang_map.get(lang_in.lower(), lang_in)
@@ -656,7 +656,13 @@ class TencentTranslator(BaseTranslator):
     def __init__(self, lang_in, lang_out, model, envs=None, **kwargs):
         self.set_envs(envs)
         super().__init__(lang_in, lang_out, model)
-        cred = credential.DefaultCredentialProvider().get_credential()
+        try:
+            cred = credential.DefaultCredentialProvider().get_credential()
+        except EnvironmentError:
+            cred = credential.Credential(
+                self.envs[""TENCENTCLOUD_SECRET_ID""],
+                self.envs[""TENCENTCLOUD_SECRET_KEY""],
+            )
         self.client = TmtClient(cred, ""ap-beijing"")
         self.req = TextTranslateRequest()
         self.req.Source = self.lang_in
",add more translations,
81261e6471a596d8f1fb75b136eb6596b35d0eb0,translator.py,"@@ -50,7 +50,7 @@ class BaseTranslator:
     envs = {}
     lang_map: dict[str, str] = {}
     CustomPrompt = False
-    ignore_cache = True
+    ignore_cache = False
 
     def __init__(self, lang_in: str, lang_out: str, model: str):
         lang_in = self.lang_map.get(lang_in.lower(), lang_in)
",add missing comments,
53d21825e88777433df487cdf9b48e1b86237590,converter.py,"@@ -28,7 +28,7 @@ from pdf2zh.translator import (
     DifyTranslator,
     GeminiTranslator,
     GoogleTranslator,
-    GorkTranslator,
+    GrokTranslator,
     GroqTranslator,
     ModelScopeTranslator,
     OllamaTranslator,
@@ -159,7 +159,7 @@ class TranslateConverter(PDFConverterEx):
         if not envs:
             envs = {}
         for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, XinferenceTranslator, AzureOpenAITranslator,
-                           OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GorkTranslator, GroqTranslator, DeepseekTranslator, OpenAIlikedTranslator, QwenMtTranslator,]:
+                           OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GrokTranslator, GroqTranslator, DeepseekTranslator, OpenAIlikedTranslator, QwenMtTranslator,]:
             if service_name == translator.name:
                 self.translator = translator(lang_in, lang_out, service_model, envs=envs, prompt=prompt, ignore_cache=ignore_cache)
         if not self.translator:
",add support for custom language files,
53d21825e88777433df487cdf9b48e1b86237590,gui.py,"@@ -6,6 +6,7 @@ from tracemalloc import Snapshot
 import uuid
 from asyncio import CancelledError
 from pathlib import Path
+import typing as T
 
 import gradio as gr
 import requests
@@ -37,7 +38,7 @@ from pdf2zh.translator import (
     TencentTranslator,
     XinferenceTranslator,
     ZhipuTranslator,
-    GorkTranslator,
+    GrokTranslator,
     GroqTranslator,
     DeepseekTranslator,
     OpenAIlikedTranslator,
@@ -67,7 +68,7 @@ service_map: dict[str, BaseTranslator] = {
     ""Dify"": DifyTranslator,
     ""AnythingLLM"": AnythingLLMTranslator,
     ""Argos Translate"": ArgosTranslator,
-    ""Grok"": GorkTranslator,
+    ""Grok"": GrokTranslator,
     ""Groq"": GroqTranslator,
     ""DeepSeek"": DeepseekTranslator,
     ""OpenAI-liked"": OpenAIlikedTranslator,
@@ -113,6 +114,16 @@ if ConfigManager.get(""PDF2ZH_DEMO""):
     server_key = ConfigManager.get(""PDF2ZH_SERVER_KEY"")
 
 
+# Limit Enabled Services
+enabled_services: T.Optional[T.List[str]] = ConfigManager.get(""ENABLED_SERVICES"")
+if isinstance(enabled_services, list):
+    enabled_services_names = [str(_).lower().strip() for _ in enabled_services]
+    enabled_services = [k for k in service_map.keys() if str(k).lower().strip() in enabled_services_names]
+    assert(enabled_services)
+
+# Configure about Gradio show keys
+hidden_gradio_details: bool = bool(ConfigManager.get(""HIDDEN_GRADIO_DETAILS""))
+
 # Public demo control
 def verify_recaptcha(response):
     """"""
@@ -358,7 +369,7 @@ def babeldoc_translate_file(**kwargs):
         AnythingLLMTranslator,
         XinferenceTranslator,
         ArgosTranslator,
-        GorkTranslator,
+        GrokTranslator,
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
@@ -383,7 +394,7 @@ def babeldoc_translate_file(**kwargs):
         DifyTranslator,
         AnythingLLMTranslator,
         ArgosTranslator,
-        GorkTranslator,
+        GrokTranslator,
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
@@ -563,8 +574,8 @@ with gr.Blocks(
             gr.Markdown(""## Option"")
             service = gr.Dropdown(
                 label=""Service"",
-                choices=service_map.keys(),
-                value=""Google"",
+                choices=enabled_services,
+                value="""",
             )
             envs = []
             for i in range(3):
@@ -622,12 +633,18 @@ with gr.Blocks(
                 for i in range(4):
                     _envs.append(gr.update(visible=False, value=""""))
                 for i, env in enumerate(translator.envs.items()):
-                    _envs[i] = gr.update(
-                        visible=True,
-                        label=env[0],
-                        value=ConfigManager.get_env_by_translatername(
+                    label = env[0]
+                    value = ConfigManager.get_env_by_translatername(
                             translator, env[0], env[1]
-                        ),
+                        )
+                    if ""MODEL"" not in str(env[0]).upper() and value and hidden_gradio_details:
+                        visible = False
+                    else:
+                        visible = True
+                    _envs[i] = gr.update(
+                        visible=visible,
+                        label=label,
+                        value=value,
                     )
                 _envs[-1] = gr.update(visible=translator.CustomPrompt)
                 return _envs
","add support for -37,7 +38,7",
53d21825e88777433df487cdf9b48e1b86237590,pdf2zh.py,"@@ -356,7 +356,7 @@ def yadt_main(parsed_args) -> int:
         AnythingLLMTranslator,
         XinferenceTranslator,
         ArgosTranslator,
-        GorkTranslator,
+        GrokTranslator,
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
@@ -381,7 +381,7 @@ def yadt_main(parsed_args) -> int:
         DifyTranslator,
         AnythingLLMTranslator,
         ArgosTranslator,
-        GorkTranslator,
+        GrokTranslator,
         GroqTranslator,
         DeepseekTranslator,
         OpenAIlikedTranslator,
",add missing comments,
53d21825e88777433df487cdf9b48e1b86237590,translator.py,"@@ -845,7 +845,7 @@ class ArgosTranslator(BaseTranslator):
         return translatedText
 
 
-class GorkTranslator(OpenAITranslator):
+class GrokTranslator(OpenAITranslator):
     # https://docs.x.ai/docs/overview#getting-started
     name = ""grok""
     envs = {
",add missing doc for grok translator,
18431981f346e0de82268dce21c86ae563e4d3d4,gui.py,"@@ -121,7 +121,7 @@ if isinstance(enabled_services, list):
     enabled_services_names = [str(_).lower().strip() for _ in enabled_services]
     enabled_services = [k for k in service_map.keys() if str(k).lower().strip() in enabled_services_names]
     if len(enabled_services) == 0:
-        raise RuntimeError(f'There is not available services.')
+        raise RuntimeError(f'No services available.')
     enabled_services = default_services + enabled_services
 else:
     enabled_services = list(service_map.keys())
",fix error when no services are available,
3ea6237cba130718e7d66c4f773f01b407b9cf4c,gui.py,"@@ -720,6 +720,11 @@ with gr.Blocks(
                 service,
                 envs,
             )
+            vfont.change(
+                on_vfont_change,
+                inputs=vfont,
+                outputs=None
+            )
             file_type.select(
                 on_select_filetype,
                 file_type,
",add missing missing vfont/filetype,
9254718f4746b131b2a4135f01f2aaf758849419,translator.py,"@@ -802,7 +802,7 @@ class DifyTranslator(BaseTranslator):
         response_data = response.json()
 
         # 解析响应
-        return response_data.get(""data"", {}).get(""outputs"", {}).get(""text"", [])
+        return response_data.get(""answer"", '')
 
 
 class ArgosTranslator(BaseTranslator):
",add missing doc block,
0907d630598cf64fb7bfbabcce1d41f0eaa540a1,pyproject.toml,"@@ -20,7 +20,7 @@ dependencies = [
     ""ollama"",
     ""xinference-client"",
     ""deepl"",
-    ""openai"",
+    ""openai>=1.0.0"",
     ""azure-ai-translation-text<=1.0.1"",
     ""gradio"",
     ""huggingface_hub"",
",add missing dependencies,
70c4a3dbcc2cc8f04f7f60b5b0b6669c181e7b22,translator.py,"@@ -470,6 +470,7 @@ class AzureOpenAITranslator(BaseTranslator):
         ""AZURE_OPENAI_BASE_URL"": None,  # e.g. ""https://xxx.openai.azure.com""
         ""AZURE_OPENAI_API_KEY"": None,
         ""AZURE_OPENAI_MODEL"": ""gpt-4o-mini"",
+        ""AZURE_API_VERSION"": ""2024-06-01"",  # default api version
     }
     CustomPrompt = True
 
@@ -488,12 +489,15 @@ class AzureOpenAITranslator(BaseTranslator):
         base_url = self.envs[""AZURE_OPENAI_BASE_URL""]
         if not model:
             model = self.envs[""AZURE_OPENAI_MODEL""]
+        api_version = self.envs.get(""AZURE_API_VERSION"", ""2024-06-01"")
+        if api_key is None:
+            api_key = self.envs[""AZURE_OPENAI_API_KEY""]
         super().__init__(lang_in, lang_out, model, ignore_cache)
         self.options = {""temperature"": 0}
         self.client = openai.AzureOpenAI(
             azure_endpoint=base_url,
             azure_deployment=model,
-            api_version=""2024-06-01"",
+            api_version=api_version,
             api_key=api_key,
         )
         self.prompttext = prompt
",add custom prompt to azure openai translator,
01f6ca0d9c3e601d7fcf39481fd7d6c2222189ed,Dockerfile.Demo,"@@ -1,17 +1,16 @@
 FROM python:3.12
+############################
+## Hugging Face Optimized ##
+############################
 
 WORKDIR /app
 
-COPY . .
-
-EXPOSE 7860
-
 ENV PYTHONUNBUFFERED=1
 
-RUN apt-get update && apt-get install -y libgl1
-
-RUN pip install .
+RUN apt-get update && apt-get install -y libgl1 \
+    && rm -rf /var/lib/apt/lists/*
 
+RUN pip install pdf2zh
 RUN mkdir -p /data
 RUN chmod 777 /data
 RUN mkdir -p /app
@@ -20,5 +19,13 @@ RUN mkdir -p /.cache
 RUN chmod 777 /.cache
 RUN mkdir -p ./gradio_files
 RUN chmod 777 ./gradio_files
+RUN mkdir -p /.config
+RUN chmod 777 /.config
+RUN mkdir -p /.config/PDFMathTranslate
+RUN chmod 777 /.config/PDFMathTranslate
+
 
-CMD [""pdf2zh"", ""-i""]
+# write several lines to the file /.config/PDFMathTranslate/config.json
+RUN echo '{ ""USE_MODELSCOPE"": ""0"", ""PDF2ZH_LANG_FROM"": ""English"", ""PDF2ZH_LANG_TO"": ""Simplified Chinese"", ""NOTO_FONT_PATH"": ""/app/SourceHanSerifCN-Regular.ttf"", ""translators"":[]}' > /.config/PDFMathTranslate/config.json
+RUN chmod 777 /.config/PDFMathTranslate/config.json
+CMD [""pdf2zh"", ""-i"", ""--config"", ""/.config/PDFMathTranslate/config.json""]
",add support for pdf2zh,
b734e26ed0ae6449c10d4691c93a56392f107007,问题反馈_cn.yaml,"@@ -29,10 +29,7 @@ body:
           - **OS**: Ubuntu 24.10  
           - **Python**: 3.12.0  
           - **pdf2zh**: 1.9.0
-      value: |
-          - OS:
-          - Python:
-          - pdf2zh:
+      value: 
       render: markdown
     validations:
       required: false
",add missing documentation,
b734e26ed0ae6449c10d4691c93a56392f107007,问题反馈_en.yaml,"@@ -28,10 +28,7 @@ body:
           - **OS**: Ubuntu 24.10
           - **Python**: 3.12.0
           - **pdf2zh**: 1.9.0
-      value: |
-          - OS:
-          - Python:
-          - pdf2zh:
+      value: 
       render: markdown
     validations:
       required: false
",add missing docs,
86a214a193bc975c137050f1e96bff5bbe67b028,问题反馈_cn.yaml,"@@ -24,12 +24,10 @@ body:
     id: environment
     attributes:
       label: 使用的环境
-      description: |
-        examples:
+      placeholder: |
           - **OS**: Ubuntu 24.10  
           - **Python**: 3.12.0  
           - **pdf2zh**: 1.9.0
-      value: 
       render: markdown
     validations:
       required: false
",add missing docs,
86a214a193bc975c137050f1e96bff5bbe67b028,问题反馈_en.yaml,"@@ -23,12 +23,10 @@ body:
     id: environment
     attributes:
       label: Environment
-      description: |
-        examples:
+      placeholder: |
           - **OS**: Ubuntu 24.10
           - **Python**: 3.12.0
           - **pdf2zh**: 1.9.0
-      value: 
       render: markdown
     validations:
       required: false
",add missing docs,
64b4fe2220b78ae340e0da85ed3db6afaa622b60,Dockerfile,"@@ -23,6 +23,6 @@ RUN uv pip install --system --no-cache -r pyproject.toml && babeldoc --version &
 
 COPY . .
 
-RUN uv pip install --system --no-cache . && uv pip install --system --no-cache -U babeldoc ""pymupdf<1.25.3"" && babeldoc --version && babeldoc --warmup
+RUN uv pip install --system --no-cache . && uv pip install --system --no-cache -U ""babeldoc<0.3.0"" ""pymupdf<1.25.3"" && babeldoc --version && babeldoc --warmup
 
 CMD [""pdf2zh"", ""-i""]
",add pdf2zh to babeldoc-cli,
6faf9b42eae708ca644947979273426ead5fce73,Dockerfile,"@@ -23,6 +23,6 @@ RUN uv pip install --system --no-cache -r pyproject.toml && babeldoc --version &
 
 COPY . .
 
-RUN uv pip install --system --no-cache . && uv pip install --system --no-cache -U ""babeldoc<0.3.0"" ""pymupdf<1.25.3"" && babeldoc --version && babeldoc --warmup
+RUN uv pip install --system --no-cache . && uv pip install --system --no-cache -U ""babeldoc<0.3.0"" ""pymupdf<1.25.3"" ""pdfminer-six==20250416"" && babeldoc --version && babeldoc --warmup
 
 CMD [""pdf2zh"", ""-i""]
",add pdfminer to babeldoc,
9ab2db25b54a9a2a8f5fcd7025e4b23448d31a83,README.md,"@@ -129,7 +129,7 @@ pip install pdf2zh
    pdf2zh -i
    ```
 
-4. If your browswer has not been started automatically, goto
+4. If your browser has not been started automatically, goto
 
    ```bash
    http://localhost:7860/
@@ -265,7 +265,7 @@ For detailed explanations, please refer to our document about [Advanced Usage](.
 
 <h2 id=""downstream"">Secondary Development (APIs)</h2>
 
-For downstream applications, please refer to our document about [API Details](./docs/APIS.md) for futher information about:
+For downstream applications, please refer to our document about [API Details](./docs/APIS.md) for further information about:
 
 - [Python API](./docs/APIS.md#api-python), how to use the program in other Python programs
 - [HTTP API](./docs/APIS.md#api-http), how to communicate with a server with the program installed
",add documentation for missing api section,
d11ff90ad0fb2d8d7a20d60238e816f2aa5f5ccf,high_level.py,"@@ -126,7 +126,7 @@ def translate_patch(
                 callback(progress)
             page.pageno = pageno
             pix = doc_zh[page.pageno].get_pixmap()
-            image = np.fromstring(pix.samples, np.uint8).reshape(
+            image = np.frombuffer(pix.samples, np.uint8).reshape(
                 pix.height, pix.width, 3
             )[:, :, ::-1]
             page_layout = model.predict(image, imgsz=int(pix.height / 32) * 32)[0]
",update translate_patch.rb,
f8d0a680ef8a01c68ebb4eee9eaaf8430203dc56,translator.py,"@@ -287,6 +287,7 @@ class DeepLXTranslator(BaseTranslator):
                 ""target_lang"": self.lang_out,
                 ""text"": text,
             },
+            verify=False,  # noqa: S506
         )
         response.raise_for_status()
         return response.json()[""data""]
",add missing missing return,
b9fa581900e6f231c51b5040b96678b777bb0e44,功能请求_cn.yaml,"@@ -2,6 +2,10 @@ name: 功能请求
 description: 使用中文进行功能请求
 labels: ['enhancement']
 body:
+  - type: markdown
+    attrbutes:
+      value: |
+        ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: textarea
     id: describe
     attributes:
",add missing link to next,
b9fa581900e6f231c51b5040b96678b777bb0e44,功能请求_en.yaml,"@@ -2,6 +2,10 @@ name: Feature request
 description: Suggest an idea for this project
 labels: ['enhancement']
 body:
+  - type: markdown
+    attrbutes:
+      value: |
+        ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: textarea
     id: describe
     attributes:
",add missing link to next link,
b9fa581900e6f231c51b5040b96678b777bb0e44,问题反馈_cn.yaml,"@@ -2,6 +2,10 @@ name: 上报 Bug
 description: 使用中文进行 Bug 报告
 labels: ['bug']
 body:
+  - type: markdown
+    attrbutes:
+      value: |
+        ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: checkboxes
     id: checks
     attributes:
",add missing link to new link,
b9fa581900e6f231c51b5040b96678b777bb0e44,问题反馈_en.yaml,"@@ -2,6 +2,10 @@ name: Bug Report
 description: Create a report to help us improve
 labels: ['bug']
 body:
+  - type: markdown
+    attrbutes:
+      value: |
+        ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: checkboxes
     id: checks
     attributes:
",add link to new bug report,
f6870239fb87aa6faf75d0a705ca788081fdd46b,功能请求_cn.yaml,"@@ -3,7 +3,7 @@ description: 使用中文进行功能请求
 labels: ['enhancement']
 body:
   - type: markdown
-    attrbutes:
+    attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: textarea
",add link to new release link,
f6870239fb87aa6faf75d0a705ca788081fdd46b,功能请求_en.yaml,"@@ -3,7 +3,7 @@ description: Suggest an idea for this project
 labels: ['enhancement']
 body:
   - type: markdown
-    attrbutes:
+    attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: textarea
",add link to new release link,
f6870239fb87aa6faf75d0a705ca788081fdd46b,问题反馈_cn.yaml,"@@ -3,7 +3,7 @@ description: 使用中文进行 Bug 报告
 labels: ['bug']
 body:
   - type: markdown
-    attrbutes:
+    attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: checkboxes
",add link to new release link,
f6870239fb87aa6faf75d0a705ca788081fdd46b,问题反馈_en.yaml,"@@ -3,7 +3,7 @@ description: Create a report to help us improve
 labels: ['bug']
 body:
   - type: markdown
-    attrbutes:
+    attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
   - type: checkboxes
",add link to new release link,
8b0a83895f4740dc1819153030d9fbc3540c3903,blank.yaml,"@@ -1,6 +1,17 @@
 name: Blank Issue
 description: Create a blank issue for discussion
-body:
+body:  
+  - type: markdown
+    attributes:
+      value: |
+        ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
+  - type: checkboxes
+    id: checks
+    attributes:
+      label: Before you asking
+      options:
+      - label: I have tried the PDFMathTranslate-next and give feedback in PDFMathTranslate-next
+        required: true
   - type: checkboxes
     id: checks
     attributes:
",add missing link to the documentation,
8b0a83895f4740dc1819153030d9fbc3540c3903,功能请求_cn.yaml,"@@ -6,6 +6,13 @@ body:
     attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
+  - type: checkboxes
+    id: checks
+    attributes:
+      label: 在提问之前...
+      options:
+      - label: 我已经尝试了PDFMathTranslate-next,并在PDFMathTranslate-next提交了issue
+        required: true
   - type: textarea
     id: describe
     attributes:
",add missing docs to the next tag,
8b0a83895f4740dc1819153030d9fbc3540c3903,功能请求_en.yaml,"@@ -6,6 +6,13 @@ body:
     attributes:
       value: |
         ## 2.0 is released! new repo is [HERE](https://github.com/PDFMathTranslate/PDFMathTranslate-next)
+  - type: checkboxes
+    id: checks
+    attributes:
+      label: Before you asking
+      options:
+      - label: I have tried the PDFMathTranslate-next and give feedback in PDFMathTranslate-next
+        required: true
   - type: textarea
     id: describe
     attributes:
",add missing tag,
8b0a83895f4740dc1819153030d9fbc3540c3903,问题反馈_cn.yaml,"@@ -11,6 +11,8 @@ body:
     attributes:
       label: 在提问之前...
       options:
+      - label: 我已经尝试了PDFMathTranslate-next,并在PDFMathTranslate-next提交了issue
+        required: true
       - label: 我已经搜索了现有的 issues
         required: true
       - label: 我在提问题之前至少花费了 5 分钟来思考和准备
",add missing options to the test,
8b0a83895f4740dc1819153030d9fbc3540c3903,问题反馈_en.yaml,"@@ -11,6 +11,8 @@ body:
     attributes:
       label: Before you asking
       options:
+      - label: I have tried the PDFMathTranslate-next and give feedback in PDFMathTranslate-next
+        required: true
       - label: I have searched the existing issues
         required: true
       - label: I spend at least 5 minutes for thinking and preparing
",add missing doc block,
f715a8705c5df1a03f477a236edc7f203e14edf4,README.md,"@@ -12,7 +12,7 @@ English | [简体中文](docs/README_zh-CN.md) | [繁體中文](docs/README_zh-T
     <img src=""https://img.shields.io/pypi/v/pdf2zh""></a>
   <a href=""https://pepy.tech/projects/pdf2zh"">
     <img src=""https://static.pepy.tech/badge/pdf2zh""></a>
-  <a href=""https://hub.docker.com/repository/docker/byaidu/pdf2zh"">
+  <a href=""https://hub.docker.com/r/byaidu/pdf2zh"">
     <img src=""https://img.shields.io/docker/pulls/byaidu/pdf2zh""></a>
   <a href=""https://hellogithub.com/repository/8ec2cfd3ef744762bf531232fa32bc47"" target=""_blank""><img src=""https://api.hellogithub.com/v1/widgets/recommend.svg?rid=8ec2cfd3ef744762bf531232fa32bc47&claim_uid=JQ0yfeBNjaTuqDU&theme=small"" alt=""Featured｜HelloGitHub"" /></a>
   <a href=""https://gitcode.com/Byaidu/PDFMathTranslate/overview"">
",add support for `--show-recommend`,
0f0618d3303d064d97e7adb77557b21236c6cee0,__init__.py,"@@ -3,6 +3,6 @@ from pdf2zh.high_level import translate, translate_stream
 
 log = logging.getLogger(__name__)
 
-__version__ = ""1.9.10""
+__version__ = ""1.9.11""
 __author__ = ""Byaidu""
 __all__ = [""translate"", ""translate_stream""]
",add version to the missing file,
0f0618d3303d064d97e7adb77557b21236c6cee0,pyproject.toml,"@@ -1,6 +1,6 @@
 [project]
 name = ""pdf2zh""
-version = ""1.9.10""
+version = ""1.9.11""
 description = ""Latex PDF Translator""
 authors = [{ name = ""Byaidu"", email = ""byaidux@gmail.com"" }]
 license = ""AGPL-3.0""
@@ -22,7 +22,8 @@ dependencies = [
     ""deepl"",
     ""openai>=1.0.0"",
     ""azure-ai-translation-text<=1.0.1"",
-    ""gradio"",
+    # 5.36 has a bug, webui starts with a white screen
+    ""gradio<5.36"",
     ""huggingface_hub"",
     ""onnx"",
     ""onnxruntime"",
@@ -77,7 +78,7 @@ max-line-length = 88
 
 
 [bumpver]
-current_version = ""1.9.10""
+current_version = ""1.9.11""
 version_pattern = ""MAJOR.MINOR.PATCH[.PYTAGNUM]""
 
 [bumpver.file_patterns]
",add missing version,
